{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6400d3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:03.990403Z",
     "start_time": "2025-03-20T03:56:55.070662Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba57fee-7745-4497-ae97-003d9e262f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameter setting\n",
    "trans_mat=np.array([[0.6,0.4],[0.8,0.2]])\n",
    "trans_mat_new=np.array([[0.5,0.5],[0.7,0.3]])\n",
    "trans_mat_new=trans_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ba1eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:07.051758Z",
     "start_time": "2025-03-20T03:57:07.046140Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "###### move one step forward ####\n",
    "#################################\n",
    "\n",
    "\n",
    "def step(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat[0,1])\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        s_next = a + 1  # next state\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        s_next = a + 1\n",
    "\n",
    "    return (a, r, s_next)\n",
    "\n",
    "def step_new(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[0,1])\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        s_next = a + 1  # next state\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        s_next = a + 1\n",
    "\n",
    "    return (a, r, s_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2221da9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:09.800005Z",
     "start_time": "2025-03-20T03:57:09.791357Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#### generate one trajectory ####\n",
    "#################################\n",
    "\n",
    "\n",
    "def gen_traj(T, gam, seed=None, s_init=None):\n",
    "    # seed: random seed\n",
    "    # s_init: initial state\n",
    "    # gam: discount\n",
    "    # T: iterative number\n",
    "\n",
    "    # initialize the state\n",
    "    if seed is None and s_init is None:\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    elif seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    if s_init is not None:\n",
    "        s = s_init\n",
    "\n",
    "    s_traj = [s]\n",
    "    a_traj = []\n",
    "    r_traj = []\n",
    "\n",
    "    ret = 0\n",
    "    for i in range(T):\n",
    "        a, r, s_next = step(s)\n",
    "        s_traj.append(s_next)\n",
    "        a_traj.append(a)\n",
    "        r_traj.append(r)\n",
    "        s = s_next  # update current S as S_next\n",
    "        ret += r * gam**i\n",
    "\n",
    "    ## output state, reward trajectory. return\n",
    "    return [s_traj, a_traj, r_traj, ret]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149bfe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:10.570183Z",
     "start_time": "2025-03-20T03:57:10.553870Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#### generate data ####\n",
    "#######################\n",
    "\n",
    "\n",
    "def data_gen(N, T_obs, T, gam, seed=None, s_init=None):\n",
    "    # N: number of trajectories\n",
    "    # T_obs: observed stage numbers\n",
    "\n",
    "    s_data = np.zeros((N, T_obs), dtype=int)\n",
    "    a_data = np.zeros((N, T_obs), dtype=int)\n",
    "    r_data = np.zeros((N, T_obs))\n",
    "    ret_data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if seed is not None:\n",
    "            seed += 1\n",
    "        tmp = gen_traj(T, gam, seed, s_init)\n",
    "        s_data[i] = tmp[0][0:T_obs]  # store the i-th state trajectory\n",
    "        a_data[i] = tmp[1][0:T_obs]\n",
    "        r_data[i] = tmp[2][0:T_obs]  # store the i-th reward trajectory\n",
    "        ret_data.append(tmp[3])\n",
    "\n",
    "    ## output observed state, reward trajectory and true return\n",
    "    return [s_data, a_data ,r_data, ret_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7432f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:14.162795Z",
     "start_time": "2025-03-20T03:57:14.156622Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### Quantile temperal difference ###\n",
    "####################################\n",
    "\n",
    "\n",
    "def QTD(state_traj,\n",
    "        action_traj,\n",
    "        reward_traj,\n",
    "        state_card,\n",
    "        action_card,\n",
    "        quantile_num,\n",
    "        gam,\n",
    "        rate=None,\n",
    "        init_val=None):\n",
    "    # obs_traj: training data\n",
    "    # state_card: cardinality of state space\n",
    "    ## quantile_num: number of target conditional quantiles for each state\n",
    "    # rate: learning rate\n",
    "    # init_val: initial value\n",
    "\n",
    "    if init_val == None:\n",
    "        ret_con_quantile = np.zeros((state_card,action_card, quantile_num))\n",
    "    elif init_value is not None:\n",
    "        ret_con_quantile = init_value\n",
    "    if rate == None:\n",
    "        rate = 0.1\n",
    "\n",
    "    #ret_con_quantile = np.zeros((state_card, quantile_num))\n",
    "\n",
    "    n = np.shape(reward_traj)[0]  ## number of trajectories\n",
    "    batch_num = np.shape(state_traj)[1] - 1  ## number of (x,r,x') tuples\n",
    "    tau = [(2 * i + 1) / (2 * quantile_num) for i in range(quantile_num)]\n",
    "    \n",
    "    for k in range(n):\n",
    "        for l in range(batch_num):\n",
    "            for i in range(quantile_num):    \n",
    "                s_current = state_traj[k, l]\n",
    "                a_current = action_traj[k, l]\n",
    "                r_current = reward_traj[k, l]\n",
    "                s_next = state_traj[k, l + 1]\n",
    "                a_next = action_traj[k, l + 1]\n",
    "                #j = np.random.randint(0, quantile_num - 1)\n",
    "                #ret_con_quantile[s_current - 1, i] += rate * tau[i] - rate * (\n",
    "                #    r_current + gam * ret_con_quantile[s_next - 1, j] -\n",
    "                #    ret_con_quantile[s_current - 1, i] < 0)\n",
    "                ret_con_quantile[s_current - 1, a_current, i] +=  rate * np.mean(\n",
    "                    [tau[i] - 1 * (r_current + gam * \n",
    "                                      ret_con_quantile[s_next - 1,a_next, j] - \n",
    "                                      ret_con_quantile[s_current - 1, a_current, i] < 0) \n",
    "                     for j in range(quantile_num)] \n",
    "                )\n",
    "\n",
    "    ## output conditional quantiles\n",
    "    return (ret_con_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae5ff8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:26.154742Z",
     "start_time": "2025-03-20T03:57:26.150664Z"
    }
   },
   "outputs": [],
   "source": [
    "## calculate V estimator based on QTD output\n",
    "def q_hat_f(G_quan):\n",
    "    return (np.mean(G_quan, axis=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c02206d-9e4e-4aac-be2e-b7ce3ddfadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算pi_a(a|x)\n",
    "p1=(trans_mat_new[0,1]/trans_mat_new[0,0])*(trans_mat[0,0]/trans_mat[0,1])\n",
    "a1=p1/(1+p1)\n",
    "p2=(trans_mat_new[1,1]/trans_mat_new[1,0])*(trans_mat[1,0]/trans_mat[1,1])\n",
    "a2=p2/(1+p2)\n",
    "def step_a(last_obs):\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=a1)\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=a2)\n",
    "\n",
    "    return (a)\n",
    "    \n",
    "vec_step=np.vectorize(step_a)\n",
    "mat=np.array([[1-a1,a1],[1-a2,a2]])\n",
    "weight_mat=trans_mat_new/trans_mat\n",
    "def weight_calculation_clip(s_vec, a_vec,clip):\n",
    "    weight=1\n",
    "    step=np.shape(s_vec)[0]-1\n",
    "    for i in range(step):\n",
    "        weight*=weight_mat[s_vec[i]-1,a_vec[i]]\n",
    "    weight=max(min(clip[1],weight),clip[0])\n",
    "    return(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfddf9eb-fc8c-4f07-9a67-6bfec1ea4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replay buffer+propensity score ratio\n",
    "def replay_buffer(s_traj, a_traj, r_traj,step_forward,ratio,clip):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward \n",
    "    Mem_state = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action_a = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    idx_weight=[]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action_a[(i*p+j),:] = vec_step(s_traj[i,j:(j+step_forward+1)])\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "            idx_weight.append(\n",
    "            weight_calculation_clip(Mem_state[(i*p+j), :], Mem_action[(i*p+j), :],clip) * ratio[Mem_state[(i*p+j), 0]-1]\n",
    "            )\n",
    "\n",
    "    total = np.array(idx_weight).sum()\n",
    "    idx_weight_final=np.array(idx_weight)/total\n",
    "    return([Mem_state,Mem_action,Mem_reward,idx_weight_final])\n",
    "\n",
    "##ratio of frequency of s_0/s_rb\n",
    "def rb(s_traj, a_traj, r_traj,step_forward):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward \n",
    "    Mem_state = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action_a = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    acc_1=0\n",
    "    acc_2=0\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action_a[(i*p+j),:] = vec_step(s_traj[i,j:(j+step_forward+1)])\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "            if (vec_step(s_traj[i,j:(j+step_forward)])==a_traj[i,j:(j+step_forward)]).all() and Mem_state[(i*p+j),0]==1 :\n",
    "                acc_1+=1\n",
    "            elif (vec_step(s_traj[i,j:(j+step_forward)])==a_traj[i,j:(j+step_forward)]).all() and Mem_state[(i*p+j),0]==2 :\n",
    "                acc_2+=1\n",
    "    ratio_1=(2*n*p-np.sum(Mem_state[:,0]))/acc_1\n",
    "    ratio_2=(np.sum(Mem_state[:,0])-n*p)/acc_2\n",
    "    return([ratio_1,ratio_2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f08e423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:58:54.244086Z",
     "start_time": "2025-03-20T03:58:54.239265Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def weighted_percentile(data, weights, perc):\n",
    "\n",
    "    data = np.array(data)\n",
    "    weights = np.array(weights)\n",
    "    idx = np.argsort(data)\n",
    "    data = data[idx] # sort data\n",
    "    weights = weights[idx] # sort weights\n",
    "    cdf = np.cumsum(weights) / np.sum(weights)\n",
    "    count = np.sum([ cdf[i] <= perc for i in range(np.shape(cdf)[0]) ])\n",
    "    #if output=infty return the maximum of V\n",
    "    if data[count]==float('inf'):\n",
    "        count-=1\n",
    "    return(data[count])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbbd0713-3728-4639-8385-a09b9d29be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(s_traj, r_traj,step_forward,gam,G_quan,v_hat):\n",
    "    # s_traj: state trajectory\n",
    "    # r_traj: reward trajectory\n",
    "    # step_forward: number of steps used in approximating return\n",
    "    # gam: discount\n",
    "    if np.shape(s_traj)[1]!=step_forward+1:\n",
    "        print(\"length dismatch\")\n",
    "    if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "        print(\"height dismatch\")\n",
    "    \n",
    "    quan_num = np.shape(G_quan)[2]\n",
    "    n = np.shape(s_traj)[0]\n",
    "    u = np.random.randint(0, quan_num - 1, size=n)\n",
    "    sc = list(\n",
    "        map(\n",
    "            abs,\n",
    "            np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] -\n",
    "                v_hat[s_traj[i, 0] - 1] for i in range(n)\n",
    "            ]))\n",
    "\n",
    "    return (sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40eb6eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:33.791316Z",
     "start_time": "2025-03-20T03:59:33.787823Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6175ce8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:41.448956Z",
     "start_time": "2025-03-20T03:59:41.435957Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_rb_res(data_train, data_test, gam, alp, step_forward, QTD_para,B,tau,seed,sample_size,clip):\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    s_init_te = data_test[0]\n",
    "    a_init_te = data_test[1]\n",
    "    ret_te = data_test[3]\n",
    "    \n",
    "    ## split training data\n",
    "    idx_perm = np.random.permutation(list(range(0, n_tr)))\n",
    "    idx_tr, idx_cal = [idx_perm[0:int(n_tr / 2)], idx_perm[int(n_tr / 2):n_tr]]\n",
    "    s_train_fold = data_train[0][idx_tr,:]\n",
    "    a_train_fold = data_train[1][idx_tr,:]\n",
    "    r_train_fold = data_train[2][idx_tr,:]\n",
    "    \n",
    "    ## train return distribution using QTD\n",
    "    G_quan = QTD_new(state_traj=s_train_fold,\n",
    "                 action_traj=a_train_fold,\n",
    "                 reward_traj=r_train_fold,\n",
    "                 state_card=2,\n",
    "                 action_card=2,\n",
    "                 quantile_num=QTD_para[0],\n",
    "                 gam=gam,\n",
    "                 seed=seed,\n",
    "                 rate=QTD_para[1],\n",
    "                 init_val=None)\n",
    "    Q_hat = q_hat_f(G_quan)\n",
    "    v_hat=np.zeros(2)\n",
    "    v_hat[0]=trans_mat_new[0,0]*Q_hat[0,0]+trans_mat_new[0,1]*Q_hat[0,1]\n",
    "    v_hat[1]=trans_mat_new[1,0]*Q_hat[1,0]+trans_mat_new[1,1]*Q_hat[1,1]\n",
    "\n",
    "\n",
    "    ## calculate nonconformity scores based on test set\n",
    "    sc_te = [abs(ret_te[i] - v_hat[s_init_te[i, 0] - 1]) for i in range(n_te)]\n",
    "    \n",
    "    ## replay buffer\n",
    "    l = np.shape(step_forward)[0]\n",
    "    if isinstance(tau, int) == False:\n",
    "        m = np.shape(tau)[0]\n",
    "    elif isinstance(tau, int) == True:\n",
    "        m = 1\n",
    "        \n",
    "    PI_cov_e = np.zeros((m,l))\n",
    "    PI_len_e = np.zeros((m,l))\n",
    "            \n",
    "    p1_s0_estimate = np.mean(s_train_fold[:,0] - 1)\n",
    "\n",
    "            \n",
    "        \n",
    "    for k in range(l):\n",
    "       \n",
    "        ratio=rb(s_traj=data_train[0][idx_tr, :],\n",
    "                    a_traj=data_train[1][idx_tr, :],\n",
    "               r_traj=data_train[2][idx_tr, :],\n",
    "                step_forward=step_forward[k])\n",
    "        ## density ratio\n",
    "        Mem_1 = replay_buffer(s_traj=s_train_fold,\n",
    "                              a_traj=a_train_fold,\n",
    "                              r_traj=r_train_fold,\n",
    "                              step_forward=1,\n",
    "                             ratio=np.ones(2),\n",
    "                             clip=np.ones(2))\n",
    "        p1_rb = np.mean(Mem_1[0][:,0] - 1)\n",
    "        dr_s_e = [((1-p1_s0_estimate)/(1-p1_rb))*ratio[0],(p1_s0_estimate/p1_rb)*ratio[1]]\n",
    "        \n",
    "        quan_B_e = np.zeros((m,n_te,B))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    " \n",
    "        for i in range(B):\n",
    "            \n",
    "        #n_cal = np.random.choice(a=[j for j in range(np.shape(Mem[0])[0])], p=p,size=200)\n",
    "            Mem = replay_buffer(s_traj=data_train[0][idx_cal, :],\n",
    "                    a_traj=data_train[1][idx_cal, :],\n",
    "                 r_traj=data_train[2][idx_cal, :],\n",
    "                step_forward=step_forward[k],\n",
    "                               ratio=ratio,\n",
    "                               clip=clip)\n",
    "            weight_is=Mem[-1]\n",
    "            n_cal = np.random.choice(range(np.shape(weight_is)[0]),size=sample_size, p=weight_is)\n",
    "            ## calculate nonconformity scores based on calibration set\n",
    "            sc_rb = scoring(s_traj=Mem[0][n_cal,],\n",
    "                            r_traj=Mem[2][n_cal,],\n",
    "                            step_forward=step_forward[k],\n",
    "                            gam=gam,\n",
    "                            G_quan=G_quan,\n",
    "                            v_hat=v_hat)\n",
    "            sc_rb.append(float('inf')) \n",
    "            for j in range(n_te): \n",
    "                for z in range(m):\n",
    "                    quan_B_e[z][j,i] = weighted_percentile(data=sc_rb,weights=np.ones(sample_size+1),\n",
    "                                                      perc=1-alp)\n",
    "                    \n",
    "        critical_value_rb_e = np.zeros((m,n_te))\n",
    " \n",
    "        for z in range(m):\n",
    "            critical_value_rb_e[z,:] = [ np.percentile(a=quan_B_e[z][k,:],\n",
    "                                                           q=tau[z]*100) for k in range(n_te) ]\n",
    "\n",
    "            \n",
    "            PI_cov_e[z,k] = np.mean([sc_te[k] <= critical_value_rb_e[z,k] \n",
    "                                         for k in range(n_te)])\n",
    "            PI_len_e[z,k] = 2 * np.mean(critical_value_rb_e[z,:])\n",
    "            \n",
    "            \n",
    "    return([PI_cov_e,PI_len_e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02f506fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:22:31.005418Z",
     "start_time": "2025-03-19T15:22:31.005418Z"
    }
   },
   "outputs": [],
   "source": [
    "def quantile_region_res(data_train, data_test, gam, alp, QTD_para,seed):\n",
    "\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    s_init_te = data_test[0]\n",
    "    a_init_te = data_test[1] \n",
    "    ret_te = data_test[3]\n",
    "    quant_num = QTD_para[0]\n",
    "    ## train QTD using full training data\n",
    "    G_quan_full = QTD_new(state_traj=data_train[0],\n",
    "                      action_traj=data_train[1],\n",
    "                      reward_traj=data_train[2],\n",
    "                      state_card=2,\n",
    "                      action_card=2,  \n",
    "                      quantile_num=quant_num,\n",
    "                      gam=gam,\n",
    "                      seed=seed,\n",
    "                      rate=QTD_para[1],\n",
    "                      init_val=None)\n",
    "    quant_interval_lower=np.zeros(2)\n",
    "    quant_interval_upper=np.zeros(2)\n",
    "\n",
    "    ## lower and upper quanitles for each states \n",
    "    for i in range(2):\n",
    "        data_aug=np.hstack((G_quan_full[i,0,:], G_quan_full[i,1,:])) \n",
    "        weight_aug=np.hstack((np.ones(quant_num)*trans_mat_new[i,0]/quant_num,np.ones(quant_num)*trans_mat_new[i,1]/quant_num))\n",
    "        quant_interval_lower[i]=weighted_percentile(data_aug,weight_aug,alp/2)\n",
    "        quant_interval_upper[i]=weighted_percentile(data_aug,weight_aug,1-alp/2)\n",
    "                       \n",
    "\n",
    "    ## calculate coverage\n",
    "    t1 = [\n",
    "    ret_te[i] >= quant_interval_lower[s_init_te[i, 0] - 1] for i in range(n_te)\n",
    "    ]\n",
    "    t2 = [\n",
    "    ret_te[i] <= quant_interval_upper[s_init_te[i, 0] - 1] for i in range(n_te)\n",
    "    ]\n",
    "    quan_PI_cov = np.mean([all([t1[i], t2[i]]) for i in range(n_te)])\n",
    "    quan_PI_len = np.mean([\n",
    "        quant_interval_upper[s_init_te[i, 0] - 1] -\n",
    "        quant_interval_lower[s_init_te[i, 0] - 1] for i in range(n_te)\n",
    "        ])\n",
    "\n",
    "    return ([quan_PI_cov, quan_PI_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b737c9-5a7b-44fc-bada-4f763172ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel Calculation\n",
    "def run_single_experiment(i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, B, alp, tau, step_forward,sample_size,clip):\n",
    "\n",
    "    data_train = data_gen(N=n_tr,\n",
    "                          T_obs=T_obs,\n",
    "                          T=T,\n",
    "                          gam=gam,\n",
    "                          seed=seed + i,\n",
    "                          s_init=None)\n",
    "\n",
    "\n",
    "    data_test = data_gen_new(N=n_te,\n",
    "                             T_obs=1,\n",
    "                             T=T,\n",
    "                             gam=gam,\n",
    "                             seed=seed + i + 10000,\n",
    "                             s_init=None)\n",
    "\n",
    "    result = new_rb_res(data_train=data_train,\n",
    "                        data_test=data_test,\n",
    "                        gam=gam,\n",
    "                        alp=alp,\n",
    "                        step_forward=step_forward,\n",
    "                        QTD_para=QTD_para,\n",
    "                        B=B,\n",
    "                        tau=tau,\n",
    "                        seed=seed + i,\n",
    "                        sample_size=sample_size,\n",
    "                       clip=clip)\n",
    "   \n",
    "    return result  # return [PI_cov_e, PI_len_e]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba05eaa-534c-43ca-867e-d005ab16965e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter setting\n",
    "rep = 100\n",
    "n_tr = 400\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 70\n",
    "QTD_para = [20, 0.1]\n",
    "B = 50\n",
    "alp = 0.1\n",
    "tau = [0.2,0.3,0.4,0.5]\n",
    "clip=np.array([0.2,5.0])\n",
    "step_forward = [1, 2, 3,4,5]\n",
    "sample_size=200\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=30, verbose=1)(\n",
    "    delayed(run_single_experiment)(\n",
    "        i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, B, alp, tau, step_forward, sample_size,clip\n",
    "    ) for i in range(rep)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30500b6f-eecd-4a06-81ef-62fd05e6bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_new_cov_tau01_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau01_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau02_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau02_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau03_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau03_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau04_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau04_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "for i in range(np.shape(results)[0]):\n",
    "\n",
    "    rb_new_cov_tau01_e3[i, :] = results [i][0][0]\n",
    "    rb_new_len_tau01_e3[i, :] = results [i][1][0]\n",
    "    rb_new_cov_tau02_e3[i, :] = results [i][0][1]\n",
    "    rb_new_len_tau02_e3[i, :] = results [i][1][1]\n",
    "    rb_new_cov_tau03_e3[i, :] = results [i][0][2]\n",
    "    rb_new_len_tau03_e3[i, :] = results [i][1][2]\n",
    "    rb_new_cov_tau04_e3[i, :] = results [i][0][3]\n",
    "    rb_new_len_tau04_e3[i, :] = results [i][1][3]\n",
    "\n",
    "\n",
    "PI_cov_all = [res[0] for res in results]\n",
    "PI_len_all = [res[1] for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d3ac89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T23:56:51.524066Z",
     "start_time": "2025-03-19T23:56:51.517499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new(tau=0.1): \n",
      "coverage probability: \n",
      "[0.8820645161290324, 0.8895483870967741, 0.8915483870967742, 0.8921935483870967, 0.8950322580645163]\n",
      "average length: \n",
      "[6.727893559099994, 6.863006978508485, 6.902510420577609, 6.91913463338389, 6.9569359766338]\n",
      "new(tau=0.2): \n",
      "coverage probability: \n",
      "[0.8921612903225805, 0.9001935483870966, 0.9024193548387096, 0.9043870967741934, 0.906032258064516]\n",
      "average length: \n",
      "[6.903011840456324, 7.038433696559764, 7.075001615714122, 7.103650731761804, 7.134154338069956]\n",
      "new(tau=0.3): \n",
      "coverage probability: \n",
      "[0.8996774193548387, 0.9075483870967741, 0.9109032258064513, 0.9121612903225806, 0.9138064516129033]\n",
      "average length: \n",
      "[7.028714164147691, 7.165922465601024, 7.217996891328595, 7.239422288179153, 7.278856408721765]\n",
      "new(tau=0.4): \n",
      "coverage probability: \n",
      "[0.9054838709677421, 0.9138387096774193, 0.9165483870967742, 0.917258064516129, 0.9189032258064516]\n",
      "average length: \n",
      "[7.13249228067631, 7.285776662150312, 7.336057332894228, 7.358677769521463, 7.398790145405934]\n"
     ]
    }
   ],
   "source": [
    "print(\"new(tau=0.2): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau01_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau01_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "\n",
    "print(\"new(tau=0.3): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau02_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau02_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "\n",
    "print(\"new(tau=0.4): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "print(\"new(tau=0.5): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau04_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau04_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74f0d730-07b6-42fc-ae91-1fb8a471246d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau01_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau01_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau01_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau01_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau01_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_simple_01.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau01_e3[:,0],\n",
    "     'k=2': rb_new_len_tau01_e3[:,1],\n",
    "     'k=3': rb_new_len_tau01_e3[:,2],\n",
    "     'k=4': rb_new_len_tau01_e3[:,3],\n",
    "     'k=5': rb_new_len_tau01_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_simple_01.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4d2d62d7-7b62-4568-9b38-b2176bbbb741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau02_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau02_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau02_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau02_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau02_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_simple_02.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau02_e3[:,0],\n",
    "     'k=2': rb_new_len_tau02_e3[:,1],\n",
    "     'k=3': rb_new_len_tau02_e3[:,2],\n",
    "     'k=4': rb_new_len_tau02_e3[:,3],\n",
    "     'k=5': rb_new_len_tau02_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_simple_02.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7ed76c28-2d36-4de5-9b73-d5f3130c6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau03_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau03_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau03_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau03_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau03_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_simple_03.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau03_e3[:,0],\n",
    "     'k=2': rb_new_len_tau03_e3[:,1],\n",
    "     'k=3': rb_new_len_tau03_e3[:,2],\n",
    "     'k=4': rb_new_len_tau03_e3[:,3],\n",
    "     'k=5': rb_new_len_tau03_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_simple_03.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27b51280-ce47-4cbc-b5d8-21e8262396da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau04_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau04_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau04_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau04_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau04_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_simple_04.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau04_e3[:,0],\n",
    "     'k=2': rb_new_len_tau04_e3[:,1],\n",
    "     'k=3': rb_new_len_tau04_e3[:,2],\n",
    "     'k=4': rb_new_len_tau04_e3[:,3],\n",
    "     'k=5': rb_new_len_tau04_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_simple_04.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a08941fe-d831-4131-b12b-d2c8c90f7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr = 400\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 70\n",
    "rep = 100\n",
    "QTD_para = [20, 0.015]\n",
    "alp = 0.1\n",
    "\n",
    "res_quan_500_qnum10 = np.zeros((rep, 2))\n",
    "\n",
    "# Parallel Calculation\n",
    "def process_iteration(i,n_tr, gam, T_obs, seed, n_te, T, QTD_para, alp):\n",
    " \n",
    "    data_train = data_gen(N=n_tr,\n",
    "                         T_obs=T_obs,\n",
    "                         T=T,\n",
    "                         gam=gam,\n",
    "                         seed=seed+i,\n",
    "                         s_init=None)\n",
    "    \n",
    "\n",
    "    data_test = data_gen_new(N=n_te,\n",
    "                            T_obs=1,\n",
    "                            T=T,\n",
    "                            gam=gam,\n",
    "                            seed=seed + i + 10000,\n",
    "                            s_init=None)\n",
    "    \n",
    "\n",
    "    quan_PI_res1 = quantile_region_res(data_train=data_train,\n",
    "                                      data_test=data_test, \n",
    "                                      gam=gam, \n",
    "                                      alp=alp,\n",
    "                                      QTD_para=QTD_para,\n",
    "                                      seed=seed+i)\n",
    "    \n",
    "    print(f\"test num: {i}\")\n",
    "    print(\"quantile region: \")\n",
    "    print(f\"cov: {quan_PI_res1[0]} | length: {quan_PI_res1[1]}\")\n",
    "    \n",
    "    return quan_PI_res1\n",
    "\n",
    "\n",
    "\n",
    "results_qr = Parallel(n_jobs=30)(delayed(process_iteration)(i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, alp) for i in range(rep))\n",
    "\n",
    "# restore data\n",
    "for i in range(rep):\n",
    "    res_quan_500_qnum10[i, :] = results_qr[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b055a675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:47:46.618942Z",
     "start_time": "2025-03-19T07:47:46.550210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantile region\n",
      "0         0.851613\n",
      "1         0.858065\n",
      "2         0.851613\n",
      "3         0.851613\n",
      "4         0.851613\n",
      "   quantile region\n",
      "0         6.989250\n",
      "1         7.057908\n",
      "2         6.953058\n",
      "3         6.959608\n",
      "4         7.008846\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "##### save simulation result\n",
    "data_quan_cov = {\n",
    "    'quantile region': res_quan_500_qnum10[:, 0]\n",
    "}\n",
    "\n",
    "df_cov = pd.DataFrame(data_quan_cov)\n",
    "\n",
    "df_cov.to_excel('QR_cov_simple_on.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_quan_len = {\n",
    "    'quantile region': res_quan_500_qnum10[:, 1]\n",
    "}\n",
    "\n",
    "df_len = pd.DataFrame(data_quan_len)\n",
    "\n",
    "df_len.to_excel('QR_len_simple_on.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "print(df_cov.head())\n",
    "print(df_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b906adf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:46:49.188482Z",
     "start_time": "2025-03-19T07:46:49.179093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile region: \n",
      "coverage probability:  0.8624838709677419 |  average length:  6.996038467742023\n"
     ]
    }
   ],
   "source": [
    "print(\"quantile region: \")\n",
    "print(\"coverage probability: \", np.mean(res_quan_500_qnum10[:, 0]),\n",
    "      \"|  average length: \", np.mean(res_quan_500_qnum10[:, 1]))\n",
    "\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d3be7",
   "metadata": {},
   "source": [
    "# Plotting simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7c59d47-218e-42d2-81d3-b36efdabaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        k=1       k=2       k=3       k=4       k=5    DRL-QR\n",
      "0  0.870968  0.890323  0.880645  0.880645  0.890323  0.851613\n",
      "1  0.870968  0.877419  0.877419  0.877419  0.893548  0.858065\n",
      "2  0.877419  0.883871  0.877419  0.896774  0.900000  0.851613\n",
      "3  0.877419  0.880645  0.877419  0.877419  0.880645  0.851613\n",
      "4  0.870968  0.890323  0.890323  0.887097  0.887097  0.851613\n",
      "        k=1       k=2       k=3       k=4       k=5    DRL-QR\n",
      "0  6.694877  7.029154  6.922169  6.938830  7.059769  6.989250\n",
      "1  6.687510  7.005146  6.981250  6.892263  7.155193  7.057908\n",
      "2  6.965559  7.031829  6.959724  7.203303  7.268165  6.953058\n",
      "3  6.831504  7.061643  6.974636  7.006035  7.026289  6.959608\n",
      "4  6.742365  7.016473  7.037745  6.972884  6.978426  7.008846\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_new_rb_cov = pd.read_excel('cov_on_simple_02.xlsx')\n",
    "data_new_rb_len = pd.read_excel('len_on_simple_02.xlsx')\n",
    "\n",
    "data_QR_cov = pd.read_excel('QR_cov_simple_on.xlsx')\n",
    "data_QR_len = pd.read_excel('QR_len_simple_on.xlsx')\n",
    "\n",
    "#data_new_rb_cov.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "#data_new_rb_len.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "data_new_rb_cov['DRL-QR'] = data_QR_cov['quantile region']\n",
    "data_new_rb_len['DRL-QR'] = data_QR_len['quantile region']\n",
    "\n",
    "print(data_new_rb_cov.head())\n",
    "print(data_new_rb_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91b40fd-20ad-47f3-82bc-ce1862baccd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_cov = data_new_rb_cov.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "colors = [\n",
    "    'goldenrod', 'orange', 'gold', 'khaki', 'wheat', 'lightyellow','skyblue'\n",
    "]\n",
    "\n",
    "colors2 = [\n",
    "    'darkseagreen','limegreen' ,'greenyellow','yellowgreen','lightgreen','honeydew','skyblue'\n",
    "]\n",
    "for patch, color in zip(bplot_new_cov.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_cov.yaxis.grid(False)\n",
    "bplot_new_cov.xaxis.grid(False)\n",
    "bplot_new_cov.set_xlabel(\"Method\")\n",
    "bplot_new_cov.set_ylabel(\"Coverage Probability\")\n",
    "\n",
    "plt.axhline(y=0.90, color='red', linestyle='-', linewidth=1)\n",
    "#plt.title(\"tau=0.9, n_tr=600, gam=0.8, quantnum=30, p_s0 estimator\")\n",
    "plt.ylim(0.75,1)\n",
    "#plt.savefig('fig/new_rb_cov_o_gam0.8_nr100_qnum10.png')\n",
    "plt.savefig('Ex1_on_policy_cp.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe97f3-e9f2-4156-ae67-593188d23223",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_len = data_new_rb_len.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "\n",
    "for patch, color in zip(bplot_new_len.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_len.yaxis.grid(False)\n",
    "bplot_new_len.xaxis.grid(False)\n",
    "bplot_new_len.set_xlabel(\"Method\")\n",
    "bplot_new_len.set_ylabel(\"Empirical Length\")\n",
    "\n",
    "#plt.title(\"tau=0.9, n_tr = 600, gam=0.8, quantnum=30, p_s0 estimator\")\n",
    "#plt.savefig('fig/new_len_o_gam0.8_nr100_qnum10.png')\n",
    "plt.show()\n",
    "plt.savefig(''Ex1_on_policy_al.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
