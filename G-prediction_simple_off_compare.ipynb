{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6400d3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:03.990403Z",
     "start_time": "2025-03-20T03:56:55.070662Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba57fee-7745-4497-ae97-003d9e262f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameter setting\n",
    "trans_mat=np.array([[0.6,0.4],[0.8,0.2]])\n",
    "trans_mat_new=np.array([[0.5,0.5],[0.7,0.3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ba1eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:07.051758Z",
     "start_time": "2025-03-20T03:57:07.046140Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "###### move one step forward ####\n",
    "#################################\n",
    "\n",
    "\n",
    "def step(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat[0,1])\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        s_next = a + 1  # next state\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        s_next = a + 1\n",
    "\n",
    "    return (a, r, s_next)\n",
    "\n",
    "def step_new(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[0,1])\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        s_next = a + 1  # next state\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        s_next = a + 1\n",
    "\n",
    "    return (a, r, s_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2221da9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:09.800005Z",
     "start_time": "2025-03-20T03:57:09.791357Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#### generate one trajectory ####\n",
    "#################################\n",
    "\n",
    "\n",
    "def gen_traj(T, gam, seed=None, s_init=None):\n",
    "    # seed: random seed\n",
    "    # s_init: initial state\n",
    "    # gam: discount\n",
    "    # T: iterative number\n",
    "\n",
    "    # initialize the state\n",
    "    if seed is None and s_init is None:\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    elif seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    if s_init is not None:\n",
    "        s = s_init\n",
    "\n",
    "    s_traj = [s]\n",
    "    a_traj = []\n",
    "    r_traj = []\n",
    "\n",
    "    ret = 0\n",
    "    for i in range(T):\n",
    "        a, r, s_next = step(s)\n",
    "        s_traj.append(s_next)\n",
    "        a_traj.append(a)\n",
    "        r_traj.append(r)\n",
    "        s = s_next  # update current S as S_next\n",
    "        ret += r * gam**i\n",
    "\n",
    "    ## output state, reward trajectory. return\n",
    "    return [s_traj, a_traj, r_traj, ret]\n",
    "\n",
    "\n",
    "def gen_traj_new(T, gam, seed=None, s_init=None):\n",
    "    # seed: random seed\n",
    "    # s_init: initial state\n",
    "    # gam: discount\n",
    "    # T: iterative number\n",
    "\n",
    "    # initialize the state\n",
    "    if seed is None and s_init is None:\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    elif seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    if s_init is not None:\n",
    "        s = s_init\n",
    "\n",
    "    s_traj = [s]\n",
    "    a_traj = []\n",
    "    r_traj = []\n",
    "\n",
    "    ret = 0\n",
    "    for i in range(T):\n",
    "        a, r, s_next = step_new(s)\n",
    "        s_traj.append(s_next)\n",
    "        a_traj.append(a)\n",
    "        r_traj.append(r)\n",
    "        s = s_next  # update current S as S_next\n",
    "        ret += r * gam**i\n",
    "\n",
    "    ## output state, reward trajectory. return\n",
    "    return [s_traj, a_traj, r_traj, ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149bfe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:10.570183Z",
     "start_time": "2025-03-20T03:57:10.553870Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#### generate data ####\n",
    "#######################\n",
    "\n",
    "\n",
    "def data_gen(N, T_obs, T, gam, seed=None, s_init=None):\n",
    "    # N: number of trajectories\n",
    "    # T_obs: observed stage numbers\n",
    "\n",
    "    s_data = np.zeros((N, T_obs), dtype=int)\n",
    "    a_data = np.zeros((N, T_obs), dtype=int)\n",
    "    r_data = np.zeros((N, T_obs))\n",
    "    ret_data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if seed is not None:\n",
    "            seed += 1\n",
    "        tmp = gen_traj(T, gam, seed, s_init)\n",
    "        s_data[i] = tmp[0][0:T_obs]  # store the i-th state trajectory\n",
    "        a_data[i] = tmp[1][0:T_obs]\n",
    "        r_data[i] = tmp[2][0:T_obs]  # store the i-th reward trajectory\n",
    "        ret_data.append(tmp[3])\n",
    "\n",
    "    ## output observed state, reward trajectory and true return\n",
    "    return [s_data, a_data ,r_data, ret_data]\n",
    "\n",
    "def data_gen_new(N, T_obs, T, gam, seed=None, s_init=None):\n",
    "    # N: number of trajectories\n",
    "    # T_obs: observed stage numbers\n",
    "\n",
    "    s_data = np.zeros((N, T_obs), dtype=int)\n",
    "    a_data = np.zeros((N, T_obs), dtype=int)\n",
    "    r_data = np.zeros((N, T_obs))\n",
    "    ret_data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if seed is not None:\n",
    "            seed += 1\n",
    "        tmp = gen_traj_new(T, gam, seed, s_init)\n",
    "        s_data[i] = tmp[0][0:T_obs]  # store the i-th state trajectory\n",
    "        a_data[i] = tmp[1][0:T_obs]\n",
    "        r_data[i] = tmp[2][0:T_obs]  # store the i-th reward trajectory\n",
    "        ret_data.append(tmp[3])\n",
    "\n",
    "    ## output observed state, reward trajectory and true return\n",
    "    return [s_data, a_data ,r_data, ret_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7432f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:14.162795Z",
     "start_time": "2025-03-20T03:57:14.156622Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### Quantile temperal difference ###\n",
    "####################################\n",
    "\n",
    "\n",
    "def QTD(state_traj,\n",
    "        action_traj,\n",
    "        reward_traj,\n",
    "        state_card,\n",
    "        action_card,\n",
    "        quantile_num,\n",
    "        gam,\n",
    "        rate=None,\n",
    "        init_val=None):\n",
    "    # obs_traj: training data\n",
    "    # state_card: cardinality of state space\n",
    "    ## quantile_num: number of target conditional quantiles for each state\n",
    "    # rate: learning rate\n",
    "    # init_val: initial value\n",
    "\n",
    "    if init_val == None:\n",
    "        ret_con_quantile = np.zeros((state_card,action_card, quantile_num))\n",
    "    elif init_value is not None:\n",
    "        ret_con_quantile = init_value\n",
    "    if rate == None:\n",
    "        rate = 0.1\n",
    "\n",
    "    #ret_con_quantile = np.zeros((state_card, quantile_num))\n",
    "\n",
    "    n = np.shape(reward_traj)[0]  ## number of trajectories\n",
    "    batch_num = np.shape(state_traj)[1] - 1  ## number of (x,r,x') tuples\n",
    "    tau = [(2 * i + 1) / (2 * quantile_num) for i in range(quantile_num)]\n",
    "    \n",
    "    for k in range(n):\n",
    "        for l in range(batch_num):\n",
    "            for i in range(quantile_num):    \n",
    "                s_current = state_traj[k, l]\n",
    "                a_current = action_traj[k, l]\n",
    "                r_current = reward_traj[k, l]\n",
    "                s_next = state_traj[k, l + 1]\n",
    "                a_next = action_traj[k, l + 1]\n",
    "                #j = np.random.randint(0, quantile_num - 1)\n",
    "                #ret_con_quantile[s_current - 1, i] += rate * tau[i] - rate * (\n",
    "                #    r_current + gam * ret_con_quantile[s_next - 1, j] -\n",
    "                #    ret_con_quantile[s_current - 1, i] < 0)\n",
    "                ret_con_quantile[s_current - 1, a_current, i] +=  rate * np.mean(\n",
    "                    [tau[i] - 1 * (r_current + gam * \n",
    "                                      ret_con_quantile[s_next - 1,a_next, j] - \n",
    "                                      ret_con_quantile[s_current - 1, a_current, i] < 0) \n",
    "                     for j in range(quantile_num)] \n",
    "                )\n",
    "\n",
    "    ## output conditional quantiles\n",
    "    return (ret_con_quantile)\n",
    "\n",
    "def QTD_new(state_traj,\n",
    "        action_traj,\n",
    "        reward_traj,\n",
    "        state_card,\n",
    "        action_card,\n",
    "        quantile_num,\n",
    "        gam,\n",
    "        seed,\n",
    "        rate=None,\n",
    "        init_val=None):\n",
    "    # obs_traj: training data\n",
    "    # state_card: cardinality of state space\n",
    "    ## quantile_num: number of target conditional quantiles for each state\n",
    "    # rate: learning rate\n",
    "    # init_val: initial value\n",
    "\n",
    "    if init_val == None:\n",
    "        ret_con_quantile = np.zeros((state_card,action_card, quantile_num))\n",
    "    elif init_value is not None:\n",
    "        ret_con_quantile = init_value\n",
    "    if rate == None:\n",
    "        rate = 0.1\n",
    "\n",
    "    #ret_con_quantile = np.zeros((state_card, quantile_num))\n",
    "    \n",
    "    n = np.shape(reward_traj)[0]  ## number of trajectories\n",
    "    batch_num = np.shape(state_traj)[1] - 1  ## number of (x,a,r,x') tuples\n",
    "    tau = [(2 * i + 1) / (2 * quantile_num) for i in range(quantile_num)]\n",
    "    \n",
    "    for k in range(n):\n",
    "        for l in range(batch_num):\n",
    "            seed+=1\n",
    "            np.random.seed(seed)\n",
    "            s_current = state_traj[k, l]\n",
    "            a_current = action_traj[k, l]\n",
    "            r_current = reward_traj[k, l]\n",
    "            s_next = state_traj[k, l + 1]\n",
    "            a_next = step_new(s_next)[0] #generate according to pi_a\n",
    "            for i in range(quantile_num):    \n",
    "               \n",
    "                #j = np.random.randint(0, quantile_num - 1)\n",
    "                #ret_con_quantile[s_current - 1, i] += rate * tau[i] - rate * (\n",
    "                #    r_current + gam * ret_con_quantile[s_next - 1, j] -\n",
    "                #    ret_con_quantile[s_current - 1, i] < 0)\n",
    "                ret_con_quantile[s_current - 1, a_current, i] +=  rate * np.mean(\n",
    "                    [tau[i] - 1 * (r_current + gam * \n",
    "                                      ret_con_quantile[s_next - 1,a_next, j] - \n",
    "                                      ret_con_quantile[s_current - 1, a_current, i] < 0)\n",
    "                     for j in range(quantile_num)] \n",
    "                )\n",
    "\n",
    "    ## output conditional quantiles\n",
    "    return (ret_con_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc20826e-0c52-4c24-9c18-226163a0946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_percentile(data, weights, perc):\n",
    "\n",
    "    data = np.array(data)\n",
    "    weights = np.array(weights)\n",
    "    idx = np.argsort(data)\n",
    "    data = data[idx] # sort data\n",
    "    weights = weights[idx] # sort weights\n",
    "    cdf = np.cumsum(weights) / np.sum(weights)\n",
    "    count = np.sum([ cdf[i] <= perc for i in range(np.shape(cdf)[0]) ])\n",
    "    #if output=infty return the maximum of V\n",
    "    if data[count]==float('inf'):\n",
    "        count-=1\n",
    "    return(data[count])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b064ff8a-e129-4f6e-8328-66435819abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(data):\n",
    "    n_tr=data[0].shape[0]\n",
    "    horizon=data[0].shape[1]\n",
    "    weight=np.ones(n_tr)\n",
    "    weight_mat=trans_mat_new/trans_mat\n",
    "    for i in range(n_tr):\n",
    "        for j in range(horizon):\n",
    "            \n",
    "            weight[i]*=weight_mat[data[0][i,j]-1,data[1][i,j]]\n",
    "    X=np.hstack((data[0][:,0].reshape(-1, 1),np.array(data[-1]).reshape(-1, 1)))\n",
    "    y=weight.reshape(-1, 1)\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    intercept=model.intercept_.item()\n",
    "    coef=model.coef_.reshape(-1)\n",
    "    return(intercept,coef)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "776dd762-a6eb-42f2-b32a-9ae004b2daa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_calc(intercept,coef,X):\n",
    "    ratio= np.dot(X,coef)+intercept\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ccc7cca-ffc7-4a48-967d-61ba75cb2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_set_f(data,intercept,coef,alp_sc,alp):\n",
    "    x=data[0][:,0]\n",
    "    y=np.array(data[-1])\n",
    "    X=np.hstack((x.reshape(-1, 1),y.reshape(-1, 1)))\n",
    "    n=np.shape(data[0])[0]\n",
    "    quant_interval_lower=np.zeros(2)\n",
    "    quant_interval_upper=np.zeros(2)\n",
    "    ratio=np.dot(X,coef.reshape(-1,1))+intercept\n",
    "    ratio = np.where(ratio < 0, 0, ratio) \n",
    "    conf_hi = np.zeros(2)\n",
    "    conf_lo = np.zeros(2)\n",
    "    ## lower and upper quanitles for each states \n",
    "    for i in range(2):\n",
    "        quant_interval_lower[i]=np.percentile(y[x==i+1],alp_sc/2*100)\n",
    "        quant_interval_upper[i]=np.percentile(y[x==i+1],(1-alp_sc/2)*100)\n",
    "\n",
    "    score=np.zeros((n,2))  \n",
    "    \n",
    "    for i in range(n):\n",
    "        score[i,0]=quant_interval_lower[x[i]-1]-y[i]\n",
    "        score[i,1]=y[i]-quant_interval_upper[x[i]-1]\n",
    "    for i in range(2):\n",
    "        conf_lo[i] = quant_interval_lower[i]-weighted_percentile(score[:,0],ratio,1-alp/2)\n",
    "        conf_hi[i] = quant_interval_upper[i]+weighted_percentile(score[:,1],ratio,1-alp/2)\n",
    "    return [conf_lo,conf_hi]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "098c312d-6396-488e-838b-a550582fdfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(data_test,conf_lo,conf_hi):\n",
    "    n=np.shape(data_test[0])[0]\n",
    "    acc=0\n",
    "    for i in range(n):\n",
    "        if data_test[-1][i]>conf_lo[data_test[0][i]-1] and data_test[-1][i]<conf_hi[data_test[0][i]-1]:\n",
    "            acc+=1\n",
    "    return acc/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ae5ff8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:26.154742Z",
     "start_time": "2025-03-20T03:57:26.150664Z"
    }
   },
   "outputs": [],
   "source": [
    "## calculate V estimator based on QTD output\n",
    "def q_hat_f(G_quan):\n",
    "    return (np.mean(G_quan, axis=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03c1b56a-2a83-4c57-9078-cd6ec57a0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CQR_quantile(alp,G_quan):\n",
    "    s=np.shape(G_quan)[0]\n",
    "    quan_num=np.shape(G_quan)[2]\n",
    "    res=np.zeros((s,np.shape(G_quan)[1]))\n",
    "    for i in range(s):\n",
    "        data_aug=np.hstack([G_quan[i,0],G_quan[i,1]])\n",
    "        weight_aug=np.hstack([np.ones(quan_num)*trans_mat_new[i,0],np.ones(quan_num)*trans_mat_new[i,1]])\n",
    "        res[i,0]=weighted_percentile(data_aug, weight_aug, alp/2)\n",
    "        res[i,1]=weighted_percentile(data_aug, weight_aug, 1-alp/2)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b17fece-abe7-40fd-9e3c-8f0ec007bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_set(s_traj, r_traj,G_quan,gam,step_forward,alp_sc,alp):\n",
    "     \n",
    "    cqr_quan=CQR_quantile(alp_sc,G_quan)\n",
    "    n=np.shape(s_traj)[0]\n",
    "    u = np.random.randint(0, np.shape(G_quan)[2], size=n)\n",
    "    x=s_traj[:,0]\n",
    "    y=np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0)+[gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] for i in range(n)]\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    conf_lo=np.zeros(2)\n",
    "    conf_hi=np.zeros(2)\n",
    "    score=np.zeros((n,2))  \n",
    "    \n",
    "    for i in range(n):\n",
    "        score[i,0]=cqr_quan[x[i]-1,0]-y[i]\n",
    "        score[i,1]=y[i]-cqr_quan[x[i]-1,1]\n",
    "    for i in range(2):\n",
    "        conf_lo[i] = cqr_quan[i,0]-weighted_percentile(score[:,0],np.ones(n),1-alp/2)\n",
    "        conf_hi[i] = cqr_quan[i,1]+weighted_percentile(score[:,1],np.ones(n),1-alp/2)\n",
    "    return [conf_lo,conf_hi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e40e077f-df63-4adc-8157-10ad34f3d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregation(conf_lo,conf_hi,data_test,xi):\n",
    "    PI_lower = np.zeros(n_te)\n",
    "    PI_upper = np.zeros(n_te)\n",
    "    covs = np.zeros(n_te)\n",
    "    lens = np.zeros(n_te)\n",
    "    s_te = data_test[0][:,0]\n",
    "    ret_te = np.array(data_test[-1])\n",
    "    B=np.shape(conf_lo)[0]\n",
    "    conf_1_lo = conf_lo[:,0]\n",
    "    conf_1_hi = conf_hi[:,0]\n",
    "    conf_2_lo = conf_lo[:,1]\n",
    "    conf_2_lo = conf_hi[:,1]\n",
    "    for j in range(n_te):\n",
    "        \n",
    "        Gs = list(conf_lo[:,s_te[j]-1]) + list(conf_hi[:,s_te[j]-1])\n",
    "        Ws = [1 for i in range(2 * B)]\n",
    "        Ss = [1 for i in range(B)] + list(np.zeros(B))\n",
    "        tol = B *(1-xi)\n",
    "        ind = np.argsort(Gs)\n",
    "        Gs = [Gs[i] for i in ind]  ## ordered YS\n",
    "        Ws = [Ws[i] for i in ind]  ## pure 1\n",
    "        Ss = [Ss[i] for i in ind]  ## left 1 right 0\n",
    "        count = 0\n",
    "        leftpoints = None\n",
    "        rightpoints = None\n",
    "\n",
    "        for i in range(2 * B):\n",
    "            if Ss[i] == 1:\n",
    "                count = count + Ws[i]\n",
    "                if count > tol and count - Ws[i] <= tol:\n",
    "                    leftpoints = Gs[i]\n",
    "            elif Ss[i] == 0:\n",
    "                if count > tol and count - Ws[i] <= tol:\n",
    "                    rightpoints = Gs[i]\n",
    "                count = count - Ws[i]\n",
    "    \n",
    "        PI_lower[j] = leftpoints\n",
    "        PI_upper[j] = rightpoints\n",
    "        covs[j] = ret_te[j] >= leftpoints and ret_te[j] <= rightpoints\n",
    "        lens[j] = rightpoints - leftpoints\n",
    "    cov=np.mean(covs)\n",
    "    len=np.mean(lens)\n",
    "    return cov, len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c02206d-9e4e-4aac-be2e-b7ce3ddfadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate pi_a(a|x)\n",
    "p1=(trans_mat_new[0,1]/trans_mat_new[0,0])*(trans_mat[0,0]/trans_mat[0,1])\n",
    "a1=p1/(1+p1)\n",
    "p2=(trans_mat_new[1,1]/trans_mat_new[1,0])*(trans_mat[1,0]/trans_mat[1,1])\n",
    "a2=p2/(1+p2)\n",
    "def step_a(last_obs):\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=a1)\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=a2)\n",
    "\n",
    "    return (a)\n",
    "    \n",
    "vec_step=np.vectorize(step_a)\n",
    "mat=np.array([[1-a1,a1],[1-a2,a2]])\n",
    "weight_mat=trans_mat_new/trans_mat\n",
    "def weight_calculation_clip(s_vec, a_vec,clip):\n",
    "    weight=1\n",
    "    step=np.shape(s_vec)[0]-1\n",
    "    for i in range(step):\n",
    "        weight*=weight_mat[s_vec[i]-1,a_vec[i]]\n",
    "    weight=max(min(clip[1],weight),clip[0])\n",
    "    return(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfddf9eb-fc8c-4f07-9a67-6bfec1ea4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replay buffer+propensity score ratio\n",
    "def replay_buffer(s_traj, a_traj, r_traj,step_forward,ratio,clip):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward \n",
    "    Mem_state = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action_a = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    idx_weight=[]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action_a[(i*p+j),:] = vec_step(s_traj[i,j:(j+step_forward+1)])\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "            idx_weight.append(\n",
    "            weight_calculation_clip(Mem_state[(i*p+j), :], Mem_action[(i*p+j), :],clip) * ratio[Mem_state[(i*p+j), 0]-1]\n",
    "            )\n",
    "\n",
    "    total = np.array(idx_weight).sum()\n",
    "    idx_weight_final=np.array(idx_weight)/total\n",
    "    return([Mem_state,Mem_action,Mem_reward,idx_weight_final])\n",
    "\n",
    "##ratio of frequency of s_0/s_rb\n",
    "def rb(s_traj, a_traj, r_traj,step_forward):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward \n",
    "    Mem_state = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action_a = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action_a[(i*p+j),:] = vec_step(s_traj[i,j:(j+step_forward+1)])\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "    ratio_1=n*p/(2*n*p-np.sum(Mem_state[:,0]))\n",
    "    ratio_2=n*p/(np.sum(Mem_state[:,0])-n*p)\n",
    "    return([ratio_1,ratio_2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbbd0713-3728-4639-8385-a09b9d29be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(s_traj, r_traj,step_forward,gam,G_quan,v_hat):\n",
    "    # s_traj: state trajectory\n",
    "    # r_traj: reward trajectory\n",
    "    # step_forward: number of steps used in approximating return\n",
    "    # gam: discount\n",
    "    if np.shape(s_traj)[1]!=step_forward+1:\n",
    "        print(\"length dismatch\")\n",
    "    if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "        print(\"height dismatch\")\n",
    "    \n",
    "    quan_num = np.shape(G_quan)[2]\n",
    "    n = np.shape(s_traj)[0]\n",
    "    u = np.random.randint(0, quan_num - 1, size=n)\n",
    "    sc = list(\n",
    "        map(\n",
    "            abs,\n",
    "            np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] -\n",
    "                v_hat[s_traj[i, 0] - 1] for i in range(n)\n",
    "            ]))\n",
    "\n",
    "    return (sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d7d75f1-f499-4e24-acc5-0e5bcbc1044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_CQR(s_traj, r_traj,step_forward,gam,G_quan,CQR_quan):\n",
    "    if np.shape(s_traj)[1]!=step_forward+1:\n",
    "        print(\"length dismatch\")\n",
    "    if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "        print(\"height dismatch\")\n",
    "    \n",
    "    quan_num = np.shape(G_quan)[2]\n",
    "    n = np.shape(s_traj)[0]\n",
    "    u = np.random.randint(0, quan_num - 1, size=n)\n",
    "    sc = list(\n",
    "        map(\n",
    "            max,\n",
    "            zip(\n",
    "            -np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                 \n",
    "                CQR_quan[s_traj[i, 0] - 1,0]-gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] \n",
    "                for i in range(n)\n",
    "            ],\n",
    "                \n",
    "            np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] -\n",
    "                CQR_quan[s_traj[i, 0] - 1,1] for i in range(n)\n",
    "            ]   \n",
    "                \n",
    "                \n",
    "                \n",
    "            )))\n",
    "\n",
    "    return (sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785db874",
   "metadata": {},
   "source": [
    "## 重复实验500次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40eb6eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:33.791316Z",
     "start_time": "2025-03-20T03:59:33.787823Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d3775cd-1d0b-43f3-845b-9035a58057d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_rb_res(data_train, data_test, gam, alp, alp_sc, step_forward, QTD_para,B,tau,seed,sample_size,clip):\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    s_te = data_test[0]\n",
    "    a_init_te = data_test[1]\n",
    "    ret_te = data_test[3]\n",
    "    \n",
    "    ## split training data\n",
    "    idx_perm = np.random.permutation(list(range(0, n_tr)))\n",
    "    idx_tr, idx_cal = [idx_perm[0:int(n_tr / 2)], idx_perm[int(n_tr / 2):n_tr]]\n",
    "    s_train_fold = data_train[0][idx_tr,:]\n",
    "    a_train_fold = data_train[1][idx_tr,:]\n",
    "    r_train_fold = data_train[2][idx_tr,:]\n",
    "    \n",
    "    ## train return distribution using QTD\n",
    "    G_quan = QTD_new(state_traj=s_train_fold,\n",
    "                 action_traj=a_train_fold,\n",
    "                 reward_traj=r_train_fold,\n",
    "                 state_card=2,\n",
    "                 action_card=2,\n",
    "                 quantile_num=QTD_para[0],\n",
    "                 gam=gam,\n",
    "                 seed=seed,\n",
    "                 rate=QTD_para[1],\n",
    "                 init_val=None)\n",
    "    Q_hat = q_hat_f(G_quan)\n",
    "    v_hat = np.zeros(2)\n",
    "    v_hat[0]=trans_mat_new[0,0]*Q_hat[0,0]+trans_mat_new[0,1]*Q_hat[0,1]\n",
    "    v_hat[1]=trans_mat_new[1,0]*Q_hat[1,0]+trans_mat_new[1,1]*Q_hat[1,1]\n",
    "    CQR_quan = CQR_quantile(alp,G_quan)\n",
    "\n",
    "    \n",
    "    ## replay buffer\n",
    "    l = np.shape(step_forward)[0]\n",
    "    if isinstance(tau, int) == False:\n",
    "        m = np.shape(tau)[0]\n",
    "    elif isinstance(tau, int) == True:\n",
    "        m = 1\n",
    "        \n",
    "    PI_cov = np.zeros((m,l))\n",
    "    PI_len = np.zeros((m,l))\n",
    "\n",
    "            \n",
    "        \n",
    "    for k in range(l):\n",
    "               ## density ratio\n",
    "        ratio=rb(s_traj=data_train[0][idx_tr, :],\n",
    "                    a_traj=data_train[1][idx_tr, :],\n",
    "               r_traj=data_train[2][idx_tr, :],\n",
    "                step_forward=step_forward[k])\n",
    "        \n",
    "        conf_lo_sets=np.zeros((B,2))\n",
    "        conf_hi_sets=np.zeros((B,2))\n",
    "        for i in range(B):\n",
    "            \n",
    "        #n_cal = np.random.choice(a=[j for j in range(np.shape(Mem[0])[0])], p=p,size=200)\n",
    "            Mem = replay_buffer(s_traj=data_train[0][idx_cal, :],\n",
    "                    a_traj=data_train[1][idx_cal, :],\n",
    "                 r_traj=data_train[2][idx_cal, :],\n",
    "                step_forward=step_forward[k],\n",
    "                               ratio=ratio,\n",
    "                               clip=clip)\n",
    "            weight_is=Mem[-1]\n",
    "            n_cal = np.random.choice(range(np.shape(weight_is)[0]),size=sample_size, p=weight_is)\n",
    "            ## calculate nonconformity scores based on calibration set\n",
    "            conf_sets = conf_set(s_traj=Mem[0][n_cal,], \n",
    "                     r_traj=Mem[2][n_cal,],\n",
    "                     G_quan=G_quan,\n",
    "                     gam=gam,\n",
    "                     step_forward=step_forward[k],\n",
    "                     alp_sc=alp_sc,\n",
    "                     alp=alp)\n",
    "            conf_lo_sets[i,:]=conf_sets[0]\n",
    "            conf_hi_sets[i,:]=conf_sets[1]\n",
    "        for z in range(m):\n",
    "            print()\n",
    "            PI_cov[z,k], PI_len[z,k]=aggregation(conf_lo_sets,conf_hi_sets,data_test,tau[z])\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "    return [PI_cov,PI_len]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eeda7bf4-3ae8-478f-aca2-445946564ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foffano(data_train, data_test, gam, alp, alp_sc):\n",
    "    n_tr, n_te = np.shape(data_train[0])[0],  np.shape(data_test[0])[0]\n",
    "    s_init_te = data_test[0]\n",
    "    a_init_te = data_test[1] \n",
    "    ret_te = data_test[-1]\n",
    "\n",
    "    intercept,coef=reg(data_train)\n",
    "    \n",
    "    conf_set=conf_set_f(data=data_train,\n",
    "         intercept=intercept,\n",
    "        coef=coef,\n",
    "        alp_sc=alp_sc,\n",
    "        alp=alp_sc\n",
    "        )\n",
    "    \n",
    "    quan_PI_cov=coverage(data_test,conf_set[0],conf_set[1])\n",
    "    quan_PI_len=np.mean(conf_set[1]-conf_set[0])\n",
    "  \n",
    "    return ([quan_PI_cov, quan_PI_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b2b737c9-5a7b-44fc-bada-4f763172ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel Calculation\n",
    "def run_single_experiment(i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, B, alp, alp_sc, tau, step_forward,sample_size,clip):\n",
    "\n",
    "    data_train = data_gen(N=n_tr,\n",
    "                          T_obs=T_obs,\n",
    "                          T=T,\n",
    "                          gam=gam,\n",
    "                          seed=seed + i,\n",
    "                          s_init=None)\n",
    "\n",
    "\n",
    "    data_test = data_gen_new(N=n_te,\n",
    "                             T_obs=1,\n",
    "                             T=T,\n",
    "                             gam=gam,\n",
    "                             seed=seed + i + 10000,\n",
    "                             s_init=None)\n",
    "\n",
    "    result = new_rb_res(data_train=data_train,\n",
    "                        data_test=data_test,\n",
    "                        gam=gam,\n",
    "                        alp=alp,\n",
    "                        alp_sc=alp_sc,\n",
    "                        step_forward=step_forward,\n",
    "                        QTD_para=QTD_para,\n",
    "                        B=B,\n",
    "                        tau=tau,\n",
    "                        seed=seed + i,\n",
    "                        sample_size=sample_size,\n",
    "                       clip=clip) \n",
    "   \n",
    "    return result  # return [PI_cov_e, PI_len_e]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "869f2ea1-53ff-4e9a-a497-184fc6b204cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=28)]: Using backend LokyBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done  46 out of  50 | elapsed:  1.2min remaining:    5.9s\n",
      "[Parallel(n_jobs=28)]: Done  50 out of  50 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "# Parameter setting\n",
    "rep = 50\n",
    "n_tr = 300\n",
    "gam = 0.8\n",
    "T_obs = 20\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 20\n",
    "QTD_para = [20, 0.1]\n",
    "B = 50\n",
    "alp = 0.1\n",
    "alp_sc = 0.1\n",
    "tau = [0.5,0.6]\n",
    "clip=np.array([0.2,5.0])\n",
    "step_forward = [1, 2]\n",
    "sample_size=100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=28, verbose=1)(\n",
    "    delayed(run_single_experiment)(\n",
    "        i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, B, alp, alp_sc,tau, step_forward, sample_size,clip\n",
    "    ) for i in range(rep)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3a2c245-88de-4b18-93cc-23b83cef9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_new_cov_tau05 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau06 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau05 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau06 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "for i in range(np.shape(results)[0]):\n",
    "    rb_new_cov_tau05[i, :] = results [i][0][0]\n",
    "    rb_new_cov_tau06[i, :] = results [i][0][1] \n",
    "\n",
    "\n",
    "\n",
    "    rb_new_len_tau05[i, :] = results [i][1][0]\n",
    "    rb_new_len_tau06[i, :] = results [i][1][1]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5a47751-83c2-406b-9384-38dd244ba34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new(tau=0.5): \n",
      "coverage probability: \n",
      "[0.9073548387096774, 0.9126451612903226]\n",
      "average length: \n",
      "[7.671753291976457, 7.773955719173105]\n",
      "std-coverage probability: \n",
      "[0.009763914535428448, 0.008723763996844056]\n",
      "std-average length: \n",
      "[0.14746043746456008, 0.12768182000345749]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"new(tau=0.5): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau05[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau05[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])\n",
    "print(\"std-coverage probability: \")\n",
    "print([np.std(rb_new_cov_tau05[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])\n",
    "print(\"std-average length: \")\n",
    "print([np.std(rb_new_len_tau05[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "315a67e5-2782-4352-a484-30f1d41816a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new(tau=0.6): \n",
      "coverage probability: \n",
      "[0.919032258064516, 0.9229032258064518]\n",
      "average length: \n",
      "[7.9090860777166725, 8.022843496213346]\n",
      "std-coverage probability: \n",
      "[0.00801273699895111, 0.0075030344191051625]\n",
      "std-average length: \n",
      "[0.1636792811408967, 0.14754633476568152]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"new(tau=0.6): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau06[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau06[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])\n",
    "print(\"std-coverage probability: \")\n",
    "print([np.std(rb_new_cov_tau06[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])\n",
    "print(\"std-average length: \")\n",
    "print([np.std(rb_new_len_tau06[:,i]) for i in range(np.shape(rb_new_cov_tau05)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee6ca554-25b5-426b-88de-8a49977509e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr = 300\n",
    "gam = 0.8\n",
    "T_obs = 20\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 20\n",
    "rep = 100\n",
    "QTD_para = [20, 0.1]\n",
    "alp = 0.1\n",
    "alp_sc=0.1\n",
    "res_quan_500_qnum10 = np.zeros((rep, 2))\n",
    "\n",
    "# Parallel Calculation\n",
    "def process_iteration(i,n_tr, gam, T_obs, seed, n_te, T, alp,alp_sc):\n",
    " \n",
    "    data_train = data_gen(N=n_tr,\n",
    "                         T_obs=T_obs,\n",
    "                         T=T,\n",
    "                         gam=gam,\n",
    "                         seed=seed+i,\n",
    "                         s_init=None)\n",
    "    \n",
    "\n",
    "    data_test = data_gen_new(N=n_te,\n",
    "                            T_obs=1,\n",
    "                            T=T,\n",
    "                            gam=gam,\n",
    "                            seed=seed + i + 10000,\n",
    "                            s_init=None)\n",
    "    \n",
    "    quan_PI_res1 = foffano(data_train=data_train,\n",
    "                                      data_test=data_test, \n",
    "                                      gam=gam, \n",
    "                                      alp=alp,\n",
    "                                      alp_sc=alp_sc\n",
    "                                      )\n",
    "  \n",
    "    print(f\"test num: {i}\")\n",
    "    print(\"quantile region: \")\n",
    "    print(f\"cov: {quan_PI_res1[0]} | length: {quan_PI_res1[1]}\")\n",
    "    \n",
    "    return quan_PI_res1\n",
    "\n",
    "\n",
    "\n",
    "results_qr = Parallel(n_jobs=30)(delayed(process_iteration)(i, n_tr, gam, T_obs, seed, n_te, T, alp,alp_sc) for i in range(rep))\n",
    "\n",
    "# restore data\n",
    "for i in range(rep):\n",
    "    res_quan_500_qnum10[i, :] = results_qr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77ed9c2e-a942-49c5-9bfe-8af315915683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8483871 , 6.36261743],\n",
       "       [0.84516129, 6.35949009],\n",
       "       [0.8483871 , 6.35949009],\n",
       "       [0.8483871 , 6.3532521 ],\n",
       "       [0.84193548, 6.31423382],\n",
       "       [0.84193548, 6.31454911],\n",
       "       [0.83870968, 6.3095209 ],\n",
       "       [0.83870968, 6.31454911],\n",
       "       [0.83870968, 6.3095209 ],\n",
       "       [0.83870968, 6.3095209 ],\n",
       "       [0.83870968, 6.31432095],\n",
       "       [0.83870968, 6.31432095],\n",
       "       [0.8516129 , 6.52801176],\n",
       "       [0.8483871 , 6.55124495],\n",
       "       [0.8483871 , 6.44806787],\n",
       "       [0.84516129, 6.44806787],\n",
       "       [0.84193548, 6.38430021],\n",
       "       [0.84516129, 6.39565194],\n",
       "       [0.84516129, 6.44661944],\n",
       "       [0.84516129, 6.41120531],\n",
       "       [0.84516129, 6.43106607],\n",
       "       [0.84516129, 6.42214562],\n",
       "       [0.84516129, 6.42214562],\n",
       "       [0.84516129, 6.42214562],\n",
       "       [0.84516129, 6.43106607],\n",
       "       [0.84516129, 6.43106607],\n",
       "       [0.84516129, 6.42214562],\n",
       "       [0.8483871 , 6.43308594],\n",
       "       [0.8483871 , 6.43308594],\n",
       "       [0.84516129, 6.44402626],\n",
       "       [0.84193548, 6.50065738],\n",
       "       [0.84193548, 6.50065738],\n",
       "       [0.84193548, 6.49593165],\n",
       "       [0.84193548, 6.49593165],\n",
       "       [0.84516129, 6.51575479],\n",
       "       [0.8483871 , 6.51575479],\n",
       "       [0.8483871 , 6.50830871],\n",
       "       [0.8516129 , 6.54047475],\n",
       "       [0.8516129 , 6.5794157 ],\n",
       "       [0.8516129 , 6.58701069],\n",
       "       [0.85483871, 6.64343635],\n",
       "       [0.85483871, 6.64343635],\n",
       "       [0.8516129 , 6.63168277],\n",
       "       [0.8516129 , 6.6649352 ],\n",
       "       [0.8516129 , 6.63687804],\n",
       "       [0.8516129 , 6.63687804],\n",
       "       [0.8516129 , 6.63687804],\n",
       "       [0.8516129 , 6.62381642],\n",
       "       [0.85483871, 6.62381642],\n",
       "       [0.85483871, 6.63191176],\n",
       "       [0.85483871, 6.61902973],\n",
       "       [0.85483871, 6.61902973],\n",
       "       [0.85483871, 6.61902973],\n",
       "       [0.85806452, 6.6189214 ],\n",
       "       [0.86129032, 6.6189214 ],\n",
       "       [0.86451613, 6.6308889 ],\n",
       "       [0.86451613, 6.6308889 ],\n",
       "       [0.86129032, 6.6189214 ],\n",
       "       [0.86774194, 6.66906331],\n",
       "       [0.87096774, 6.67790066],\n",
       "       [0.87419355, 6.67790066],\n",
       "       [0.87419355, 6.69301035],\n",
       "       [0.87419355, 6.69301035],\n",
       "       [0.86451613, 6.66833542],\n",
       "       [0.86129032, 6.64095948],\n",
       "       [0.86451613, 6.64095948],\n",
       "       [0.86451613, 6.62022118],\n",
       "       [0.86451613, 6.62022118],\n",
       "       [0.86451613, 6.62022118],\n",
       "       [0.86451613, 6.62022118],\n",
       "       [0.86774194, 6.62239842],\n",
       "       [0.86451613, 6.65336059],\n",
       "       [0.86451613, 6.65358851],\n",
       "       [0.86129032, 6.60661122],\n",
       "       [0.86774194, 6.53128636],\n",
       "       [0.86451613, 6.53128636],\n",
       "       [0.86774194, 6.52485416],\n",
       "       [0.86774194, 6.52485416],\n",
       "       [0.86774194, 6.51842197],\n",
       "       [0.86129032, 6.5241336 ],\n",
       "       [0.85806452, 6.441154  ],\n",
       "       [0.86129032, 6.5241336 ],\n",
       "       [0.86451613, 6.5241336 ],\n",
       "       [0.86451613, 6.55867661],\n",
       "       [0.86451613, 6.55867661],\n",
       "       [0.86451613, 6.53830349],\n",
       "       [0.86129032, 6.5241336 ],\n",
       "       [0.85806452, 6.44954671],\n",
       "       [0.86129032, 6.52824557],\n",
       "       [0.85806452, 6.45673385],\n",
       "       [0.85806452, 6.45673385],\n",
       "       [0.86129032, 6.44873965],\n",
       "       [0.86129032, 6.47669555],\n",
       "       [0.86129032, 6.47669555],\n",
       "       [0.84516129, 6.34503983],\n",
       "       [0.84516129, 6.35240856],\n",
       "       [0.84516129, 6.35863705],\n",
       "       [0.84193548, 6.34441437],\n",
       "       [0.8483871 , 6.35863705],\n",
       "       [0.8483871 , 6.35863705]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_quan_500_qnum10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b906adf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:46:49.188482Z",
     "start_time": "2025-03-19T07:46:49.179093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile region: \n",
      "coverage probability:  0.8539999999999999 |  average length:  6.510429285054148 |  std-cov:  0.009630207417348005 |  std-len:  0.11375181024677512\n"
     ]
    }
   ],
   "source": [
    "print(\"quantile region: \")\n",
    "print(\"coverage probability: \", np.mean(res_quan_500_qnum10[:, 0]),\n",
    "      \"|  average length: \", np.mean(res_quan_500_qnum10[:, 1]),\n",
    "      \"|  std-cov: \", np.std(res_quan_500_qnum10[:, 0]),\n",
    "      \"|  std-len: \", np.std(res_quan_500_qnum10[:, 1])) \n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
