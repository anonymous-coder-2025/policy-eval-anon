{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6400d3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:03.990403Z",
     "start_time": "2025-03-20T03:56:55.070662Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba57fee-7745-4497-ae97-003d9e262f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameter setting\n",
    "trans_mat=np.array([[0.6,0.4],[0.8,0.2]])\n",
    "trans_mat_new=np.array([[0.5,0.5],[0.7,0.3]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ba1eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:07.051758Z",
     "start_time": "2025-03-20T03:57:07.046140Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "###### move one step forward ####\n",
    "#################################\n",
    "\n",
    "\n",
    "def step(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat[0,1])\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        s_next = a + 1  # next state\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        s_next = a + 1\n",
    "\n",
    "    return (a, r, s_next)\n",
    "\n",
    "def step_new(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[0,1])\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        s_next = a + 1  # next state\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        s_next = a + 1\n",
    "\n",
    "    return (a, r, s_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2221da9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:09.800005Z",
     "start_time": "2025-03-20T03:57:09.791357Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#### generate one trajectory ####\n",
    "#################################\n",
    "\n",
    "\n",
    "def gen_traj(T, gam, seed=None, s_init=None):\n",
    "    # seed: random seed\n",
    "    # s_init: initial state\n",
    "    # gam: discount\n",
    "    # T: iterative number\n",
    "\n",
    "    # initialize the state\n",
    "    if seed is None and s_init is None:\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    elif seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    if s_init is not None:\n",
    "        s = s_init\n",
    "\n",
    "    s_traj = [s]\n",
    "    a_traj = []\n",
    "    r_traj = []\n",
    "\n",
    "    ret = 0\n",
    "    for i in range(T):\n",
    "        a, r, s_next = step(s)\n",
    "        s_traj.append(s_next)\n",
    "        a_traj.append(a)\n",
    "        r_traj.append(r)\n",
    "        s = s_next  # update current S as S_next\n",
    "        ret += r * gam**i\n",
    "\n",
    "    ## output state, reward trajectory. return\n",
    "    return [s_traj, a_traj, r_traj, ret]\n",
    "\n",
    "\n",
    "def gen_traj_new(T, gam, seed=None, s_init=None):\n",
    "    # seed: random seed\n",
    "    # s_init: initial state\n",
    "    # gam: discount\n",
    "    # T: iterative number\n",
    "\n",
    "    # initialize the state\n",
    "    if seed is None and s_init is None:\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    elif seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        s = np.random.binomial(1, p=0.5) + 1\n",
    "    if s_init is not None:\n",
    "        s = s_init\n",
    "\n",
    "    s_traj = [s]\n",
    "    a_traj = []\n",
    "    r_traj = []\n",
    "\n",
    "    ret = 0\n",
    "    for i in range(T):\n",
    "        a, r, s_next = step_new(s)\n",
    "        s_traj.append(s_next)\n",
    "        a_traj.append(a)\n",
    "        r_traj.append(r)\n",
    "        s = s_next  # update current S as S_next\n",
    "        ret += r * gam**i\n",
    "\n",
    "    ## output state, reward trajectory. return\n",
    "    return [s_traj, a_traj, r_traj, ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149bfe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:10.570183Z",
     "start_time": "2025-03-20T03:57:10.553870Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#### generate data ####\n",
    "#######################\n",
    "\n",
    "\n",
    "def data_gen(N, T_obs, T, gam, seed=None, s_init=None):\n",
    "    # N: number of trajectories\n",
    "    # T_obs: observed stage numbers\n",
    "\n",
    "    s_data = np.zeros((N, T_obs), dtype=int)\n",
    "    a_data = np.zeros((N, T_obs), dtype=int)\n",
    "    r_data = np.zeros((N, T_obs))\n",
    "    ret_data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if seed is not None:\n",
    "            seed += 1\n",
    "        tmp = gen_traj(T, gam, seed, s_init)\n",
    "        s_data[i] = tmp[0][0:T_obs]  # store the i-th state trajectory\n",
    "        a_data[i] = tmp[1][0:T_obs]\n",
    "        r_data[i] = tmp[2][0:T_obs]  # store the i-th reward trajectory\n",
    "        ret_data.append(tmp[3])\n",
    "\n",
    "    ## output observed state, reward trajectory and true return\n",
    "    return [s_data, a_data ,r_data, ret_data]\n",
    "\n",
    "def data_gen_new(N, T_obs, T, gam, seed=None, s_init=None):\n",
    "    # N: number of trajectories\n",
    "    # T_obs: observed stage numbers\n",
    "\n",
    "    s_data = np.zeros((N, T_obs), dtype=int)\n",
    "    a_data = np.zeros((N, T_obs), dtype=int)\n",
    "    r_data = np.zeros((N, T_obs))\n",
    "    ret_data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if seed is not None:\n",
    "            seed += 1\n",
    "        tmp = gen_traj_new(T, gam, seed, s_init)\n",
    "        s_data[i] = tmp[0][0:T_obs]  # store the i-th state trajectory\n",
    "        a_data[i] = tmp[1][0:T_obs]\n",
    "        r_data[i] = tmp[2][0:T_obs]  # store the i-th reward trajectory\n",
    "        ret_data.append(tmp[3])\n",
    "\n",
    "    ## output observed state, reward trajectory and true return\n",
    "    return [s_data, a_data ,r_data, ret_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa71bb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:11.306634Z",
     "start_time": "2025-03-20T03:57:11.279249Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "## simulation setup ###\n",
    "#######################\n",
    "\n",
    "n_tr = 100\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "\n",
    "data_train = data_gen(N=n_tr,\n",
    "                      T_obs=T_obs,\n",
    "                      T=100,\n",
    "                      gam=gam,\n",
    "                      seed=seed,\n",
    "                      s_init=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7432f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:14.162795Z",
     "start_time": "2025-03-20T03:57:14.156622Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### Quantile temperal difference ###\n",
    "####################################\n",
    "\n",
    "\n",
    "def QTD(state_traj,\n",
    "        action_traj,\n",
    "        reward_traj,\n",
    "        state_card,\n",
    "        action_card,\n",
    "        quantile_num,\n",
    "        gam,\n",
    "        rate=None,\n",
    "        init_val=None):\n",
    "    # obs_traj: training data\n",
    "    # state_card: cardinality of state space\n",
    "    ## quantile_num: number of target conditional quantiles for each state\n",
    "    # rate: learning rate\n",
    "    # init_val: initial value\n",
    "\n",
    "    if init_val == None:\n",
    "        ret_con_quantile = np.zeros((state_card,action_card, quantile_num))\n",
    "    elif init_value is not None:\n",
    "        ret_con_quantile = init_value\n",
    "    if rate == None:\n",
    "        rate = 0.1\n",
    "\n",
    "    #ret_con_quantile = np.zeros((state_card, quantile_num))\n",
    "\n",
    "    n = np.shape(reward_traj)[0]  ## number of trajectories\n",
    "    batch_num = np.shape(state_traj)[1] - 1  ## number of (x,r,x') tuples\n",
    "    tau = [(2 * i + 1) / (2 * quantile_num) for i in range(quantile_num)]\n",
    "    \n",
    "    for k in range(n):\n",
    "        for l in range(batch_num):\n",
    "            for i in range(quantile_num):    \n",
    "                s_current = state_traj[k, l]\n",
    "                a_current = action_traj[k, l]\n",
    "                r_current = reward_traj[k, l]\n",
    "                s_next = state_traj[k, l + 1]\n",
    "                a_next = action_traj[k, l + 1]\n",
    "                #j = np.random.randint(0, quantile_num - 1)\n",
    "                #ret_con_quantile[s_current - 1, i] += rate * tau[i] - rate * (\n",
    "                #    r_current + gam * ret_con_quantile[s_next - 1, j] -\n",
    "                #    ret_con_quantile[s_current - 1, i] < 0)\n",
    "                ret_con_quantile[s_current - 1, a_current, i] +=  rate * np.mean(\n",
    "                    [tau[i] - 1 * (r_current + gam * \n",
    "                                      ret_con_quantile[s_next - 1,a_next, j] - \n",
    "                                      ret_con_quantile[s_current - 1, a_current, i] < 0) \n",
    "                     for j in range(quantile_num)] \n",
    "                )\n",
    "\n",
    "    ## output conditional quantiles\n",
    "    return (ret_con_quantile)\n",
    "\n",
    "def QTD_new(state_traj,\n",
    "        action_traj,\n",
    "        reward_traj,\n",
    "        state_card,\n",
    "        action_card,\n",
    "        quantile_num,\n",
    "        gam,\n",
    "        seed,\n",
    "        rate=None,\n",
    "        init_val=None):\n",
    "    # obs_traj: training data\n",
    "    # state_card: cardinality of state space\n",
    "    ## quantile_num: number of target conditional quantiles for each state\n",
    "    # rate: learning rate\n",
    "    # init_val: initial value\n",
    "\n",
    "    if init_val == None:\n",
    "        ret_con_quantile = np.zeros((state_card,action_card, quantile_num))\n",
    "    elif init_value is not None:\n",
    "        ret_con_quantile = init_value\n",
    "    if rate == None:\n",
    "        rate = 0.1\n",
    "\n",
    "    #ret_con_quantile = np.zeros((state_card, quantile_num))\n",
    "    \n",
    "    n = np.shape(reward_traj)[0]  ## number of trajectories\n",
    "    batch_num = np.shape(state_traj)[1] - 1  ## number of (x,a,r,x') tuples\n",
    "    tau = [(2 * i + 1) / (2 * quantile_num) for i in range(quantile_num)]\n",
    "    \n",
    "    for k in range(n):\n",
    "        for l in range(batch_num):\n",
    "            seed+=1\n",
    "            np.random.seed(seed)\n",
    "            s_current = state_traj[k, l]\n",
    "            a_current = action_traj[k, l]\n",
    "            r_current = reward_traj[k, l]\n",
    "            s_next = state_traj[k, l + 1]\n",
    "            a_next = step_new(s_next)[0] #generate according to pi_a\n",
    "            for i in range(quantile_num):    \n",
    "               \n",
    "                #j = np.random.randint(0, quantile_num - 1)\n",
    "                #ret_con_quantile[s_current - 1, i] += rate * tau[i] - rate * (\n",
    "                #    r_current + gam * ret_con_quantile[s_next - 1, j] -\n",
    "                #    ret_con_quantile[s_current - 1, i] < 0)\n",
    "                ret_con_quantile[s_current - 1, a_current, i] +=  rate * np.mean(\n",
    "                    [tau[i] - 1 * (r_current + gam * \n",
    "                                      ret_con_quantile[s_next - 1,a_next, j] - \n",
    "                                      ret_con_quantile[s_current - 1, a_current, i] < 0)\n",
    "                     for j in range(quantile_num)] \n",
    "                )\n",
    "\n",
    "    ## output conditional quantiles\n",
    "    return (ret_con_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ae5ff8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:26.154742Z",
     "start_time": "2025-03-20T03:57:26.150664Z"
    }
   },
   "outputs": [],
   "source": [
    "## calculate V estimator based on QTD output\n",
    "def q_hat_f(G_quan):\n",
    "    return (np.mean(G_quan, axis=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7046cd6a-0ecb-4397-9e35-b3d2f37c3273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_percentile(data, weights, perc):\n",
    "\n",
    "    data = np.array(data)\n",
    "    weights = np.array(weights)\n",
    "    idx = np.argsort(data)\n",
    "    data = data[idx] # sort data\n",
    "    weights = weights[idx] # sort weights\n",
    "    cdf = np.cumsum(weights) / np.sum(weights)\n",
    "    count = np.sum([ cdf[i] <= perc for i in range(np.shape(cdf)[0]) ])\n",
    "    #if output=infty return the maximum of V\n",
    "    if data[count]==float('inf'):\n",
    "        count-=1\n",
    "    return(data[count])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62ce069a-98ac-4250-b44e-46c017e26703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CQR_quantile(alp,G_quan):\n",
    "    s=np.shape(G_quan)[0]\n",
    "    quan_num=np.shape(G_quan)[2]\n",
    "    res=np.zeros((s,np.shape(G_quan)[1]))\n",
    "    for i in range(s):\n",
    "        data_aug=np.hstack([G_quan[i,0],G_quan[i,1]])\n",
    "        weight_aug=np.hstack([np.ones(quan_num)*trans_mat_new[i,0],np.ones(quan_num)*trans_mat_new[i,1]])\n",
    "        res[i,0]=weighted_percentile(data_aug, weight_aug, alp/2)\n",
    "        res[i,1]=weighted_percentile(data_aug, weight_aug, 1-alp/2)\n",
    "    return (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c02206d-9e4e-4aac-be2e-b7ce3ddfadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算pi_a(a|x)\n",
    "p1=(trans_mat_new[0,1]/trans_mat_new[0,0])*(trans_mat[0,0]/trans_mat[0,1])\n",
    "a1=p1/(1+p1)\n",
    "p2=(trans_mat_new[1,1]/trans_mat_new[1,0])*(trans_mat[1,0]/trans_mat[1,1])\n",
    "a2=p2/(1+p2)\n",
    "def step_a(last_obs):\n",
    "    if last_obs == 1:\n",
    "        a = np.random.binomial(1, p=a1)\n",
    "    elif last_obs == 2:\n",
    "        a = np.random.binomial(1, p=a2)\n",
    "\n",
    "    return (a)\n",
    "    \n",
    "vec_step=np.vectorize(step_a)\n",
    "mat=np.array([[1-a1,a1],[1-a2,a2]])\n",
    "weight_mat=trans_mat_new/trans_mat\n",
    "def weight_calculation_clip(s_vec, a_vec,clip):\n",
    "    weight=1\n",
    "    step=np.shape(s_vec)[0]-1\n",
    "    for i in range(step):\n",
    "        weight*=weight_mat[s_vec[i]-1,a_vec[i]]\n",
    "    weight=max(min(clip[1],weight),clip[0])\n",
    "    return(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfddf9eb-fc8c-4f07-9a67-6bfec1ea4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replay buffer+propensity score ratio\n",
    "def replay_buffer(s_traj, a_traj, r_traj,step_forward,ratio,clip):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward \n",
    "    Mem_state = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action_a = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    idx_weight=[]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action_a[(i*p+j),:] = vec_step(s_traj[i,j:(j+step_forward+1)])\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "            idx_weight.append(\n",
    "            weight_calculation_clip(Mem_state[(i*p+j), :], Mem_action[(i*p+j), :],clip) * ratio[Mem_state[(i*p+j), 0]-1]\n",
    "            )\n",
    "\n",
    "    total = np.array(idx_weight).sum()\n",
    "    idx_weight_final=np.array(idx_weight)/total\n",
    "    return([Mem_state,Mem_action,Mem_reward,idx_weight_final])\n",
    "\n",
    "##ratio of frequency of s_0/s_rb\n",
    "def rb(s_traj, a_traj, r_traj,step_forward):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward \n",
    "    Mem_state = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action_a = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    acc_1=0\n",
    "    acc_2=0\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action_a[(i*p+j),:] = vec_step(s_traj[i,j:(j+step_forward+1)])\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "            if (vec_step(s_traj[i,j:(j+step_forward)])==a_traj[i,j:(j+step_forward)]).all() and Mem_state[(i*p+j),0]==1 :\n",
    "                acc_1+=1\n",
    "            elif (vec_step(s_traj[i,j:(j+step_forward)])==a_traj[i,j:(j+step_forward)]).all() and Mem_state[(i*p+j),0]==2 :\n",
    "                acc_2+=1\n",
    "    ratio_1=(2*n*p-np.sum(Mem_state[:,0]))/acc_1\n",
    "    ratio_2=(np.sum(Mem_state[:,0])-n*p)/acc_2\n",
    "    return([ratio_1,ratio_2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbbd0713-3728-4639-8385-a09b9d29be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(s_traj, r_traj,step_forward,gam,G_quan,v_hat):\n",
    "    # s_traj: state trajectory\n",
    "    # r_traj: reward trajectory\n",
    "    # step_forward: number of steps used in approximating return\n",
    "    # gam: discount\n",
    "    if np.shape(s_traj)[1]!=step_forward+1:\n",
    "        print(\"length dismatch\")\n",
    "    if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "        print(\"height dismatch\")\n",
    "    \n",
    "    quan_num = np.shape(G_quan)[2]\n",
    "    n = np.shape(s_traj)[0]\n",
    "    u = np.random.randint(0, quan_num - 1, size=n)\n",
    "    sc = list(\n",
    "        map(\n",
    "            abs,\n",
    "            np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] -\n",
    "                v_hat[s_traj[i, 0] - 1] for i in range(n)\n",
    "            ]))\n",
    "\n",
    "    return (sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d7d75f1-f499-4e24-acc5-0e5bcbc1044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_CQR(s_traj, r_traj,step_forward,gam,G_quan,CQR_quan):\n",
    "    if np.shape(s_traj)[1]!=step_forward+1:\n",
    "        print(\"length dismatch\")\n",
    "    if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "        print(\"height dismatch\")\n",
    "    \n",
    "    quan_num = np.shape(G_quan)[2]\n",
    "    n = np.shape(s_traj)[0]\n",
    "    u = np.random.randint(0, quan_num - 1, size=n)\n",
    "    sc = list(\n",
    "        map(\n",
    "            max,\n",
    "            zip(\n",
    "            -np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                 \n",
    "                CQR_quan[s_traj[i, 0] - 1,0]-gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] \n",
    "                for i in range(n)\n",
    "            ],\n",
    "                \n",
    "            np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                gam**step_forward * G_quan[s_traj[i, step_forward] - 1, step_new(s_traj[i, step_forward])[0],u[i]] -\n",
    "                CQR_quan[s_traj[i, 0] - 1,1] for i in range(n)\n",
    "            ]   \n",
    "                \n",
    "                \n",
    "                \n",
    "            )))\n",
    "\n",
    "    return (sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785db874",
   "metadata": {},
   "source": [
    "## replicate experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40eb6eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:33.791316Z",
     "start_time": "2025-03-20T03:59:33.787823Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6175ce8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:41.448956Z",
     "start_time": "2025-03-20T03:59:41.435957Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_rb_res(data_train, data_test, gam, alp, step_forward, QTD_para,B,tau,seed,sample_size,clip):\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    s_init_te = data_test[0]\n",
    "    a_init_te = data_test[1]\n",
    "    ret_te = data_test[3]\n",
    "    \n",
    "    ## split training data\n",
    "    idx_perm = np.random.permutation(list(range(0, n_tr)))\n",
    "    idx_tr, idx_cal = [idx_perm[0:int(n_tr / 2)], idx_perm[int(n_tr / 2):n_tr]]\n",
    "    s_train_fold = data_train[0][idx_tr,:]\n",
    "    a_train_fold = data_train[1][idx_tr,:]\n",
    "    r_train_fold = data_train[2][idx_tr,:]\n",
    "    \n",
    "    ## train return distribution using QTD\n",
    "    G_quan = QTD_new(state_traj=s_train_fold,\n",
    "                 action_traj=a_train_fold,\n",
    "                 reward_traj=r_train_fold,\n",
    "                 state_card=2,\n",
    "                 action_card=2,\n",
    "                 quantile_num=QTD_para[0],\n",
    "                 gam=gam,\n",
    "                 seed=seed,\n",
    "                 rate=QTD_para[1],\n",
    "                 init_val=None)\n",
    "    Q_hat = q_hat_f(G_quan)\n",
    "    v_hat = np.zeros(2)\n",
    "    v_hat[0]=trans_mat_new[0,0]*Q_hat[0,0]+trans_mat_new[0,1]*Q_hat[0,1]\n",
    "    v_hat[1]=trans_mat_new[1,0]*Q_hat[1,0]+trans_mat_new[1,1]*Q_hat[1,1]\n",
    "    CQR_quan = CQR_quantile(alp,G_quan)\n",
    "\n",
    "\n",
    "    ## calculate nonconformity scores based on test set\n",
    "    sc_te = [abs(ret_te[i] - v_hat[s_init_te[i, 0] - 1]) for i in range(n_te)]\n",
    "    sc_te_cqr = [max((ret_te[i] - CQR_quan[s_init_te[i, 0] - 1, 1]),CQR_quan[s_init_te[i, 0] - 1, 0] - ret_te[i]  ) for i in range(n_te)]\n",
    "    \n",
    "    ## replay buffer\n",
    "    l = np.shape(step_forward)[0]\n",
    "    if isinstance(tau, int) == False:\n",
    "        m = np.shape(tau)[0]\n",
    "    elif isinstance(tau, int) == True:\n",
    "        m = 1\n",
    "        \n",
    "    PI_cov_e = np.zeros((m,l))\n",
    "    PI_len_e = np.zeros((m,l))\n",
    "    PI_cov_c = np.zeros((m,l))\n",
    "    PI_len_c = np.zeros((m,l))\n",
    "            \n",
    "    p1_s0_estimate = np.mean(s_train_fold[:,0] - 1)\n",
    "\n",
    "            \n",
    "        \n",
    "    for k in range(l):\n",
    "       \n",
    "        ratio=rb(s_traj=data_train[0][idx_tr, :],\n",
    "                    a_traj=data_train[1][idx_tr, :],\n",
    "               r_traj=data_train[2][idx_tr, :],\n",
    "                step_forward=step_forward[k])\n",
    "        ## density ratio\n",
    "        Mem_1 = replay_buffer(s_traj=s_train_fold,\n",
    "                              a_traj=a_train_fold,\n",
    "                              r_traj=r_train_fold,\n",
    "                              step_forward=1,\n",
    "                             ratio=np.ones(2),\n",
    "                             clip=np.ones(2))\n",
    "        p1_rb = np.mean(Mem_1[0][:,0] - 1)\n",
    "        dr_s_e = [((1-p1_s0_estimate)/(1-p1_rb))*ratio[0],(p1_s0_estimate/p1_rb)*ratio[1]]\n",
    "        \n",
    "        quan_B_e = np.zeros((m,n_te,B))\n",
    "        quan_B_c = np.zeros((m,n_te,B))\n",
    "        \n",
    "\n",
    "        for i in range(B):\n",
    "            \n",
    "        #n_cal = np.random.choice(a=[j for j in range(np.shape(Mem[0])[0])], p=p,size=200)\n",
    "            Mem = replay_buffer(s_traj=data_train[0][idx_cal, :],\n",
    "                    a_traj=data_train[1][idx_cal, :],\n",
    "                 r_traj=data_train[2][idx_cal, :],\n",
    "                step_forward=step_forward[k],\n",
    "                               ratio=ratio,\n",
    "                               clip=clip)\n",
    "            weight_is=Mem[-1]\n",
    "            n_cal = np.random.choice(range(np.shape(weight_is)[0]),size=sample_size, p=weight_is)\n",
    "            ## calculate nonconformity scores based on calibration set\n",
    "            sc_rb = scoring(s_traj=Mem[0][n_cal,],\n",
    "                            r_traj=Mem[2][n_cal,],\n",
    "                            step_forward=step_forward[k],\n",
    "                            gam=gam,\n",
    "                            G_quan=G_quan,\n",
    "                            v_hat=v_hat)\n",
    "            sc_cqr = scoring_CQR(s_traj=Mem[0][n_cal,],\n",
    "                            r_traj=Mem[2][n_cal,],\n",
    "                            step_forward=step_forward[k],\n",
    "                            gam=gam,\n",
    "                            G_quan=G_quan,\n",
    "                            CQR_quan=CQR_quan\n",
    "                                )\n",
    "            sc_rb.append(float('inf')) \n",
    "            sc_cqr.append(float('inf')) \n",
    "            for j in range(n_te): \n",
    "                for z in range(m):\n",
    "                    quan_B_e[z][j,i] = weighted_percentile(data=sc_rb,weights=np.ones(sample_size+1),\n",
    "                                                      perc=1-alp)\n",
    "                    quan_B_c[z][j,i] = weighted_percentile(data=sc_cqr,weights=np.ones(sample_size+1),\n",
    "                                                      perc=1-alp)\n",
    "                    \n",
    "        critical_value_rb_e = np.zeros((m,n_te))\n",
    "        critical_value_rb_c = np.zeros((m,n_te))\n",
    "        \n",
    " \n",
    "        for z in range(m):\n",
    "            critical_value_rb_e[z,:] = [ np.percentile(a=quan_B_e[z][k,:],\n",
    "                                                           q=tau[z]*100) for k in range(n_te) ]\n",
    "\n",
    "            critical_value_rb_c[z,:] = [ np.percentile(a=quan_B_c[z][k,:],\n",
    "                                                           q=tau[z]*100) for k in range(n_te) ]\n",
    "\n",
    "            \n",
    "            PI_cov_e[z,k] = np.mean([sc_te[k] <= critical_value_rb_e[z,k] \n",
    "                                         for k in range(n_te)])\n",
    "            PI_len_e[z,k] = 2 * np.mean(critical_value_rb_e[z,:])\n",
    "            PI_cov_c[z,k] = np.mean([sc_te_cqr[k] <= critical_value_rb_c[z,k] \n",
    "                                         for k in range(n_te)])\n",
    "            PI_len_c[z,k] = 2 * np.mean(critical_value_rb_c[z,:]) + np.mean([CQR_quan[s_init_te[i, 0] - 1, 1] - CQR_quan[s_init_te[i, 0] - 1, 0]  for k in range(n_te) ])\n",
    "            \n",
    "            \n",
    "    return(np.array([[PI_cov_e,PI_len_e], [PI_cov_c,PI_len_c]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02f506fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:22:31.005418Z",
     "start_time": "2025-03-19T15:22:31.005418Z"
    }
   },
   "outputs": [],
   "source": [
    "def quantile_region_res(data_train, data_test, gam, alp, QTD_para,seed):\n",
    "\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    s_init_te = data_test[0]\n",
    "    a_init_te = data_test[1] \n",
    "    ret_te = data_test[3]\n",
    "    quant_num = QTD_para[0]\n",
    "    ## train QTD using full training data\n",
    "    G_quan_full = QTD_new(state_traj=data_train[0],\n",
    "                      action_traj=data_train[1],\n",
    "                      reward_traj=data_train[2],\n",
    "                      state_card=2,\n",
    "                      action_card=2,  \n",
    "                      quantile_num=quant_num,\n",
    "                      gam=gam,\n",
    "                      seed=seed,\n",
    "                      rate=QTD_para[1],\n",
    "                      init_val=None)\n",
    "    quant_interval_lower=np.zeros(2)\n",
    "    quant_interval_upper=np.zeros(2)\n",
    "\n",
    "    ## lower and upper quanitles for each states \n",
    "    for i in range(2):\n",
    "        data_aug=np.hstack((G_quan_full[i,0,:], G_quan_full[i,1,:])) \n",
    "        weight_aug=np.hstack((np.ones(quant_num)*trans_mat_new[i,0]/quant_num,np.ones(quant_num)*trans_mat_new[i,1]/quant_num))\n",
    "        quant_interval_lower[i]=weighted_percentile(data_aug,weight_aug,alp/2)\n",
    "        quant_interval_upper[i]=weighted_percentile(data_aug,weight_aug,1-alp/2)\n",
    "                       \n",
    "\n",
    "    ## calculate coverage\n",
    "    t1 = [\n",
    "    ret_te[i] >= quant_interval_lower[s_init_te[i, 0] - 1] for i in range(n_te)\n",
    "    ]\n",
    "    t2 = [\n",
    "    ret_te[i] <= quant_interval_upper[s_init_te[i, 0] - 1] for i in range(n_te)\n",
    "    ]\n",
    "    quan_PI_cov = np.mean([all([t1[i], t2[i]]) for i in range(n_te)])\n",
    "    quan_PI_len = np.mean([\n",
    "        quant_interval_upper[s_init_te[i, 0] - 1] -\n",
    "        quant_interval_lower[s_init_te[i, 0] - 1] for i in range(n_te)\n",
    "        ])\n",
    "\n",
    "    return ([quan_PI_cov, quan_PI_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2b737c9-5a7b-44fc-bada-4f763172ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel Calculation\n",
    "def run_single_experiment(i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, B, alp, tau, step_forward,sample_size,clip):\n",
    "\n",
    "    data_train = data_gen(N=n_tr,\n",
    "                          T_obs=T_obs,\n",
    "                          T=T,\n",
    "                          gam=gam,\n",
    "                          seed=seed + i,\n",
    "                          s_init=None)\n",
    "\n",
    "\n",
    "    data_test = data_gen_new(N=n_te,\n",
    "                             T_obs=1,\n",
    "                             T=T,\n",
    "                             gam=gam,\n",
    "                             seed=seed + i + 10000,\n",
    "                             s_init=None)\n",
    "\n",
    "    result = new_rb_res(data_train=data_train,\n",
    "                        data_test=data_test,\n",
    "                        gam=gam,\n",
    "                        alp=alp,\n",
    "                        step_forward=step_forward,\n",
    "                        QTD_para=QTD_para,\n",
    "                        B=B,\n",
    "                        tau=tau,\n",
    "                        seed=seed + i,\n",
    "                        sample_size=sample_size,\n",
    "                       clip=clip)\n",
    "   \n",
    "    return result  # return [PI_cov_e, PI_len_e]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "869f2ea1-53ff-4e9a-a497-184fc6b204cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=26)]: Using backend LokyBackend with 26 concurrent workers.\n",
      "[Parallel(n_jobs=26)]: Done  50 out of  50 | elapsed: 54.8min finished\n"
     ]
    }
   ],
   "source": [
    "# Parameter setting\n",
    "rep = 50\n",
    "n_tr = 400\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 70\n",
    "QTD_para = [20, 0.1]\n",
    "B = 100\n",
    "alp = 0.1\n",
    "tau = [0.5,0.6,0.7,0.8,0.9]\n",
    "clip=np.array([0.2,5.0])\n",
    "step_forward = [1, 2, 3,4,5]\n",
    "sample_size=400\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=26, verbose=1)(\n",
    "    delayed(run_single_experiment)(\n",
    "        i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, B, alp, tau, step_forward, sample_size,clip\n",
    "    ) for i in range(rep)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0fb3b866-a784-424c-90b8-c3d63f798519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.89677419, 0.90322581, 0.90322581, 0.90322581, 0.90322581])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "30500b6f-eecd-4a06-81ef-62fd05e6bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rb_new_cov_tau05_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau06_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau07_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau08_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau09_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau05_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau06_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau07_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau08_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau09_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "\n",
    "rb_new_len_tau05_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau06_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau07_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau08_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau09_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau05_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau06_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau07_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau08_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau09_c3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "\n",
    "\n",
    "#Restore data\n",
    "for i in range(np.shape(results)[0]):\n",
    "    rb_new_cov_tau05_e3[i, :] = results [i][0][0][0]\n",
    "    rb_new_cov_tau06_e3[i, :] = results [i][0][0][1]\n",
    "    rb_new_cov_tau07_e3[i, :] = results [i][0][0][2]\n",
    "    rb_new_cov_tau08_e3[i, :] = results [i][0][0][3]\n",
    "    rb_new_cov_tau09_e3[i, :] = results [i][0][0][4]\n",
    "    rb_new_cov_tau05_c3[i, :] = results [i][1][0][0]\n",
    "    rb_new_cov_tau06_c3[i, :] = results [i][1][0][1]\n",
    "    rb_new_cov_tau07_c3[i, :] = results [i][1][0][2]\n",
    "    rb_new_cov_tau08_c3[i, :] = results [i][1][0][3]\n",
    "    rb_new_cov_tau09_c3[i, :] = results [i][1][0][4]\n",
    "\n",
    "\n",
    "\n",
    "    rb_new_len_tau05_e3[i, :] = results [i][0][1][0]\n",
    "    rb_new_len_tau06_e3[i, :] = results [i][0][1][1]\n",
    "    rb_new_len_tau07_e3[i, :] = results [i][0][1][2]\n",
    "    rb_new_len_tau08_e3[i, :] = results [i][0][1][3]\n",
    "    rb_new_len_tau09_e3[i, :] = results [i][0][1][4]\n",
    "    rb_new_len_tau05_c3[i, :] = results [i][1][1][0]\n",
    "    rb_new_len_tau06_c3[i, :] = results [i][1][1][1]\n",
    "    rb_new_len_tau07_c3[i, :] = results [i][1][1][2]\n",
    "    rb_new_len_tau08_c3[i, :] = results [i][1][1][3]\n",
    "    rb_new_len_tau09_c3[i, :] = results [i][1][1][4]\n",
    "\n",
    "\n",
    "PI_cov_all = [res[0] for res in results]\n",
    "PI_len_all = [res[1] for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d3ac89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T23:56:51.524066Z",
     "start_time": "2025-03-19T23:56:51.517499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new(tau=0.5): \n",
      "coverage probability: \n",
      "[0.8854193548387098, 0.8949677419354838, 0.8990322580645161, 0.8998709677419354, 0.901032258064516]\n",
      "average length: \n",
      "[7.345789251332047, 7.527736699385553, 7.591523913105704, 7.617437787121841, 7.633841954903639]\n",
      "new(tau=0.6): \n",
      "coverage probability: \n",
      "[0.8893548387096775, 0.8998709677419356, 0.9047096774193548, 0.9059354838709678, 0.9065806451612903]\n",
      "average length: \n",
      "[7.419672341433534, 7.60546178408489, 7.672430586289693, 7.695741294964429, 7.718315209717754]\n",
      "new(tau=0.7): \n",
      "coverage probability: \n",
      "[0.8938709677419354, 0.9056129032258065, 0.9098709677419354, 0.9118064516129032, 0.9119999999999999]\n",
      "average length: \n",
      "[7.504068875714554, 7.6943841995042375, 7.761487934075203, 7.789678237119019, 7.805704300440607]\n",
      "new(tau=0.8): \n",
      "coverage probability: \n",
      "[0.9007096774193549, 0.9125161290322581, 0.9163870967741936, 0.9184516129032257, 0.9198709677419356]\n",
      "average length: \n",
      "[7.606103286530054, 7.792725281603938, 7.859996165452284, 7.89360678105463, 7.910703268638444]\n",
      "new(tau=0.9): \n",
      "coverage probability: \n",
      "[0.9095483870967742, 0.921032258064516, 0.9243225806451614, 0.925225806451613, 0.9269677419354838]\n",
      "average length: \n",
      "[7.73536296820114, 7.937066617085657, 8.000863366423175, 8.034573914450748, 8.046813787112685]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(\"new(tau=0.5): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau05_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau05_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.6): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau06_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau06_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.7): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau07_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau07_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.8): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau08_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau08_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "\n",
    "print(\"new(tau=0.9): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau09_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau09_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c122dac-4dcf-4532-9f4b-6bebebae52df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new(tau=0.5): \n",
      "coverage probability: \n",
      "[0.8923870967741935, 0.8983870967741936, 0.9016129032258065, 0.9018064516129032, 0.9025806451612902]\n",
      "average length: \n",
      "[7.3557549944269205, 7.504955885529669, 7.5676093314613935, 7.565621839564374, 7.582240681034324]\n",
      "new(tau=0.6): \n",
      "coverage probability: \n",
      "[0.8953548387096774, 0.902, 0.9058064516129031, 0.905548387096774, 0.9065806451612903]\n",
      "average length: \n",
      "[7.433492506936812, 7.589868212387205, 7.654981831947721, 7.646651641679553, 7.667079998608845]\n",
      "new(tau=0.7): \n",
      "coverage probability: \n",
      "[0.8977419354838709, 0.9067096774193548, 0.9104516129032258, 0.9096774193548387, 0.9113548387096775]\n",
      "average length: \n",
      "[7.512933505270488, 7.677102466595763, 7.74353349694107, 7.73352535064873, 7.750900159162187]\n",
      "new(tau=0.8): \n",
      "coverage probability: \n",
      "[0.9029032258064515, 0.9123225806451611, 0.9172258064516129, 0.9173548387096774, 0.9175483870967741]\n",
      "average length: \n",
      "[7.6178597171025215, 7.786373561940102, 7.856812116541559, 7.84650303183024, 7.856703493884708]\n",
      "new(tau=0.9): \n",
      "coverage probability: \n",
      "[0.9114838709677419, 0.9212258064516129, 0.9249677419354839, 0.9243870967741935, 0.9246451612903226]\n",
      "average length: \n",
      "[7.762398242214325, 7.934298811665793, 8.007524325993435, 8.001764666626377, 8.003840878817137]\n"
     ]
    }
   ],
   "source": [
    "print(\"new(tau=0.5): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau05_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau05_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.6): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau06_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau06_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.7): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau07_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau07_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.8): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau08_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau08_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "\n",
    "print(\"new(tau=0.9): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau09_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau09_c3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7091ce2-47fc-4506-a445-78a08edc392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau05_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau05_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau05_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau05_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau05_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_05.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau05_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau05_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau05_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau05_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau05_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_05.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b4ebfc5-94b3-459b-b871-9b171f07ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau05_c3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau05_c3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau05_c3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau05_c3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau05_c3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_cqr_05.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau05_c3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau05_c3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau05_c3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau05_c3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau05_c3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_cqr_05.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f301934-ac2d-4e63-912a-4afdb871ebea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau06_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau06_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau06_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau06_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau06_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_06.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau06_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau06_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau06_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau06_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau06_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_06.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c5cb816-647f-4bc8-b308-b67951772cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau06_c3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau06_c3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau06_c3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau06_c3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau06_c3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_cqr_06.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau06_c3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau06_c3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau06_c3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau06_c3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau06_c3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_cqr_06.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86b2d07d-b47f-438c-9b5e-07aadd3de641",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau07_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau07_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau07_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau07_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau07_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_07.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau07_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau07_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau07_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau07_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau07_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_07.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8a4b4224-8800-4c81-a95c-4005a2eb03f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau07_c3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau07_c3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau07_c3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau07_c3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau07_c3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_cqr_07.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau07_c3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau07_c3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau07_c3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau07_c3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau07_c3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_cqr_07.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88046857-69d6-40c1-ab03-6fc407e1b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau08_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau08_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau08_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau08_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau08_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_08.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau08_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau08_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau08_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau08_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau08_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_08.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0fb1cbc6-6167-4b4c-bd2b-85e9c704d35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau08_c3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau08_c3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau08_c3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau08_c3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau08_c3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_cqr_08.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau08_c3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau08_c3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau08_c3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau08_c3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau08_c3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_cqr_08.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8aa5cfd-ed3c-41ab-8ef9-a7a620c2c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau09_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau09_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau09_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau09_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau09_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_09.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau09_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau09_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau09_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau09_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau09_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_09.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "53691fe0-d516-40e5-a40e-6b5eb4e8bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau09_c3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau09_c3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau09_c3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau09_c3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau09_c3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_simple_cqr_09.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau09_c3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau09_c3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau09_c3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau09_c3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau09_c3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_simple_cqr_09.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a08941fe-d831-4131-b12b-d2c8c90f7e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr = 400\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 70\n",
    "rep = 100\n",
    "QTD_para = [20, 0.1]\n",
    "alp = 0.1\n",
    "\n",
    "res_quan_500_qnum10 = np.zeros((rep, 2))\n",
    "\n",
    "# Parallel Calculation\n",
    "def process_iteration(i,n_tr, gam, T_obs, seed, n_te, T, QTD_para, alp, tau):\n",
    " \n",
    "    data_train = data_gen(N=n_tr,\n",
    "                         T_obs=T_obs,\n",
    "                         T=T,\n",
    "                         gam=gam,\n",
    "                         seed=seed+i,\n",
    "                         s_init=None)\n",
    "    \n",
    "\n",
    "    data_test = data_gen_new(N=n_te,\n",
    "                            T_obs=1,\n",
    "                            T=T,\n",
    "                            gam=gam,\n",
    "                            seed=seed + i + 10000,\n",
    "                            s_init=None)\n",
    "    \n",
    "\n",
    "    quan_PI_res1 = quantile_region_res(data_train=data_train,\n",
    "                                      data_test=data_test, \n",
    "                                      gam=gam, \n",
    "                                      alp=alp,\n",
    "                                      QTD_para=QTD_para,\n",
    "                                      seed=seed+i)\n",
    "    \n",
    "    print(f\"test num: {i}\")\n",
    "    print(\"quantile region: \")\n",
    "    print(f\"cov: {quan_PI_res1[0]} | length: {quan_PI_res1[1]}\")\n",
    "    \n",
    "    return quan_PI_res1\n",
    "\n",
    "\n",
    "\n",
    "results_qr = Parallel(n_jobs=30)(delayed(process_iteration)(i, n_tr, gam, T_obs, seed, n_te, T, QTD_para, alp, tau) for i in range(rep))\n",
    "\n",
    "# restore data\n",
    "for i in range(rep):\n",
    "    res_quan_500_qnum10[i, :] = results_qr[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b055a675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:47:46.618942Z",
     "start_time": "2025-03-19T07:47:46.550210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantile region\n",
      "0         0.864516\n",
      "1         0.877419\n",
      "2         0.864516\n",
      "3         0.864516\n",
      "4         0.858065\n",
      "   quantile region\n",
      "0         6.990484\n",
      "1         7.243581\n",
      "2         6.945185\n",
      "3         6.941258\n",
      "4         6.875847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "##### save simulation result\n",
    "data_quan_cov = {\n",
    "    'quantile region': res_quan_500_qnum10[:, 0]\n",
    "}\n",
    "\n",
    "df_cov = pd.DataFrame(data_quan_cov)\n",
    "\n",
    "df_cov.to_excel('QR_cov_simple_off.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_quan_len = {\n",
    "    'quantile region': res_quan_500_qnum10[:, 1]\n",
    "}\n",
    "\n",
    "df_len = pd.DataFrame(data_quan_len)\n",
    "\n",
    "df_len.to_excel('QR_len_simple_off.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "print(df_cov.head())\n",
    "print(df_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b906adf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:46:49.188482Z",
     "start_time": "2025-03-19T07:46:49.179093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile region: \n",
      "coverage probability:  0.888 |  average length:  7.2640579569888\n"
     ]
    }
   ],
   "source": [
    "print(\"quantile region: \")\n",
    "print(\"coverage probability: \", np.mean(res_quan_500_qnum10[:, 0]),\n",
    "      \"|  average length: \", np.mean(res_quan_500_qnum10[:, 1]))\n",
    "\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d3be7",
   "metadata": {},
   "source": [
    "# Plotting simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7c59d47-218e-42d2-81d3-b36efdabaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        k=1       k=2       k=3       k=4       k=5    DRL-QR\n",
      "0  0.883871  0.890323  0.900000  0.890323  0.903226  0.864516\n",
      "1  0.880645  0.896774  0.896774  0.896774  0.896774  0.877419\n",
      "2  0.893548  0.900000  0.900000  0.900000  0.900000  0.864516\n",
      "3  0.893548  0.896774  0.896774  0.906452  0.909677  0.864516\n",
      "4  0.877419  0.883871  0.903226  0.906452  0.909677  0.858065\n",
      "        k=1       k=2       k=3       k=4       k=5    DRL-QR\n",
      "0  7.361889  7.570965  7.603751  7.564340  7.620636  6.990484\n",
      "1  7.355154  7.527859  7.614888  7.674988  7.735537  7.243581\n",
      "2  7.477631  7.714179  7.784218  7.841054  7.783430  6.945185\n",
      "3  7.406987  7.476894  7.554979  7.721526  7.744091  6.941258\n",
      "4  7.395082  7.516494  7.672196  7.679850  7.710134  6.875847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_new_rb_cov = pd.read_excel('cov_simple_06.xlsx')\n",
    "data_new_rb_len = pd.read_excel('len_simple_06.xlsx')\n",
    "data_new_rb_cov.columns = ['k=1', 'k=2', 'k=3' , 'k=4' , 'k=5']\n",
    "data_new_rb_len.columns = ['k=1', 'k=2', 'k=3' , 'k=4' , 'k=5']\n",
    "data_QR_cov = pd.read_excel('QR_cov_simple_off.xlsx')\n",
    "data_QR_len = pd.read_excel('QR_len_simple_off.xlsx')\n",
    "\n",
    "\n",
    "#data_new_rb_cov.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "#data_new_rb_len.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "data_new_rb_cov['DRL-QR'] = data_QR_cov['quantile region']\n",
    "data_new_rb_len['DRL-QR'] = data_QR_len['quantile region']\n",
    "\n",
    "print(data_new_rb_cov.head())\n",
    "print(data_new_rb_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c5f728-f558-4156-970e-d6753583a52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_cov = data_new_rb_cov.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "colors = [\n",
    "    'goldenrod', 'orange', 'gold', 'khaki', 'wheat', 'lightyellow','skyblue'\n",
    "]\n",
    "\n",
    "colors2 = [\n",
    "    'darkseagreen','limegreen' ,'greenyellow','yellowgreen','lightgreen','honeydew','skyblue'\n",
    "]\n",
    "for patch, color in zip(bplot_new_cov.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_cov.yaxis.grid(False)\n",
    "bplot_new_cov.xaxis.grid(False)\n",
    "bplot_new_cov.set_xlabel(\"Method\")\n",
    "bplot_new_cov.set_ylabel(\"Coverage Probability\")\n",
    "\n",
    "plt.axhline(y=0.90, color='red', linestyle='-', linewidth=1)\n",
    "#plt.title(\"tau='flexible', n_tr=400, gam=0.8, quantnum=20, p_s0 estimator\")\n",
    "plt.ylim(0.75,1)\n",
    "#plt.savefig('fig/new_rb_cov_o_gam0.8_nr100_qnum10.png')\n",
    "plt.show()\n",
    "plt.savefig('Ex1_off_oplicy_cp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec311640-5a1c-4031-a58c-52243434c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_len = data_new_rb_len.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "\n",
    "for patch, color in zip(bplot_new_len.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_len.yaxis.grid(False)\n",
    "bplot_new_len.xaxis.grid(False)\n",
    "bplot_new_len.set_xlabel(\"Method\")\n",
    "bplot_new_len.set_ylabel(\"Empirical Length\")\n",
    "\n",
    "#plt.title(\"tau='flexible' n_tr = 400, gam=0.8, quantnum=20, p_s0 estimator\")\n",
    "#plt.savefig('fig/new_len_o_gam0.8_nr100_qnum10.png')\n",
    "plt.show()\n",
    "plt.savefig('Ex1_off_oplicy_al.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
