{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52372680",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# Ex1-high dimensional\n",
    "The state is 50 dimensional, each feature of which is a binary variable.   \n",
    "Denote the first feature of the  state variable as $x_1$. \n",
    "The reward obtained when transitioning from state in which $x_1=1$ is distributed as N (2, 1), and the reward obtained when transitioning from state in which $x_1=2$ is distributed as N (1, 1).    \n",
    "The action space is $\\{0,1\\}$ which is an indicator of transfering $x_1$ of the current state to $2$.  \n",
    "The behaviour policy specifies the probabilities of transferring from $x_1=1$ to $x_1=2$ and $x_1=2$ to $x_1=1$ are 0.4 and 0.8, respectively. The rest features, i.e., $x_2,\\ldots,x_{49},x_{50}$, are binary variables that are drawn uniformly from $\\{1,2\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6400d3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:03.990403Z",
     "start_time": "2025-03-20T03:56:55.070662Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import norm\n",
    "from torch.distributions import Categorical\n",
    "from collections import deque\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0957d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba57fee-7745-4497-ae97-003d9e262f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##parameter setting\n",
    "trans_mat=np.array([[0.6,0.4],[0.8,0.2]])\n",
    "# trans_mat_new=np.array([[0.5,0.5],[0.7,0.3]])\n",
    "trans_mat_new=trans_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ba1eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:07.051758Z",
     "start_time": "2025-03-20T03:57:07.046140Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "###### move one step forward ####\n",
    "#################################\n",
    "\n",
    "# behaviour policy\n",
    "def step(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "    s_next = np.zeros(50, dtype=int)\n",
    "    if last_obs[0] == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat[0,1])  # ation: wheter to transition to x1=2\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        ## next state\n",
    "        s_next[0] = a + 1  \n",
    "        s_next[1:51] = np.random.binomial(1, p=0.5,size=49) + 1\n",
    "    elif last_obs[0] == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        ## next state\n",
    "        s_next[0] = a + 1\n",
    "        s_next[1:50] = np.random.binomial(1, p=0.5,size=49) + 1\n",
    "\n",
    "    return (a, r, s_next)\n",
    "\n",
    "\n",
    "def step_new(last_obs):\n",
    "    # last_obs: last observation of state\n",
    "    s_next = np.zeros(50, dtype=int)\n",
    "    if last_obs[0] == 1:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[0,1])  # ation: wheter to transition to x1=2\n",
    "        r = np.random.normal(2, 1)  # reward at the same stage\n",
    "        ## next state\n",
    "        s_next[0] = a + 1  \n",
    "        s_next[1:51] = np.random.binomial(1, p=0.5,size=49) + 1\n",
    "    elif last_obs[0] == 2:\n",
    "        a = np.random.binomial(1, p=trans_mat_new[1,1])\n",
    "        r = np.random.normal(-1, 1)\n",
    "        ## next state\n",
    "        s_next[0] = a + 1\n",
    "        s_next[1:50] = np.random.binomial(1, p=0.5,size=49) + 1\n",
    "\n",
    "    return (a, r, s_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2221da9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:09.800005Z",
     "start_time": "2025-03-20T03:57:09.791357Z"
    }
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "#### generate one trajectory ####\n",
    "#################################\n",
    "\n",
    "\n",
    "def gen_traj(T, gam, seed=None, s_init=None):\n",
    "    # seed: random seed\n",
    "    # s_init: initial state\n",
    "    # gam: discount\n",
    "    # T: iterative number\n",
    "\n",
    "    # initialize the state\n",
    "    s = np.zeros(50, dtype=int)\n",
    "    if seed is None and s_init is None:\n",
    "        s[0] = np.random.binomial(1, p=0.5) + 1\n",
    "        s[1:50] = np.random.binomial(1, p=0.5,size=49) + 1\n",
    "    elif seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        s[0] = np.random.binomial(1, p=0.5) + 1\n",
    "        s[1:50] = np.random.binomial(1, p=0.5,size=49) + 1\n",
    "    if s_init is not None:\n",
    "        s = s_init\n",
    "    \n",
    "    s_traj = np.zeros((T+1,50), dtype=int)\n",
    "    s_traj[0][0:50] = s\n",
    "    a_traj = []\n",
    "    r_traj = []\n",
    "\n",
    "    ret = 0\n",
    "    for i in range(T):\n",
    "        a, r, s_next = step(s)\n",
    "        s_traj[i+1][0:50] = s_next\n",
    "        a_traj.append(a)\n",
    "        r_traj.append(r)\n",
    "        s = s_next  # update current S as S_next\n",
    "        ret += r * gam**i\n",
    "\n",
    "    ## output state, reward trajectory. return\n",
    "    return [s_traj, a_traj, r_traj, ret]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "149bfe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:10.570183Z",
     "start_time": "2025-03-20T03:57:10.553870Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#### generate data ####\n",
    "#######################\n",
    "\n",
    "# on-policy\n",
    "def data_gen(N, T_obs, T, gam, seed=None, s_init=None):\n",
    "    # N: number of trajectories\n",
    "    # T_obs: observed stage numbers\n",
    "\n",
    "    s_data = np.zeros((N, T_obs,50), dtype=int)\n",
    "    a_data = np.zeros((N, T_obs), dtype=int)\n",
    "    r_data = np.zeros((N, T_obs))\n",
    "    ret_data = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if seed is not None:\n",
    "            seed += 1\n",
    "        tmp = gen_traj(T, gam, seed, s_init)\n",
    "        s_data[i][0:T_obs][0:50] = tmp[0][0:T_obs][0:50]  # store the i-th state trajectory\n",
    "        a_data[i] = tmp[1][0:T_obs]\n",
    "        r_data[i] = tmp[2][0:T_obs]  # store the i-th reward trajectory\n",
    "        ret_data.append(tmp[3])\n",
    "\n",
    "    ## output observed state, reward trajectory and true return\n",
    "    ## the s_data is the state data, which is a tensor. The first axis is observation number, the second time, the third value of state.\n",
    "    return [s_data, a_data ,r_data, ret_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b612d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[1, 2, 2, ..., 1, 2, 2],\n",
       "         [1, 1, 2, ..., 2, 2, 2],\n",
       "         [1, 2, 1, ..., 2, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 2, ..., 2, 2, 1],\n",
       "         [2, 1, 1, ..., 2, 2, 1],\n",
       "         [1, 1, 1, ..., 1, 2, 2]],\n",
       " \n",
       "        [[1, 2, 1, ..., 2, 1, 2],\n",
       "         [2, 1, 2, ..., 1, 1, 2],\n",
       "         [1, 2, 1, ..., 2, 1, 1],\n",
       "         ...,\n",
       "         [1, 2, 1, ..., 2, 1, 1],\n",
       "         [2, 1, 2, ..., 1, 2, 2],\n",
       "         [1, 1, 2, ..., 1, 1, 2]],\n",
       " \n",
       "        [[1, 1, 1, ..., 2, 2, 1],\n",
       "         [1, 1, 2, ..., 1, 2, 1],\n",
       "         [1, 1, 2, ..., 2, 1, 2],\n",
       "         ...,\n",
       "         [2, 2, 1, ..., 1, 2, 1],\n",
       "         [2, 1, 2, ..., 1, 1, 2],\n",
       "         [1, 2, 1, ..., 2, 1, 2]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[2, 1, 1, ..., 1, 1, 2],\n",
       "         [1, 2, 1, ..., 2, 1, 2],\n",
       "         [1, 2, 2, ..., 1, 2, 2],\n",
       "         ...,\n",
       "         [1, 1, 2, ..., 2, 1, 1],\n",
       "         [2, 1, 2, ..., 1, 1, 2],\n",
       "         [2, 1, 1, ..., 2, 1, 2]],\n",
       " \n",
       "        [[2, 1, 2, ..., 1, 2, 1],\n",
       "         [1, 2, 2, ..., 2, 2, 2],\n",
       "         [1, 1, 2, ..., 2, 1, 2],\n",
       "         ...,\n",
       "         [1, 2, 2, ..., 1, 1, 1],\n",
       "         [1, 2, 1, ..., 1, 1, 2],\n",
       "         [2, 1, 1, ..., 1, 1, 1]],\n",
       " \n",
       "        [[2, 1, 1, ..., 1, 1, 1],\n",
       "         [1, 1, 2, ..., 1, 1, 1],\n",
       "         [1, 2, 1, ..., 2, 2, 2],\n",
       "         ...,\n",
       "         [1, 2, 2, ..., 2, 2, 1],\n",
       "         [1, 2, 2, ..., 2, 2, 1],\n",
       "         [1, 1, 2, ..., 2, 1, 1]]]),\n",
       " array([[0, 0, 0, ..., 1, 0, 1],\n",
       "        [1, 0, 1, ..., 1, 0, 1],\n",
       "        [0, 0, 1, ..., 1, 0, 1],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 1, 1, 0],\n",
       "        [0, 0, 0, ..., 0, 1, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0]]),\n",
       " array([[ 4.1008821 ,  1.50012785,  1.11323497, ...,  0.53036013,\n",
       "         -1.11051324,  2.16530577],\n",
       "        [ 1.77705783, -1.32293265,  2.55136676, ...,  0.12232357,\n",
       "         -2.54054424,  1.04810221],\n",
       "        [ 1.39685418,  1.83314979,  2.86013901, ..., -1.88714074,\n",
       "         -1.34542806,  1.84879546],\n",
       "        ...,\n",
       "        [-0.85466444,  2.42085242, -1.39159746, ...,  0.68265095,\n",
       "         -1.95232314, -0.53369297],\n",
       "        [-2.33020617,  1.65879568,  0.83896418, ...,  2.53325269,\n",
       "          2.51285239, -2.69677183],\n",
       "        [-2.71150201,  1.1917055 ,  2.1526741 , ...,  3.87362417,\n",
       "          1.66449471,  1.45623203]]),\n",
       " [10.29055584195567,\n",
       "  4.086905047770976,\n",
       "  6.866667529132379,\n",
       "  7.36189259741371,\n",
       "  1.8511624340845492,\n",
       "  4.131128261493859,\n",
       "  2.8120185022846784,\n",
       "  7.348082612563933,\n",
       "  5.541881136614221,\n",
       "  6.727585372007868,\n",
       "  5.871995527001429,\n",
       "  2.3328889620360593,\n",
       "  6.525865320869808,\n",
       "  3.5549293330610974,\n",
       "  6.375103354252047,\n",
       "  2.1331946281458447,\n",
       "  3.0987530067934355,\n",
       "  7.726763501274069,\n",
       "  1.262747653630025,\n",
       "  4.891936855129588,\n",
       "  3.9234976321865593,\n",
       "  1.3671967117522046,\n",
       "  5.17707184864902,\n",
       "  3.0781898928829237,\n",
       "  6.580230507272602,\n",
       "  5.544156642129922,\n",
       "  -0.2801274825143233,\n",
       "  5.832640870527517,\n",
       "  5.675436830116906,\n",
       "  -1.6541635919530657,\n",
       "  0.6462761868875403,\n",
       "  7.366995736317455,\n",
       "  1.8742832011899566,\n",
       "  8.0144682967072,\n",
       "  2.6957188027830066,\n",
       "  4.519192856545652,\n",
       "  5.658222667333011,\n",
       "  7.751533327027287,\n",
       "  7.513824601035702,\n",
       "  7.016560477975115,\n",
       "  5.858380814785937,\n",
       "  8.62087559476054,\n",
       "  6.886728745768365,\n",
       "  1.9594955467843185,\n",
       "  4.270957589949334,\n",
       "  5.153622826126652,\n",
       "  8.407008885967269,\n",
       "  5.354712677074062,\n",
       "  0.7902317317600511,\n",
       "  2.0627008163784177,\n",
       "  5.937834109682696,\n",
       "  4.737087784169811,\n",
       "  4.30324553771638,\n",
       "  5.889397661392396,\n",
       "  1.444063443360583,\n",
       "  4.472996344420485,\n",
       "  3.455864139451904,\n",
       "  6.000952061676737,\n",
       "  1.2284570041263252,\n",
       "  3.015222536567288,\n",
       "  5.677928502871794,\n",
       "  5.042264216512141,\n",
       "  5.0292492862978975,\n",
       "  3.296832643170277,\n",
       "  1.1630322062680678,\n",
       "  3.550690962547587,\n",
       "  7.597182467857032,\n",
       "  2.9684428291720426,\n",
       "  6.721223841683837,\n",
       "  3.278036646147174,\n",
       "  4.263852532053076,\n",
       "  5.01966622715572,\n",
       "  4.8368728463242725,\n",
       "  1.1684889529055325,\n",
       "  4.018543565665881,\n",
       "  1.3364087594529817,\n",
       "  3.6058562429175014,\n",
       "  5.598098650703213,\n",
       "  3.8093204843227024,\n",
       "  6.685405506266468,\n",
       "  4.985457614127381,\n",
       "  4.919515996885292,\n",
       "  5.078639648828881,\n",
       "  1.4263378249730192,\n",
       "  0.8843086510812079,\n",
       "  2.904052254891114,\n",
       "  6.344928023697669,\n",
       "  0.6846837044702688,\n",
       "  5.4353016274070125,\n",
       "  2.8053763916861225,\n",
       "  8.324028756390794,\n",
       "  6.869396581114772,\n",
       "  3.277290322157273,\n",
       "  4.394927829600613,\n",
       "  5.978657136993451,\n",
       "  -0.4288195882438736,\n",
       "  9.280093787824514,\n",
       "  2.8374059971496277,\n",
       "  5.34371770214817,\n",
       "  7.718597104181811,\n",
       "  3.59933346458955,\n",
       "  3.5509330803900947,\n",
       "  -1.5283841904397155,\n",
       "  5.452085242367271,\n",
       "  6.467581965006572,\n",
       "  4.00013868930684,\n",
       "  1.596177869818738,\n",
       "  3.7276696091512878,\n",
       "  3.401608318756896,\n",
       "  7.607399861635356,\n",
       "  6.353690925457557,\n",
       "  3.1970493841842416,\n",
       "  0.9103495075661306,\n",
       "  2.1808798263205924,\n",
       "  -0.3076800849035558,\n",
       "  1.7917495876055727,\n",
       "  7.351821644998267,\n",
       "  5.280714766944091,\n",
       "  1.8876015815452318,\n",
       "  3.9035639589933635,\n",
       "  6.992697190029636,\n",
       "  4.919859794029025,\n",
       "  4.647685096309823,\n",
       "  5.1022562585344176,\n",
       "  4.529931923330068,\n",
       "  5.760319311711784,\n",
       "  1.7687066682863992,\n",
       "  8.19038339418207,\n",
       "  7.800513554581537,\n",
       "  7.8658395091066975,\n",
       "  5.438167585009417,\n",
       "  5.043466956695621,\n",
       "  0.8819220677280624,\n",
       "  7.2928102077308825,\n",
       "  5.554546350515885,\n",
       "  3.9487985624602757,\n",
       "  2.64928706229552,\n",
       "  7.966819393655609,\n",
       "  5.025198553969407,\n",
       "  2.693433582132634,\n",
       "  11.697076523214278,\n",
       "  1.8199040404187172,\n",
       "  8.450289911076133,\n",
       "  3.5255767219111798,\n",
       "  5.013975883606591,\n",
       "  1.4286721155632904,\n",
       "  -0.1274515470409618,\n",
       "  6.020532895644722,\n",
       "  5.324117672161175,\n",
       "  4.595700385816516,\n",
       "  -1.271003031705855,\n",
       "  6.4056784089564545,\n",
       "  7.634425731095549,\n",
       "  7.445366072663327,\n",
       "  6.2583148933759185,\n",
       "  4.9210491537926915,\n",
       "  2.795881250043772,\n",
       "  7.028601146452195,\n",
       "  2.497943954062514,\n",
       "  6.058043569838785,\n",
       "  3.6389223828598714,\n",
       "  4.966105796523578,\n",
       "  3.0072228155543548,\n",
       "  0.37730213743185576,\n",
       "  4.273071566529961,\n",
       "  7.3573927048160375,\n",
       "  8.393674924857748,\n",
       "  -2.465667780230505,\n",
       "  5.839710277903867,\n",
       "  4.58307574035333,\n",
       "  3.249232751005094,\n",
       "  8.229923939789268,\n",
       "  1.4648285375617747,\n",
       "  5.1776805653038265,\n",
       "  2.058310618387235,\n",
       "  9.496376304393479,\n",
       "  2.631694830363541,\n",
       "  8.0060306088629,\n",
       "  -0.2855632697704568,\n",
       "  5.013978976030258,\n",
       "  0.20489307247625738,\n",
       "  1.3672908574671592,\n",
       "  8.828892661689592,\n",
       "  5.662365512266362,\n",
       "  2.2243879175578187,\n",
       "  5.305752610785588,\n",
       "  6.139992542203878,\n",
       "  2.1047151242356463,\n",
       "  0.6716268738610934,\n",
       "  2.846887044535223,\n",
       "  3.3250942428890373,\n",
       "  2.1127015346460873,\n",
       "  7.689410861373608,\n",
       "  5.139588622848846,\n",
       "  6.383951750794699,\n",
       "  3.7659022352821934,\n",
       "  3.646320245485594,\n",
       "  2.8593055225026394,\n",
       "  6.778427597354849,\n",
       "  6.122913763300702,\n",
       "  7.8001591625727915,\n",
       "  6.522018794450605,\n",
       "  7.949404100101807,\n",
       "  11.566515507583373,\n",
       "  7.930594860669181,\n",
       "  3.3615414004128934,\n",
       "  4.2250335429016594,\n",
       "  4.4241145588744475,\n",
       "  2.9257257979474147,\n",
       "  4.776633977291017,\n",
       "  -0.7820864719847218,\n",
       "  3.7831098983385374,\n",
       "  3.7890043944153544,\n",
       "  4.147902362135197,\n",
       "  6.454100859712746,\n",
       "  8.781147807642048,\n",
       "  3.855422517755428,\n",
       "  7.981919072905908,\n",
       "  7.003656679645433,\n",
       "  6.619460599648545,\n",
       "  6.214959847439781,\n",
       "  2.3499237246267564,\n",
       "  7.008108448292693,\n",
       "  1.057117192239284,\n",
       "  5.213448746194626,\n",
       "  4.605260406651429,\n",
       "  7.548458530028045,\n",
       "  2.6098901246003217,\n",
       "  3.9737117551791625,\n",
       "  1.6196035071051245,\n",
       "  3.9103761861147093,\n",
       "  1.2351047754664821,\n",
       "  7.440154571104058,\n",
       "  6.161790148501742,\n",
       "  4.162804108059386,\n",
       "  7.456060069286774,\n",
       "  6.948603678715827,\n",
       "  4.085059530251497,\n",
       "  4.792600269120299,\n",
       "  8.745436447649892,\n",
       "  4.121135295319939,\n",
       "  3.568007485710711,\n",
       "  6.664377992619018,\n",
       "  2.48623129761973,\n",
       "  4.424861780709649,\n",
       "  7.207009902487193,\n",
       "  7.233931792863691,\n",
       "  4.439294096199068,\n",
       "  -0.6496063802783204,\n",
       "  2.1001891484144983,\n",
       "  7.505074286573208,\n",
       "  8.23773362134608,\n",
       "  6.981919090391319,\n",
       "  5.336389304911184,\n",
       "  -0.4869006960508324,\n",
       "  1.9385632040779424,\n",
       "  -0.17629140520658346,\n",
       "  2.3156107696488433,\n",
       "  3.8883853930886625,\n",
       "  4.647627051512861,\n",
       "  1.6361850648355547,\n",
       "  7.641279131389273,\n",
       "  1.1736163804833422,\n",
       "  0.8644601996559867,\n",
       "  1.2042766251205628,\n",
       "  3.673023811563444,\n",
       "  2.434112786668122,\n",
       "  6.116334610603868,\n",
       "  4.737353607340832,\n",
       "  7.508711481001987,\n",
       "  7.00146504610783,\n",
       "  5.7510676272206345,\n",
       "  9.748724610965558,\n",
       "  6.2139235972516635,\n",
       "  7.55823944605577,\n",
       "  0.8208760865824298,\n",
       "  2.996703463368538,\n",
       "  5.567920409394022,\n",
       "  5.650994922179635,\n",
       "  8.855549211329041,\n",
       "  5.499025588583058,\n",
       "  1.0290035283276087,\n",
       "  4.667469988663874,\n",
       "  6.157333750351929,\n",
       "  8.122214396056041,\n",
       "  1.1541885566012282,\n",
       "  2.471922418031336,\n",
       "  5.415440283491861,\n",
       "  6.47712930416923,\n",
       "  6.94577633660181,\n",
       "  3.485068710552555,\n",
       "  7.235854575469224,\n",
       "  3.84323700255322,\n",
       "  1.6063448760805479,\n",
       "  3.5747879122371446,\n",
       "  5.269108911254516,\n",
       "  3.393458800438805,\n",
       "  1.543119634837249,\n",
       "  1.923516713429463,\n",
       "  9.706899160911044,\n",
       "  10.806482027629043,\n",
       "  5.712425327197094,\n",
       "  1.1136301143982335,\n",
       "  8.653102911483892,\n",
       "  7.668226413057249,\n",
       "  6.586788754330743,\n",
       "  4.462905380295633,\n",
       "  2.5090596520006136,\n",
       "  6.11082947880748,\n",
       "  10.447448359856715,\n",
       "  0.13093609459928793,\n",
       "  1.537754213436634,\n",
       "  4.682927279844633,\n",
       "  6.113104639331888,\n",
       "  6.07703845838607,\n",
       "  6.889842260280679,\n",
       "  7.964121719561694,\n",
       "  6.538400863320472,\n",
       "  2.677978971973692,\n",
       "  2.4282622111217784,\n",
       "  0.14481569489225776,\n",
       "  3.2467187830854143,\n",
       "  7.252991297484198,\n",
       "  3.695267228678847,\n",
       "  8.0082772224586,\n",
       "  3.0307061383655745,\n",
       "  5.360525566331677,\n",
       "  4.461903574336857,\n",
       "  2.765508086074813,\n",
       "  11.773970199286445,\n",
       "  4.928633220713595,\n",
       "  5.426914516016986,\n",
       "  3.7429020703592024,\n",
       "  0.7763488399303465,\n",
       "  7.773751605491573,\n",
       "  4.000251515655926,\n",
       "  7.742731600714966,\n",
       "  4.594326369317116,\n",
       "  3.174893603977687,\n",
       "  2.373294032740073,\n",
       "  8.195222863144748,\n",
       "  3.2948222392409052,\n",
       "  7.244489052313009,\n",
       "  2.842533542990263,\n",
       "  4.623469904831219,\n",
       "  4.125045852475432,\n",
       "  8.412676673020071,\n",
       "  3.007010582032384,\n",
       "  3.191175329285051,\n",
       "  2.181426502549559,\n",
       "  2.425021673808106,\n",
       "  6.012345026727623,\n",
       "  0.5928266808756552,\n",
       "  4.56260939549645,\n",
       "  5.286997186577769,\n",
       "  9.556927816092484,\n",
       "  1.0009784868339042,\n",
       "  5.529013702545653,\n",
       "  2.875981246680303,\n",
       "  4.523049782440399,\n",
       "  2.5311477242141422,\n",
       "  3.7728742675447724,\n",
       "  6.381285261331985,\n",
       "  2.875347453471545,\n",
       "  3.398470307189602,\n",
       "  3.194907901431854,\n",
       "  2.6992297590701906,\n",
       "  6.172219482360252,\n",
       "  5.4307007210432126,\n",
       "  5.72357866431679,\n",
       "  -1.5942232145524489,\n",
       "  1.4006586023459051,\n",
       "  6.70230896652496,\n",
       "  3.3059210140521307,\n",
       "  5.938784104594175,\n",
       "  2.125217071796885,\n",
       "  0.548216586413988,\n",
       "  4.834198051741143,\n",
       "  5.209136657910489,\n",
       "  3.9353692586785662,\n",
       "  4.7557094994768905,\n",
       "  3.799078181457695,\n",
       "  8.12568031313664,\n",
       "  -1.7060901389828789,\n",
       "  2.342327642521835,\n",
       "  4.999025989129716,\n",
       "  2.1563209254400233,\n",
       "  3.5916376590411194,\n",
       "  0.8869172736481277,\n",
       "  1.8461709677360618,\n",
       "  5.654952762541504,\n",
       "  7.208888107482886,\n",
       "  5.605498712800635,\n",
       "  2.056176243299453,\n",
       "  0.5654759974010942,\n",
       "  2.862996493907886,\n",
       "  2.745216736225105,\n",
       "  1.6490956704893431,\n",
       "  3.3380058808167226,\n",
       "  2.8334061579460754]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gen(N=400,T_obs=30,T=70,gam=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46afef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, num_quantiles):\n",
    "        super(QuantileNetwork, self).__init__()\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.action_dim = action_dim\n",
    "        \n",
    "        # Quantile output layer\n",
    "        self.quantiles = nn.Linear(state_dim, action_dim * num_quantiles).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convert input to tensor if needed and move to device\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.FloatTensor(x).to(device)\n",
    "        elif x.device != device:\n",
    "            x = x.to(device)\n",
    "            \n",
    "\n",
    "        quantiles = self.quantiles(x)\n",
    "        return quantiles.view(-1, self.action_dim, self.num_quantiles)\n",
    "\n",
    "class BehaviorPolicyNetwork(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, hidden_size=32):\n",
    "        super(BehaviorPolicyNetwork, self).__init__()\n",
    "        # Policy network architecture\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, action_dim)\n",
    "        ).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Convert input to tensor if needed and move to device\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.FloatTensor(x).to(device)\n",
    "        elif x.device != device:\n",
    "            x = x.to(device)\n",
    "        return self.net(x)\n",
    "    \n",
    "    def get_probs(self, x):\n",
    "        logits = self.forward(x)\n",
    "        return torch.softmax(logits, dim=-1)\n",
    "\n",
    "class QTD_Agent:\n",
    "    def __init__(self, state_dim, action_dim, gamma, lr, num_quantiles, \n",
    "                 behavior_lr, beta, batch_size, pen_lambd):\n",
    "        \n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.gamma = gamma\n",
    "        self.num_quantiles = num_quantiles\n",
    "        self.beta = beta\n",
    "        self.device = device\n",
    "        self.penal_para = pen_lambd \n",
    "        \n",
    "        # Initialize networks and move to GPU\n",
    "        self.net = QuantileNetwork(state_dim, action_dim, num_quantiles).to(device)\n",
    "        self.target_net = QuantileNetwork(state_dim, action_dim, num_quantiles).to(device)\n",
    "        self.target_net.load_state_dict(self.net.state_dict())\n",
    "        \n",
    "        self.behavior_policy = BehaviorPolicyNetwork(state_dim, action_dim).to(device)\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=lr)\n",
    "        self.behavior_optimizer = optim.Adam(self.behavior_policy.parameters(), lr=behavior_lr)\n",
    "        \n",
    "        # Replay buffer\n",
    "        self.buffer = deque(maxlen=100000)\n",
    "        self.batch_size = batch_size\n",
    "        self.quantile_fractions = torch.linspace(0.5/num_quantiles, 1-0.5/num_quantiles, num_quantiles).to(device)\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        self.scheduler=SequentialLR(self.optimizer,\n",
    "            schedulers=[\n",
    "                LinearLR(self.optimizer, start_factor=0.2, end_factor=1.0, total_iters=300),  # Warm-up phase\n",
    "                CosineAnnealingLR(self.optimizer, T_max=700, eta_min=1e-5)                  # Main decay phase\n",
    "            ],\n",
    "            milestones=[300]  # Switch after 300 steps\n",
    "                                   )                \n",
    "        self.behavior__scheduler = LinearLR(self.behavior_optimizer, start_factor=1, end_factor=0.2, total_iters=3000)\n",
    " \n",
    "    def get_target_policy_probs(self, states, actions=None):\n",
    "        with torch.no_grad():\n",
    "            # Define the transition matrix (convert from NumPy to PyTorch tensor)\n",
    "            trans_mat = torch.from_numpy(trans_mat_new).to(device)\n",
    "            \n",
    "            # Get policy probabilities based on states\n",
    "            \n",
    "            states = states[:,0].long() - 1  # Convert to zero-based integer indices\n",
    "            p = trans_mat[states, 1]  # Probability of transitioning to state 2\n",
    "            \n",
    "            # Construct action probability distribution\n",
    "            probs = torch.stack([1-p, p], dim=1)\n",
    "            \n",
    "            if actions is not None:\n",
    "                actions = actions.to(device)\n",
    "            # Ensure actions has shape [batch_size, 1] for gathering\n",
    "                if actions.dim() == 1:\n",
    "                    actions = actions.unsqueeze(1)\n",
    "                return probs.gather(1, actions)  # Shape [batch_size, 1]\n",
    "        return probs  # Return full action probability distribution\n",
    "    \n",
    "    # Polyak averaging for target network update\n",
    "    def update_target(self, tau):\n",
    "        for target_param, param in zip(self.target_net.parameters(), self.net.parameters()):\n",
    "            target_param.data.copy_(tau * param.data + (1-tau) * target_param.data)\n",
    "    \n",
    "    def store_transition(self, state, action, reward, next_state, done, behavior_prob):\n",
    "        # Ensure we store Python scalars or NumPy arrays\n",
    "        if isinstance(state, torch.Tensor):\n",
    "            state = state.cpu().numpy()\n",
    "        if isinstance(next_state, torch.Tensor):\n",
    "            next_state = next_state.cpu().numpy()\n",
    "        self.buffer.append((state, action, reward, next_state, done, behavior_prob))\n",
    "    \n",
    "    def train_behavior_policy(self, states, actions):\n",
    "        probs = self.behavior_policy.get_probs(states)\n",
    "        action_probs = probs.gather(1, actions.unsqueeze(1))\n",
    "        loss = -torch.log(action_probs).mean()\n",
    "        \n",
    "        self.behavior_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.behavior_optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def pseudo_sample_next_actions(self, next_states):\n",
    "        probs = self.get_target_policy_probs(next_states)\n",
    "        probs = torch.clamp(probs, min=1e-5, max=1.0-1e-5)\n",
    "        probs = probs / probs.sum(dim=-1, keepdim=True)\n",
    "        actions = torch.multinomial(probs, num_samples=1)\n",
    "        return actions.squeeze(-1)\n",
    "        \n",
    "    def get_quantiles_for_state(self, state, action=None):\n",
    "        with torch.no_grad():\n",
    "            state_tensor = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "            quantiles = self.net(state_tensor).squeeze(0)  # [action_dim, num_quantiles]\n",
    "            \n",
    "            if action is not None:\n",
    "                return quantiles[action].cpu().numpy()\n",
    "            return quantiles.cpu().numpy()\n",
    "\n",
    "    def train(self):\n",
    "        if len(self.buffer) < self.batch_size:\n",
    "            return 0, 0\n",
    "        \n",
    "        # Sample batch from replay buffer\n",
    "        batch = random.sample(self.buffer, self.batch_size)\n",
    "        states, actions, rewards, next_states, dones, behavior_probs = zip(*batch)\n",
    "        \n",
    "        # Convert to tensors and move to GPU\n",
    "        states = torch.FloatTensor(np.array(states)).to(device)\n",
    "        actions = torch.LongTensor(np.array(actions)).to(device)\n",
    "        rewards = torch.FloatTensor(np.array(rewards)).unsqueeze(-1).to(device)\n",
    "        next_states = torch.FloatTensor(np.array(next_states)).to(device)\n",
    "        dones = torch.FloatTensor(np.array(dones)).unsqueeze(-1).to(device)\n",
    "        behavior_probs = torch.FloatTensor(np.array(behavior_probs)).unsqueeze(-1).to(device)\n",
    "        \n",
    "        # 1. Train behavior policy\n",
    "        behavior_loss = self.train_behavior_policy(states, actions)\n",
    "        \n",
    "        # 2. Calculate importance weights\n",
    "        with torch.no_grad():\n",
    "            current_action_probs = self.get_target_policy_probs(states, actions)\n",
    "            importance_weights = (current_action_probs / behavior_probs+ 1e-5).clamp(0, 1/self.beta)\n",
    "        \n",
    "        # 3. Get current quantile estimates\n",
    "        current_quantiles = self.net(states)\n",
    "        actions = actions.view(-1, 1, 1).expand(-1, -1, self.num_quantiles)\n",
    "        current_quantiles = current_quantiles.gather(1, actions).squeeze(1)\n",
    "        \n",
    "        # 4. Compute target quantiles\n",
    "        with torch.no_grad():\n",
    "            next_actions = self.pseudo_sample_next_actions(next_states)\n",
    "            next_actions = next_actions.view(-1, 1, 1).expand(-1, -1, self.num_quantiles)\n",
    "            \n",
    "            target_quantiles = self.target_net(next_states)\n",
    "            target_quantiles = target_quantiles.gather(1, next_actions).squeeze(1)\n",
    "            target_quantiles = rewards + self.gamma * target_quantiles * (1 - dones)\n",
    "        \n",
    "        # 5. Compute quantile regression loss\n",
    "        diff = target_quantiles.unsqueeze(-1) - current_quantiles.unsqueeze(1)\n",
    "        weight = torch.abs(self.quantile_fractions - (diff.detach() < 0).float())\n",
    "        \n",
    "        l2_reg = sum(p.pow(2).sum() for p in self.net.parameters())\n",
    "        loss = torch.where(\n",
    "            diff.abs() < 1,\n",
    "            0.5 * diff.pow(2) * weight,\n",
    "            (diff.abs() - 0.5) * weight\n",
    "        ) \n",
    "        loss += 0.5 * self.penal_para * l2_reg\n",
    "        loss = (loss * importance_weights.unsqueeze(-1)).mean()\n",
    "    \n",
    "        # 6. Optimize model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.net.parameters(), 2.0)\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step()\n",
    "        \n",
    "        return loss.item(), behavior_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7432f6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:14.162795Z",
     "start_time": "2025-03-20T03:57:14.156622Z"
    }
   },
   "outputs": [],
   "source": [
    "####################################\n",
    "### Quantile temperal difference ###\n",
    "####################################\n",
    "\n",
    "\n",
    "def QTD_new(state_traj,\n",
    "        action_traj,\n",
    "        reward_traj,\n",
    "        state_dim,\n",
    "        action_card,\n",
    "        quantile_num,\n",
    "        gam,\n",
    "        seed,\n",
    "        lr,\n",
    "        behavior_lr,\n",
    "        beta,\n",
    "        batch_size,\n",
    "        tau,\n",
    "        lambd):\n",
    "\n",
    "    agent = QTD_Agent(state_dim = state_dim, action_dim = action_card,gamma=gam,lr=lr,num_quantiles=quantile_num,behavior_lr=behavior_lr,\n",
    "                      beta=beta,batch_size=batch_size,pen_lambd=lambd)\n",
    "    n_tr=np.shape(state_traj)[0]\n",
    "    T_obs=np.shape(state_traj)[1]\n",
    "    for i in range(n_tr):\n",
    "        for j in range(T_obs-1):\n",
    "            with torch.no_grad():   \n",
    "                state = state_traj[i,j]\n",
    "                state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "                action = action_traj[i,j]\n",
    "                behavior_probs = agent.behavior_policy.get_probs(state_tensor)\n",
    "                behavior_prob = behavior_probs[0, action].item()\n",
    "                reward = reward_traj[i,j]\n",
    "                next_state = state_traj[i,j+1]\n",
    "                done=False\n",
    "                behavior_prob = behavior_probs[0, action].item()\n",
    "        \n",
    "            agent.store_transition(state, action, reward, next_state, done, behavior_prob)\n",
    "    for step in range(2001):\n",
    "        loss, behavior_loss = agent.train()\n",
    "        if step % 5 == 0:\n",
    "            agent.update_target(tau=tau)\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb89d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr = 400\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 70\n",
    "B = 50\n",
    "alp = 0.1\n",
    "tau = 0.1\n",
    "quantile_num = 20\n",
    "clip=np.array([0.2,5.0])\n",
    "step_forward = [1, 2, 3,4,5]\n",
    "sample_size=200\n",
    "lr=0.006\n",
    "behavior_lr=0.01\n",
    "beta=0.5\n",
    "batch_size=64\n",
    "lambd=0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7371e057",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_gen(N=n_tr,\n",
    "                          T_obs=T_obs,\n",
    "                          T=T,\n",
    "                          gam=gam,\n",
    "                          seed=seed,\n",
    "                          s_init=None)\n",
    "\n",
    "\n",
    "data_test = data_gen(N=n_te,\n",
    "                         T_obs=1,\n",
    "                         T=T,\n",
    "                         gam=gam,\n",
    "                         seed=seed + 10000,\n",
    "                         s_init=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bc1cdf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\Pytorch\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "agent = QTD_new(state_traj=data_train[0],\n",
    "                    action_traj=data_train[1],\n",
    "                    reward_traj=data_train[2],\n",
    "                    state_dim=50,\n",
    "                    action_card=2,\n",
    "                    quantile_num=quantile_num,\n",
    "                    gam=gam,\n",
    "                    seed=seed,\n",
    "                    lr=lr,\n",
    "                    behavior_lr=behavior_lr,\n",
    "                    beta=beta,\n",
    "                    batch_size=batch_size,\n",
    "                    tau=tau,\n",
    "                    lambd=lambd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae5ff8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:26.154742Z",
     "start_time": "2025-03-20T03:57:26.150664Z"
    }
   },
   "outputs": [],
   "source": [
    "## calculate V estimator based on QTD output\n",
    "def v_hat_f(state):\n",
    "    q_hat = (np.mean(agent.get_quantiles_for_state(state), axis=1))\n",
    "    v = (q_hat[0]*trans_mat_new[state[0]-1,0]+q_hat[1]*trans_mat_new[state[0]-1,1]).item()\n",
    "    return v\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b10cb43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_calculation_clip(states, actions, clip):\n",
    "    weight=1\n",
    "    step=np.shape(states)[0]-1\n",
    "    for i in range(step):\n",
    "        state_tensor = torch.FloatTensor(states[i]).unsqueeze(0)\n",
    "        behavior_probs = agent.behavior_policy.get_probs(state_tensor)\n",
    "        behavior_prob = behavior_probs[0, actions[i]].item()\n",
    "        weight*=trans_mat_new[states[i][0]-1,actions[i]]/behavior_prob\n",
    "    weight=max(min(clip[1],weight),clip[0]) \n",
    "    return(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2d53976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replay_buffer(s_traj, s_traj_train, a_traj, r_traj,step_forward,clip):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward\n",
    "    state_dim=np.shape(s_traj)[2]\n",
    "#logistic regression\n",
    "    s_b = s_traj_train[:,1:p].reshape(-1,state_dim)\n",
    "    s_0 = s_traj_train[:,0]\n",
    "    X = np.vstack([s_b,s_0])\n",
    "    y = np.concatenate([np.ones(np.shape(s_b)[0]), np.zeros(np.shape(s_0)[0])])\n",
    "    rt = 1/(p-1)\n",
    "    model = LogisticRegression().fit(X, y)\n",
    "    \n",
    "    Mem_state = np.zeros((n*p,step_forward+1,state_dim))\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    idx_weight=[]\n",
    "    state_zero=s_traj[:,0]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "            idx_weight.append(\n",
    "            weight_calculation_clip(Mem_state[(i*p+j), :], Mem_action[(i*p+j), :],clip) * rt*model.predict_proba(np.expand_dims(Mem_state[(i*p+j), 0], axis=0))[0, 1]/model.predict_proba(np.expand_dims(Mem_state[(i*p+j), 0], axis=0))[0, 0]\n",
    "            )\n",
    "\n",
    "    total = np.array(idx_weight).sum()\n",
    "    idx_weight_final=np.array(idx_weight)/total\n",
    "    return([Mem_state,Mem_action,Mem_reward,idx_weight_final])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f08e423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:58:54.244086Z",
     "start_time": "2025-03-20T03:58:54.239265Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def weighted_percentile(data, weights, perc,method):\n",
    "\n",
    "    data = np.array(data)\n",
    "    weights = np.array(weights)\n",
    "    idx = np.argsort(data)\n",
    "    data = data[idx] # sort data\n",
    "    weights = weights[idx] # sort weights\n",
    "    cdf = np.cumsum(weights) / np.sum(weights)\n",
    "    count = np.sum([ cdf[i] <= perc for i in range(np.shape(cdf)[0]) ])\n",
    "    #if output=infty return the maximum of V\n",
    "    if data[count]==float('inf') or method==\"min\":\n",
    "        count-=1\n",
    "\n",
    "        \n",
    "    return(data[count])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbbd0713-3728-4639-8385-a09b9d29be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(s_traj, r_traj,step_forward,gam,quan_num):\n",
    "    # s_traj: state trajectory\n",
    "    # r_traj: reward trajectory\n",
    "    # step_forward: number of steps used in approximating return\n",
    "    # gam: discount\n",
    "    if np.shape(s_traj)[1]!=step_forward+1:\n",
    "        print(\"length dismatch\")\n",
    "    if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "        print(\"height dismatch\")\n",
    "    \n",
    "    n = np.shape(s_traj)[0]\n",
    "    u = np.random.randint(0, quan_num - 1, size=n)\n",
    "    sc = list(\n",
    "        map(\n",
    "            abs,\n",
    "            np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                   axis=0) +\n",
    "            [\n",
    "                gam**step_forward * agent.get_quantiles_for_state(s_traj[i, step_forward])[step_new(s_traj[i, step_forward])[0],u[i]] -\n",
    "                v_hat_f(s_traj[i, 0] ) for i in range(n)\n",
    "            ]))\n",
    "    return (sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40eb6eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:33.791316Z",
     "start_time": "2025-03-20T03:59:33.787823Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5d211d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_rb_res(data_train, data_test, gam, alp, step_forward, num_quantiles,B,eta,seed,sample_size,clip,action_card,lr,behavior_lr,beta,batch_size,tau,lambd):\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    s_init_te = data_test[0]\n",
    "    a_init_te = data_test[1]\n",
    "    ret_te = data_test[3]\n",
    "    state_dim=np.shape(data_test[0])[2]\n",
    "    \n",
    "    ## split training data\n",
    "    idx_perm = np.random.permutation(list(range(0, n_tr)))\n",
    "    idx_tr, idx_cal = [idx_perm[0:int(n_tr / 2)], idx_perm[int(n_tr / 2):n_tr]]\n",
    "    s_train_fold = data_train[0][idx_tr]\n",
    "    a_train_fold = data_train[1][idx_tr]\n",
    "    r_train_fold = data_train[2][idx_tr]\n",
    "    \n",
    "    ## train return distribution using QTD\n",
    "    agent=QTD_new(state_traj=s_train_fold,\n",
    "        action_traj=a_train_fold,\n",
    "        reward_traj=r_train_fold,\n",
    "        state_dim=state_dim,\n",
    "        action_card=action_card,\n",
    "        quantile_num=num_quantiles,\n",
    "        gam=gam,\n",
    "        seed=seed,\n",
    "        lr=lr,\n",
    "        behavior_lr=behavior_lr,\n",
    "        beta=beta,\n",
    "        batch_size=batch_size,\n",
    "        tau=tau,\n",
    "        lambd=lambd)\n",
    "\n",
    "    def v_hat_f(state):\n",
    "        state_idx = int(state[0]) - 1  # Convert to 0-based index\n",
    "        q_hat = np.mean(agent.get_quantiles_for_state(state), axis=1)\n",
    "        v = q_hat[0] * trans_mat_new[state_idx, 0] + q_hat[1] * trans_mat_new[state_idx, 1]\n",
    "        return float(v)\n",
    "\n",
    "    def weight_calculation_clip(states, actions, clip):\n",
    "        weight = 1.0\n",
    "        steps = states.shape[0] - 1\n",
    "        \n",
    "        for i in range(steps):\n",
    "            state_tensor = torch.FloatTensor(states[i]).unsqueeze(0)\n",
    "            behavior_probs = agent.behavior_policy.get_probs(state_tensor)\n",
    "            \n",
    "            # Ensure action is integer\n",
    "            action_idx = int(actions[i])\n",
    "            behavior_prob = behavior_probs[0, action_idx].item()\n",
    "            \n",
    "            # Ensure state index is integer\n",
    "            state_idx = int(states[i][0]) - 1\n",
    "            weight *= trans_mat_new[state_idx, action_idx] / behavior_prob\n",
    "        \n",
    "        return np.clip(weight, clip[0], clip[1])\n",
    "\n",
    "    def replay_buffer(s_traj, s_traj_train, a_traj, r_traj,step_forward,clip):\n",
    "        with torch.no_grad():\n",
    "            n = np.shape(s_traj)[0]\n",
    "            p = np.shape(s_traj)[1] - step_forward\n",
    "            state_dim=np.shape(s_traj)[2]\n",
    "        #logistic regression\n",
    "            s_b = s_traj_train[:,1:p].reshape(-1,state_dim)\n",
    "            s_0 = s_traj_train[:,0]\n",
    "            X = np.vstack([s_b,s_0])\n",
    "            y = np.concatenate([np.ones(np.shape(s_b)[0]), np.zeros(np.shape(s_0)[0])])\n",
    "            rt = 1/(p-1)\n",
    "            model = LogisticRegression().fit(X, y)\n",
    "            \n",
    "            Mem_state = np.zeros((n*p,step_forward+1,state_dim))\n",
    "            Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "            Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "            idx_weight=[]\n",
    "            state_zero=s_traj[:,0]\n",
    "            for i in range(n):\n",
    "                for j in range(p):\n",
    "                    Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "                    Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "                    Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "                    idx_weight.append(\n",
    "                    weight_calculation_clip(Mem_state[(i*p+j), :], Mem_action[(i*p+j), :],clip) * rt*model.predict_proba(np.expand_dims(Mem_state[(i*p+j), 0], axis=0))[0, 1]/model.predict_proba(np.expand_dims(Mem_state[(i*p+j), 0], axis=0))[0, 0]\n",
    "                    )\n",
    "        \n",
    "            total = np.array(idx_weight).sum()\n",
    "            idx_weight_final=np.array(idx_weight)/total\n",
    "        return([Mem_state,Mem_action,Mem_reward,idx_weight_final])\n",
    "    \n",
    "    def scoring(s_traj, r_traj,step_forward,gam,quan_num):\n",
    "    # s_traj: state trajectory\n",
    "    # r_traj: reward trajectory\n",
    "    # step_forward: number of steps used in approximating return\n",
    "    # gam: discount\n",
    "        with torch.no_grad():\n",
    "            if np.shape(s_traj)[1]!=step_forward+1:\n",
    "                print(\"length dismatch\")\n",
    "            if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "                print(\"height dismatch\")\n",
    "            \n",
    "            n = np.shape(s_traj)[0]\n",
    "            u = np.random.randint(0, quan_num - 1, size=n)\n",
    "            sc = list(\n",
    "                map(\n",
    "                    abs,\n",
    "                    np.sum([gam**i * r_traj[:, i] for i in range(step_forward)],\n",
    "                           axis=0) +\n",
    "                    [\n",
    "                        gam**step_forward * agent.get_quantiles_for_state(s_traj[i, step_forward])[step_new(s_traj[i, step_forward])[0],u[i]] -\n",
    "                        v_hat_f(s_traj[i, 0] ) for i in range(n)\n",
    "                    ]))\n",
    "        return (sc)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "    ## calculate nonconformity scores based on test set\n",
    "        sc_te = [abs(ret_te[i] - v_hat_f(s_init_te[i, 0])) for i in range(n_te)]\n",
    "        \n",
    "        ## replay buffer\n",
    "        l = np.shape(step_forward)[0]\n",
    "        if isinstance(eta, int) == False:\n",
    "            m = np.shape(eta)[0]\n",
    "        elif isinstance(eta, int) == True:\n",
    "            m = 1\n",
    "            \n",
    "        PI_cov_e = np.zeros((m,l))\n",
    "        PI_len_e = np.zeros((m,l))\n",
    "                \n",
    "    \n",
    "        for k in range(l):\n",
    "            \n",
    "           \n",
    "            quan_B_e = np.zeros((m,n_te,B))\n",
    "     \n",
    "            for i in range(B):\n",
    "                \n",
    "            #n_cal = np.random.choice(a=[j for j in range(np.shape(Mem[0])[0])], p=p,size=200)\n",
    "                Mem=replay_buffer(s_traj=data_train[0][idx_cal, :], s_traj_train=s_train_fold, a_traj=data_train[1][idx_cal, :], \n",
    "                             r_traj=data_train[2][idx_cal, :],step_forward=step_forward[k],clip=clip)\n",
    "                \n",
    "                weight_is=Mem[-1]\n",
    "                n_cal = np.random.choice(range(np.shape(weight_is)[0]),size=sample_size, p=weight_is)\n",
    "                ## calculate nonconformity scores based on calibration set\n",
    "                sc_rb = scoring(s_traj=Mem[0][n_cal,],\n",
    "                                r_traj=Mem[2][n_cal,],\n",
    "                                step_forward=step_forward[k],\n",
    "                                gam=gam,\n",
    "                                quan_num=num_quantiles)\n",
    "                sc_rb.append(float('inf')) \n",
    "                for j in range(n_te): \n",
    "                    for z in range(m):\n",
    "                        quan_B_e[z][j,i] = weighted_percentile(data=sc_rb,weights=np.ones(sample_size+1),\n",
    "                                                          perc=1-alp*eta[z],method=\"min\")\n",
    "                        \n",
    "            critical_value_rb_e = np.zeros((m,n_te))\n",
    "     \n",
    "            for z in range(m):\n",
    "                critical_value_rb_e[z,:] = [ np.percentile(a=quan_B_e[z][k,:],\n",
    "                                                               q=eta[z]*100) for k in range(n_te) ]\n",
    "    \n",
    "                \n",
    "                PI_cov_e[z,k] = np.mean([sc_te[k] <= critical_value_rb_e[z,k] \n",
    "                                             for k in range(n_te)])\n",
    "                PI_len_e[z,k] = 2 * np.mean(critical_value_rb_e[z,:])\n",
    "                \n",
    "            \n",
    "    return([PI_cov_e,PI_len_e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02f506fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:22:31.005418Z",
     "start_time": "2025-03-19T15:22:31.005418Z"
    }
   },
   "outputs": [],
   "source": [
    "def quantile_region_res(data_train, data_test, gam, alp, num_quantiles,seed,action_card,lr,behavior_lr,beta,batch_size,tau,lambd):\n",
    "\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    state_dim = np.shape(data_train[0])[2]\n",
    "    s_init_te = data_test[0]\n",
    "    a_init_te = data_test[1] \n",
    "    ret_te = data_test[3]\n",
    "    quant_num = num_quantiles\n",
    "    ## train QTD using full training data\n",
    "    agent=QTD_new(state_traj=data_train[0],\n",
    "        action_traj=data_train[1],\n",
    "        reward_traj=data_train[2],\n",
    "        state_dim=state_dim,\n",
    "        action_card=action_card,\n",
    "        quantile_num=num_quantiles,\n",
    "        gam=gam,\n",
    "        seed=seed,\n",
    "        lr=lr,\n",
    "        behavior_lr=behavior_lr,\n",
    "        beta=beta,\n",
    "        batch_size=batch_size,\n",
    "        tau=tau,\n",
    "        lambd=lambd)\n",
    "    with torch.no_grad():\n",
    "        data_t=data_test[0].reshape(-1,state_dim)\n",
    "        quant_interval_lower=np.zeros(n_te)\n",
    "        quant_interval_upper=np.zeros(n_te)\n",
    "        ## lower and upper quanitles for each states \n",
    "        for i in range(n_te):\n",
    "            data_aug=np.hstack((agent.get_quantiles_for_state(data_t[i])[0,:], agent.get_quantiles_for_state(data_t[i])[1,:])) \n",
    "            weight_aug=np.hstack((np.ones(quant_num)*trans_mat_new[data_t[i,0]-1,0]/quant_num,np.ones(quant_num)*trans_mat_new[data_t[i,0]-1,1]/quant_num))\n",
    "            quant_interval_lower[i]=weighted_percentile(data_aug,weight_aug,alp/2,method=\"min\")\n",
    "            quant_interval_upper[i]=weighted_percentile(data_aug,weight_aug,1-alp/2,method=\"max\")\n",
    "                           \n",
    "    \n",
    "        ## calculate coverage\n",
    "        t1 = [\n",
    "        ret_te[i] >= quant_interval_lower[i] for i in range(n_te)\n",
    "        ]\n",
    "        t2 = [\n",
    "        ret_te[i] <= quant_interval_upper[i] for i in range(n_te)\n",
    "        ]\n",
    "        quan_PI_cov = np.mean([all([t1[i], t2[i]]) for i in range(n_te)])\n",
    "        quan_PI_len = np.mean(quant_interval_upper - quant_interval_lower\n",
    "            )\n",
    "\n",
    "    return ([quan_PI_cov, quan_PI_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2b737c9-5a7b-44fc-bada-4f763172ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel Calculation\n",
    "#Parallel Calculation\n",
    "def run_single_experiment(i, n_tr, gam, T_obs, seed, n_te, T, num_quantiles, B, alp, eta, step_forward,sample_size,clip,action_card,lr,behavior_lr,beta,batch_size,tau,lambd):\n",
    "\n",
    "    data_train = data_gen(N=n_tr,\n",
    "                          T_obs=T_obs,\n",
    "                          T=T,\n",
    "                          gam=gam,\n",
    "                          seed=seed + i,\n",
    "                          s_init=None)\n",
    "\n",
    "\n",
    "    data_test = data_gen(N=n_te,\n",
    "                             T_obs=1,\n",
    "                             T=T,\n",
    "                             gam=gam,\n",
    "                             seed=seed + i + 10000,\n",
    "                             s_init=None)\n",
    "\n",
    "    result = new_rb_res(data_train=data_train,\n",
    "                        data_test=data_test,\n",
    "                        gam=gam,\n",
    "                        alp=alp,\n",
    "                        step_forward=step_forward,\n",
    "                        num_quantiles=num_quantiles,\n",
    "                        B=B,\n",
    "                        eta=eta,\n",
    "                        seed=seed + i,\n",
    "                        sample_size=sample_size,\n",
    "                       clip=clip,\n",
    "                       action_card=action_card,\n",
    "                       lr=lr,\n",
    "                       behavior_lr=behavior_lr,\n",
    "                       beta=beta,\n",
    "                       batch_size=batch_size,\n",
    "                       tau=tau,\n",
    "                       lambd=lambd)\n",
    "   \n",
    "    return result  # return [PI_cov_e, PI_len_e]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba05eaa-534c-43ca-867e-d005ab16965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  10 out of  10 | elapsed: 137.7min finished\n"
     ]
    }
   ],
   "source": [
    "# Parameter setting\n",
    "rep = 50\n",
    "n_tr = 400\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 70\n",
    "num_quantiles = 30\n",
    "B = 50\n",
    "alp = 0.1\n",
    "eta = [0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "clip=np.array([0.2,5.0])\n",
    "step_forward = [1, 2, 3,4,5]\n",
    "sample_size=200\n",
    "action_card=2\n",
    "lr=0.05\n",
    "behavior_lr=0.005\n",
    "beta=0.5\n",
    "batch_size=64\n",
    "tau=0.1\n",
    "lambd=0.001\n",
    "\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=13, verbose=1)(\n",
    "    delayed(run_single_experiment)(\n",
    "        i, n_tr, gam, T_obs, seed, n_te, T, num_quantiles, B, alp, eta, step_forward,sample_size,clip,action_card,lr,behavior_lr,beta,batch_size,tau,lambd\n",
    "    ) for i in range(rep)\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78406237-5ccc-4cc6-a12f-2514a7ea7807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[0.93548387, 0.96774194, 0.97419355, 0.97419355, 0.97419355],\n",
       "         [0.90645161, 0.9516129 , 0.96774194, 0.97419355, 0.97419355],\n",
       "         [0.88709677, 0.94193548, 0.96774194, 0.97096774, 0.96774194],\n",
       "         [0.88064516, 0.93225806, 0.95483871, 0.96774194, 0.96774194],\n",
       "         [0.86451613, 0.92903226, 0.9483871 , 0.96774194, 0.96451613],\n",
       "         [0.86451613, 0.92580645, 0.9483871 , 0.95483871, 0.95483871],\n",
       "         [0.86451613, 0.90967742, 0.94516129, 0.95483871, 0.95483871]]),\n",
       "  array([[8.2244556 , 9.16083324, 9.69972944, 9.9442224 , 9.92807247],\n",
       "         [7.7521044 , 8.72994534, 9.2115843 , 9.72704669, 9.51949683],\n",
       "         [7.56053859, 8.42084251, 9.07083761, 9.40777304, 9.22250554],\n",
       "         [7.39161972, 8.19120468, 8.78681704, 9.19020734, 9.03727396],\n",
       "         [7.27803691, 8.01848451, 8.63064506, 9.03849889, 8.98230576],\n",
       "         [7.15243925, 7.95900045, 8.56897786, 8.81100347, 8.85498837],\n",
       "         [7.120319  , 7.80946346, 8.48392009, 8.8195608 , 8.78787171]])],\n",
       " [array([[0.93870968, 0.96774194, 0.96774194, 0.97419355, 0.97419355],\n",
       "         [0.91612903, 0.95806452, 0.96774194, 0.96774194, 0.96774194],\n",
       "         [0.90967742, 0.95483871, 0.96129032, 0.96774194, 0.96774194],\n",
       "         [0.90645161, 0.94193548, 0.95483871, 0.95806452, 0.96774194],\n",
       "         [0.89677419, 0.91935484, 0.95483871, 0.95806452, 0.95806452],\n",
       "         [0.88709677, 0.91612903, 0.94193548, 0.95483871, 0.95806452],\n",
       "         [0.89677419, 0.91290323, 0.94193548, 0.95483871, 0.95806452]]),\n",
       "  array([[ 8.38462505,  9.35042973,  9.74716702, 10.01074367, 10.07725315],\n",
       "         [ 8.15069898,  9.09762806,  9.52926871,  9.58644958,  9.73451397],\n",
       "         [ 7.97912957,  8.78857113,  9.14079191,  9.24964996,  9.53533414],\n",
       "         [ 7.74675629,  8.45745002,  8.84490159,  9.03471159,  9.25632199],\n",
       "         [ 7.61693432,  8.20142656,  8.70702526,  8.91196654,  9.09523412],\n",
       "         [ 7.55281954,  8.13128596,  8.59485109,  8.76937279,  8.99429383],\n",
       "         [ 7.62813896,  8.09623436,  8.63797372,  8.82020976,  8.93771497]])],\n",
       " [array([[0.92903226, 0.96451613, 0.97096774, 0.97096774, 0.97096774],\n",
       "         [0.92580645, 0.96129032, 0.96451613, 0.97096774, 0.97096774],\n",
       "         [0.91290323, 0.94193548, 0.96129032, 0.96451613, 0.96451613],\n",
       "         [0.9       , 0.93225806, 0.94193548, 0.96451613, 0.96129032],\n",
       "         [0.88387097, 0.92903226, 0.93225806, 0.96129032, 0.9483871 ],\n",
       "         [0.88387097, 0.92580645, 0.92903226, 0.9483871 , 0.94516129],\n",
       "         [0.87741935, 0.91290323, 0.92580645, 0.94193548, 0.93225806]]),\n",
       "  array([[8.33992022, 9.14262887, 9.5057355 , 9.92665816, 9.93677941],\n",
       "         [8.11949745, 8.90988959, 9.12943297, 9.58048206, 9.55171265],\n",
       "         [7.87796858, 8.70147814, 8.9631025 , 9.27418166, 9.19676762],\n",
       "         [7.77430847, 8.48957545, 8.69230444, 9.13059189, 8.91498287],\n",
       "         [7.53681042, 8.34333958, 8.41237548, 8.91407008, 8.72380042],\n",
       "         [7.51837305, 8.16272614, 8.30556523, 8.78092482, 8.71203311],\n",
       "         [7.3554838 , 7.95163908, 8.2086063 , 8.68232408, 8.47486946]])],\n",
       " [array([[0.93225806, 0.96774194, 0.96774194, 0.96774194, 0.97096774],\n",
       "         [0.91290323, 0.96129032, 0.96774194, 0.96774194, 0.96774194],\n",
       "         [0.90645161, 0.95806452, 0.96451613, 0.96129032, 0.96774194],\n",
       "         [0.90322581, 0.94193548, 0.95806452, 0.95806452, 0.96774194],\n",
       "         [0.89032258, 0.92580645, 0.9516129 , 0.9516129 , 0.96451613],\n",
       "         [0.87741935, 0.92580645, 0.9483871 , 0.9516129 , 0.95806452],\n",
       "         [0.87096774, 0.93225806, 0.94193548, 0.9483871 , 0.95806452]]),\n",
       "  array([[8.28576758, 9.27328307, 9.61570107, 9.64912859, 9.85121614],\n",
       "         [8.05351308, 8.95599714, 9.39820806, 9.27662024, 9.63961769],\n",
       "         [7.83580761, 8.73053301, 9.11215538, 8.97904567, 9.43864886],\n",
       "         [7.69800952, 8.44305723, 8.78012288, 8.74944912, 9.23599239],\n",
       "         [7.52650433, 8.19282901, 8.62792493, 8.65616758, 9.08161508],\n",
       "         [7.35102215, 8.18979491, 8.50358891, 8.59509893, 8.89215048],\n",
       "         [7.29360166, 8.22995027, 8.42328285, 8.48321375, 8.73204345]])],\n",
       " [array([[0.92903226, 0.95483871, 0.96774194, 0.96774194, 0.97096774],\n",
       "         [0.90967742, 0.95483871, 0.95806452, 0.96774194, 0.96774194],\n",
       "         [0.9       , 0.94516129, 0.95483871, 0.95483871, 0.96129032],\n",
       "         [0.87741935, 0.93870968, 0.9516129 , 0.95483871, 0.95483871],\n",
       "         [0.87096774, 0.92903226, 0.94516129, 0.95483871, 0.95483871],\n",
       "         [0.87096774, 0.92580645, 0.94193548, 0.9483871 , 0.95483871],\n",
       "         [0.86774194, 0.91290323, 0.93870968, 0.94193548, 0.95483871]]),\n",
       "  array([[8.24122458, 9.13998979, 9.45752638, 9.73770093, 9.91791676],\n",
       "         [7.8629914 , 8.83759841, 9.20921182, 9.41627662, 9.62507003],\n",
       "         [7.66232522, 8.57476265, 9.05366037, 9.08524018, 9.24175955],\n",
       "         [7.39860887, 8.33729341, 8.81399081, 9.00306803, 9.09990725],\n",
       "         [7.28576979, 8.15755763, 8.58026216, 8.9053455 , 8.96479752],\n",
       "         [7.16720123, 8.13770891, 8.49247493, 8.63107989, 8.9801657 ],\n",
       "         [7.10598275, 7.99139252, 8.40109061, 8.52844058, 8.90405381]])],\n",
       " [array([[0.91935484, 0.95483871, 0.96451613, 0.96774194, 0.97419355],\n",
       "         [0.90967742, 0.95483871, 0.95806452, 0.96451613, 0.96774194],\n",
       "         [0.89354839, 0.93225806, 0.95806452, 0.95806452, 0.96451613],\n",
       "         [0.87741935, 0.92903226, 0.94193548, 0.95483871, 0.95806452],\n",
       "         [0.87741935, 0.92258065, 0.93225806, 0.9483871 , 0.95483871],\n",
       "         [0.86451613, 0.90645161, 0.93225806, 0.94193548, 0.94516129],\n",
       "         [0.86451613, 0.90322581, 0.93225806, 0.93870968, 0.93870968]]),\n",
       "  array([[ 8.07668137,  8.98644623,  9.38492736,  9.86142281, 10.12064732],\n",
       "         [ 7.90455402,  8.81143173,  9.09765087,  9.50443157,  9.732854  ],\n",
       "         [ 7.65861868,  8.48516485,  9.03470121,  9.18354595,  9.37537345],\n",
       "         [ 7.51920917,  8.34419666,  8.68154811,  8.9960479 ,  9.17196764],\n",
       "         [ 7.44954084,  8.12481181,  8.53293079,  8.7395446 ,  8.96296811],\n",
       "         [ 7.25953544,  7.86131112,  8.41605998,  8.64674234,  8.71423539],\n",
       "         [ 7.21208357,  7.79354912,  8.41930926,  8.6394274 ,  8.60676095]])],\n",
       " [array([[0.92580645, 0.95483871, 0.96451613, 0.96774194, 0.97096774],\n",
       "         [0.91612903, 0.94516129, 0.96129032, 0.96451613, 0.96774194],\n",
       "         [0.90645161, 0.92580645, 0.95483871, 0.95806452, 0.96451613],\n",
       "         [0.88709677, 0.91935484, 0.95483871, 0.95483871, 0.96451613],\n",
       "         [0.88064516, 0.91290323, 0.9483871 , 0.9483871 , 0.95483871],\n",
       "         [0.88064516, 0.90645161, 0.94193548, 0.94193548, 0.95483871],\n",
       "         [0.87419355, 0.90645161, 0.94193548, 0.92580645, 0.95483871]]),\n",
       "  array([[ 8.46566953,  9.02399324,  9.69967562,  9.80915995, 10.10842316],\n",
       "         [ 8.2032666 ,  8.73651592,  9.31646533,  9.49556704,  9.9107538 ],\n",
       "         [ 7.91137832,  8.49650453,  8.99858765,  9.19977255,  9.61468633],\n",
       "         [ 7.64562374,  8.35237174,  8.91082518,  9.0260757 ,  9.39043344],\n",
       "         [ 7.47727162,  8.11117566,  8.8104015 ,  8.76882342,  9.16895175],\n",
       "         [ 7.41989357,  8.04640515,  8.62693886,  8.6823254 ,  9.00671685],\n",
       "         [ 7.28373246,  7.97768665,  8.63882308,  8.53978874,  9.01848014]])],\n",
       " [array([[0.92580645, 0.96451613, 0.96451613, 0.96774194, 0.97096774],\n",
       "         [0.91935484, 0.96129032, 0.96129032, 0.96451613, 0.96774194],\n",
       "         [0.89032258, 0.9516129 , 0.95483871, 0.96129032, 0.96129032],\n",
       "         [0.88387097, 0.94193548, 0.9516129 , 0.9516129 , 0.96129032],\n",
       "         [0.88064516, 0.93548387, 0.94193548, 0.9483871 , 0.9516129 ],\n",
       "         [0.86774194, 0.92580645, 0.94193548, 0.9483871 , 0.94193548],\n",
       "         [0.86451613, 0.92903226, 0.93870968, 0.94193548, 0.94193548]]),\n",
       "  array([[8.13563012, 9.2812922 , 9.41447589, 9.57070524, 9.79418684],\n",
       "         [7.98548157, 8.98124203, 9.12791355, 9.3040023 , 9.52306014],\n",
       "         [7.65533077, 8.80027   , 8.93251107, 9.08961619, 9.24169408],\n",
       "         [7.44476906, 8.50248691, 8.6891481 , 8.84556942, 9.0094159 ],\n",
       "         [7.34509603, 8.3186316 , 8.46988095, 8.6636207 , 8.80456432],\n",
       "         [7.17085646, 8.12667199, 8.52814563, 8.64028206, 8.58364444],\n",
       "         [7.07611056, 8.2390077 , 8.40805406, 8.53341139, 8.58373997]])],\n",
       " [array([[0.91612903, 0.95483871, 0.95806452, 0.97096774, 0.97096774],\n",
       "         [0.90967742, 0.9483871 , 0.9516129 , 0.96774194, 0.96451613],\n",
       "         [0.89354839, 0.94193548, 0.94516129, 0.96451613, 0.96451613],\n",
       "         [0.88387097, 0.92580645, 0.94516129, 0.95483871, 0.95483871],\n",
       "         [0.88064516, 0.91612903, 0.93870968, 0.94516129, 0.95483871],\n",
       "         [0.86774194, 0.90967742, 0.92580645, 0.94516129, 0.9516129 ],\n",
       "         [0.86451613, 0.90322581, 0.91612903, 0.93870968, 0.9516129 ]]),\n",
       "  array([[ 8.17933118,  9.09115287,  9.29226602,  9.87912749, 10.16948205],\n",
       "         [ 7.95258898,  8.86900254,  8.91232974,  9.63814455,  9.59721757],\n",
       "         [ 7.63137744,  8.5428708 ,  8.71174287,  9.36857684,  9.39161972],\n",
       "         [ 7.43488595,  8.23398462,  8.63826203,  9.12144139,  9.22823597],\n",
       "         [ 7.27712368,  8.10263586,  8.4456292 ,  8.81078488,  9.12929863],\n",
       "         [ 7.12865261,  7.96548352,  8.26533057,  8.56533288,  8.92330171],\n",
       "         [ 6.99614904,  7.86318448,  8.16523229,  8.44804275,  8.93018103]])],\n",
       " [array([[0.90967742, 0.9516129 , 0.96129032, 0.96451613, 0.97096774],\n",
       "         [0.89677419, 0.94516129, 0.96129032, 0.96129032, 0.96451613],\n",
       "         [0.89032258, 0.93870968, 0.9516129 , 0.96129032, 0.96129032],\n",
       "         [0.87741935, 0.92258065, 0.94516129, 0.9516129 , 0.95806452],\n",
       "         [0.87419355, 0.91290323, 0.93225806, 0.93870968, 0.9483871 ],\n",
       "         [0.87419355, 0.91290323, 0.93225806, 0.93548387, 0.9483871 ],\n",
       "         [0.87419355, 0.90967742, 0.92903226, 0.93870968, 0.94516129]]),\n",
       "  array([[ 8.07341487,  8.98158154,  9.54629504,  9.72761001, 10.05687229],\n",
       "         [ 7.82778137,  8.76476676,  9.23760849,  9.40136775,  9.76821424],\n",
       "         [ 7.58759017,  8.6397104 ,  8.98941729,  9.18049677,  9.29552503],\n",
       "         [ 7.44600471,  8.44165274,  8.81377822,  8.93180393,  9.11406628],\n",
       "         [ 7.27371534,  8.22882852,  8.55054154,  8.71524928,  8.87543395],\n",
       "         [ 7.18932611,  8.22898469,  8.5661148 ,  8.59345561,  8.84586395],\n",
       "         [ 7.18075756,  8.05880663,  8.49424225,  8.61364273,  8.77551916]])]]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30500b6f-eecd-4a06-81ef-62fd05e6bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rb_new_cov_tau03_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau03_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau04_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau04_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau05_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau05_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau06_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau06_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau07_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau07_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau08_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau08_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau09_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau09_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "\n",
    "for i in range(np.shape(results)[0]):\n",
    "\n",
    "    rb_new_cov_tau03_e3[i, :] = results [i][0][0]\n",
    "    rb_new_len_tau03_e3[i, :] = results [i][1][0]\n",
    "    rb_new_cov_tau04_e3[i, :] = results [i][0][1]\n",
    "    rb_new_len_tau04_e3[i, :] = results [i][1][1]\n",
    "    rb_new_cov_tau05_e3[i, :] = results [i][0][2]\n",
    "    rb_new_len_tau05_e3[i, :] = results [i][1][2]\n",
    "    rb_new_cov_tau06_e3[i, :] = results [i][0][3]\n",
    "    rb_new_len_tau06_e3[i, :] = results [i][1][3]\n",
    "    rb_new_cov_tau07_e3[i, :] = results [i][0][4]\n",
    "    rb_new_len_tau07_e3[i, :] = results [i][1][4]\n",
    "    rb_new_cov_tau08_e3[i, :] = results [i][0][5]\n",
    "    rb_new_len_tau08_e3[i, :] = results [i][1][5]\n",
    "    rb_new_cov_tau09_e3[i, :] = results [i][0][6]\n",
    "    rb_new_len_tau09_e3[i, :] = results [i][1][6]\n",
    "\n",
    "\n",
    "PI_cov_all = [res[0] for res in results]\n",
    "PI_len_all = [res[1] for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d3ac89d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T23:56:51.524066Z",
     "start_time": "2025-03-19T23:56:51.517499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new(tau=0.3): \n",
      "coverage probability: \n",
      "[0.9261290322580645, 0.9603225806451613, 0.9661290322580645, 0.9693548387096774, 0.9719354838709677]\n",
      "average length: \n",
      "[8.240672010522266, 9.143163076623397, 9.536349934161212, 9.811647925486918, 9.996084959015453]\n",
      "new(tau=0.4): \n",
      "coverage probability: \n",
      "[0.9261290322580645, 0.9603225806451613, 0.9661290322580645, 0.9693548387096774, 0.9719354838709677]\n",
      "average length: \n",
      "[8.240672010522266, 9.143163076623397, 9.536349934161212, 9.811647925486918, 9.996084959015453]\n",
      "new(tau=0.5): \n",
      "coverage probability: \n",
      "[0.9122580645161291, 0.9541935483870969, 0.9619354838709677, 0.9670967741935484, 0.9680645161290323]\n",
      "average length: \n",
      "[7.981247786914142, 8.869401752352935, 9.216967383345706, 9.493038839719388, 9.66025109281948]\n",
      "new(tau=0.6): \n",
      "coverage probability: \n",
      "[0.8877419354838709, 0.9325806451612901, 0.95, 0.9570967741935483, 0.9616129032258065]\n",
      "average length: \n",
      "[7.549979550717586, 8.379327345916032, 8.765169840376988, 9.002896629786683, 9.145859770228165]\n",
      "new(tau=0.7): \n",
      "coverage probability: \n",
      "[0.8800000000000001, 0.9232258064516129, 0.9425806451612904, 0.9522580645161292, 0.9554838709677419]\n",
      "average length: \n",
      "[7.406680328083958, 8.179972074566972, 8.576761687515923, 8.812407145801032, 8.978896967237851]\n",
      "new(tau=0.8): \n",
      "coverage probability: \n",
      "[0.8738709677419354, 0.9180645161290322, 0.9383870967741934, 0.9470967741935483, 0.9512903225806453]\n",
      "average length: \n",
      "[7.291011940989362, 8.08093728325188, 8.486804785986156, 8.671561819473249, 8.85073938346274]\n",
      "new(tau=0.9): \n",
      "coverage probability: \n",
      "[0.8719354838709676, 0.913225806451613, 0.9351612903225808, 0.9425806451612904, 0.9490322580645161]\n",
      "average length: \n",
      "[7.225235935847657, 8.001091426067724, 8.428053449126281, 8.610806196811541, 8.775123465549123]\n"
     ]
    }
   ],
   "source": [
    "print(\"new(tau=0.3): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "\n",
    "print(\"new(tau=0.4): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "print(\"new(tau=0.5): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau04_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau04_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "print(\"new(tau=0.6): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau06_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau06_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "print(\"new(tau=0.7): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau07_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau07_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "print(\"new(tau=0.8): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau08_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau08_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "\n",
    "print(\"new(tau=0.9): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau09_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau09_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3efbe2-cfb7-4f0d-9416-92342a0ea056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed76c28-2d36-4de5-9b73-d5f3130c6bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau03_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau03_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau03_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau03_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau03_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_hd_03.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau03_e3[:,0],\n",
    "     'k=2': rb_new_len_tau03_e3[:,1],\n",
    "     'k=3': rb_new_len_tau03_e3[:,2],\n",
    "     'k=4': rb_new_len_tau03_e3[:,3],\n",
    "     'k=5': rb_new_len_tau03_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_hd_03.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b51280-ce47-4cbc-b5d8-21e8262396da",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau04_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau04_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau04_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau04_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau04_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_hd_04.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau04_e3[:,0],\n",
    "     'k=2': rb_new_len_tau04_e3[:,1],\n",
    "     'k=3': rb_new_len_tau04_e3[:,2],\n",
    "     'k=4': rb_new_len_tau04_e3[:,3],\n",
    "     'k=5': rb_new_len_tau04_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_hd_04.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25548d93-5be2-4e6b-8d3d-de94fc547e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau05_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau05_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau05_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau05_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau05_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_hd_05.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau05_e3[:,0],\n",
    "     'k=2': rb_new_len_tau05_e3[:,1],\n",
    "     'k=3': rb_new_len_tau05_e3[:,2],\n",
    "     'k=4': rb_new_len_tau05_e3[:,3],\n",
    "     'k=5': rb_new_len_tau05_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_hd_05.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf07a8e-b12a-4d1c-8047-a7e41dbae0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau06_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau06_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau06_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau06_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau06_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_hd_06.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau06_e3[:,0],\n",
    "     'k=2': rb_new_len_tau06_e3[:,1],\n",
    "     'k=3': rb_new_len_tau06_e3[:,2],\n",
    "     'k=4': rb_new_len_tau06_e3[:,3],\n",
    "     'k=5': rb_new_len_tau06_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_hd_06.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaef170d-c295-49d6-961e-c8c62a7c6ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau07_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau07_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau07_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau07_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau07_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_hd_07.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau07_e3[:,0],\n",
    "     'k=2': rb_new_len_tau07_e3[:,1],\n",
    "     'k=3': rb_new_len_tau07_e3[:,2],\n",
    "     'k=4': rb_new_len_tau07_e3[:,3],\n",
    "     'k=5': rb_new_len_tau07_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_hd_07.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc29e46-7f1d-4c8c-a36e-f9651a7b6882",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau08_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau08_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau08_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau08_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau08_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_hd_08.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau08_e3[:,0],\n",
    "     'k=2': rb_new_len_tau08_e3[:,1],\n",
    "     'k=3': rb_new_len_tau08_e3[:,2],\n",
    "     'k=4': rb_new_len_tau08_e3[:,3],\n",
    "     'k=5': rb_new_len_tau08_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_hd_08.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af7c2c-74cb-46dd-acc7-532bc87119f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'k=1': rb_new_cov_tau09_e3[:,0],\n",
    "    'k=2': rb_new_cov_tau09_e3[:,1],\n",
    "    'k=3': rb_new_cov_tau09_e3[:,2],\n",
    "    'k=4': rb_new_cov_tau09_e3[:,3],\n",
    "    'k=5': rb_new_cov_tau09_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_on_hd_09.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'k=1': rb_new_len_tau09_e3[:,0],\n",
    "     'k=2': rb_new_len_tau09_e3[:,1],\n",
    "     'k=3': rb_new_len_tau09_e3[:,2],\n",
    "     'k=4': rb_new_len_tau09_e3[:,3],\n",
    "     'k=5': rb_new_len_tau09_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_on_hd_09.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a08941fe-d831-4131-b12b-d2c8c90f7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  10 out of  10 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "rep = 50\n",
    "n_tr = 400\n",
    "gam = 0.8\n",
    "T_obs = 30\n",
    "seed = 2025\n",
    "n_te = 310\n",
    "T = 70\n",
    "num_quantiles = 20\n",
    "clip=np.array([0.2,5.0])\n",
    "step_forward = [1, 2, 3,4,5]\n",
    "action_card=2\n",
    "lr=0.05\n",
    "behavior_lr=0.005\n",
    "lambd=0.001\n",
    "beta=0.2\n",
    "batch_size=64\n",
    "tau=0.1\n",
    "alp=0.1\n",
    "res_quan = np.zeros((rep, 2))\n",
    "\n",
    "# Parallel Calculation\n",
    "def process_iteration(i,n_tr, gam, T_obs, n_te, T, num_quantiles, alp, seed,action_card,lr,behavior_lr,beta,batch_size,tau,lambd):\n",
    " \n",
    "    data_train = data_gen(N=n_tr,\n",
    "                         T_obs=T_obs,\n",
    "                         T=T,\n",
    "                         gam=gam,\n",
    "                         seed=seed+i,\n",
    "                         s_init=None)\n",
    "    \n",
    "\n",
    "    data_test = data_gen(N=n_te,\n",
    "                            T_obs=1,\n",
    "                            T=T,\n",
    "                            gam=gam,\n",
    "                            seed=seed + i + 10000,\n",
    "                            s_init=None)\n",
    "    \n",
    "\n",
    "    quan_PI_res1 = quantile_region_res(data_train=data_train,\n",
    "                                      data_test=data_test, \n",
    "                                      gam=gam, \n",
    "                                      alp=alp,\n",
    "                                      num_quantiles=num_quantiles,\n",
    "                                      seed=seed+i,\n",
    "                                        action_card=action_card,\n",
    "                                        lr=lr,\n",
    "                                        behavior_lr=behavior_lr,\n",
    "                                        beta=beta,\n",
    "                                        batch_size=batch_size,\n",
    "                                        tau=tau,\n",
    "                                        lambd=lambd)\n",
    "    \n",
    "    print(f\"test num: {i}\")\n",
    "    print(\"quantile region: \")\n",
    "    print(f\"cov: {quan_PI_res1[0]} | length: {quan_PI_res1[1]}\")\n",
    "    \n",
    "    return quan_PI_res1\n",
    "\n",
    "\n",
    "\n",
    "results_qr = Parallel(n_jobs=13, verbose=1)(delayed(process_iteration)(i, n_tr, gam, T_obs, n_te, T, num_quantiles, alp, seed,action_card,lr,behavior_lr,beta,batch_size,tau,lambd) for i in range(rep))\n",
    "\n",
    "# restore data\n",
    "for i in range(rep):\n",
    "    res_quan[i, :] = results_qr[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055a675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:47:46.618942Z",
     "start_time": "2025-03-19T07:47:46.550210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantile region\n",
      "0         0.851613\n",
      "1         0.858065\n",
      "2         0.851613\n",
      "3         0.851613\n",
      "4         0.851613\n",
      "   quantile region\n",
      "0         6.989250\n",
      "1         7.057908\n",
      "2         6.953058\n",
      "3         6.959608\n",
      "4         7.008846\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "##### save simulation result\n",
    "data_quan_cov = {\n",
    "    'quantile region': res_quan[:, 0]\n",
    "}\n",
    "\n",
    "df_cov = pd.DataFrame(data_quan_cov)\n",
    "\n",
    "df_cov.to_excel('QR_cov_hd_on.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_quan_len = {\n",
    "    'quantile region': res_quan[:, 1]\n",
    "}\n",
    "\n",
    "df_len = pd.DataFrame(data_quan_len)\n",
    "\n",
    "df_len.to_excel('QR_len_hd_on.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "print(df_cov.head())\n",
    "print(df_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "455d9652-4e15-4760-8f29-c09290514b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile region: \n",
      "coverage probability:  0.817741935483871 |  average length:  6.841461800144866\n"
     ]
    }
   ],
   "source": [
    "print(\"quantile region: \")\n",
    "print(\"coverage probability: \", np.mean(res_quan[:, 0]),\n",
    "      \"|  average length: \", np.mean(res_quan[:, 1]))\n",
    "\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b906adf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:46:49.188482Z",
     "start_time": "2025-03-19T07:46:49.179093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile region: \n",
      "coverage probability:  0.8180645161290323 |  average length:  6.8887147247995575\n"
     ]
    }
   ],
   "source": [
    "print(\"quantile region: \")\n",
    "print(\"coverage probability: \", np.mean(res_quan[:, 0]),\n",
    "      \"|  average length: \", np.mean(res_quan[:, 1]))\n",
    "\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d3be7",
   "metadata": {},
   "source": [
    "# Plotting simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7c59d47-218e-42d2-81d3-b36efdabaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        k=1       k=2       k=3       k=4       k=5    DRL-QR\n",
      "0  0.861290  0.900000  0.932258  0.938710  0.938710  0.851613\n",
      "1  0.835484  0.900000  0.919355  0.932258  0.954839  0.835484\n",
      "2  0.861290  0.912903  0.929032  0.951613  0.935484  0.838710\n",
      "3  0.867742  0.922581  0.935484  0.935484  0.954839  0.825806\n",
      "4  0.880645  0.919355  0.935484  0.938710  0.945161  0.767742\n",
      "        k=1       k=2       k=3       k=4       k=5    DRL-QR\n",
      "0  7.002390  7.722383  8.273463  8.643360  8.620562  7.373246\n",
      "1  6.705014  7.628546  8.042908  8.417831  8.635395  6.975127\n",
      "2  7.062016  7.945103  8.306917  8.782129  8.656705  7.096733\n",
      "3  7.169248  8.048030  8.343284  8.387969  8.666618  6.821812\n",
      "4  7.552464  7.975333  8.415395  8.514447  8.654872  6.027849\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_new_rb_cov = pd.read_excel('cov_on_hd_09.xlsx')\n",
    "data_new_rb_len = pd.read_excel('len_on_hd_09.xlsx')\n",
    "\n",
    "data_QR_cov = pd.read_excel('QR_cov_hd_on.xlsx')\n",
    "data_QR_len = pd.read_excel('QR_len_hd_on.xlsx')\n",
    "\n",
    "#data_new_rb_cov.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "#data_new_rb_len.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "data_new_rb_cov['DRL-QR'] = data_QR_cov['quantile region']\n",
    "data_new_rb_len['DRL-QR'] = data_QR_len['quantile region']\n",
    "\n",
    "print(data_new_rb_cov.head())\n",
    "print(data_new_rb_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91b40fd-20ad-47f3-82bc-ce1862baccd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_cov = data_new_rb_cov.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "colors = [\n",
    "    'goldenrod', 'orange', 'gold', 'khaki', 'wheat', 'lightyellow','skyblue'\n",
    "]\n",
    "\n",
    "colors2 = [\n",
    "    'darkseagreen','limegreen' ,'greenyellow','yellowgreen','lightgreen','honeydew','skyblue'\n",
    "]\n",
    "for patch, color in zip(bplot_new_cov.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_cov.yaxis.grid(False)\n",
    "bplot_new_cov.xaxis.grid(False)\n",
    "bplot_new_cov.set_xlabel(\"Method\")\n",
    "bplot_new_cov.set_ylabel(\"Coverage Probability\")\n",
    "\n",
    "plt.axhline(y=0.90, color='red', linestyle='-', linewidth=1)\n",
    "#plt.title(\"tau=0.9, n_tr=600, gam=0.8, quantnum=30, p_s0 estimator\")\n",
    "plt.ylim(0.75,1)\n",
    "#plt.savefig('fig/new_rb_cov_o_gam0.8_nr100_qnum10.png')\n",
    "plt.savefig('Ex1_on_hd_cp.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ebe97f3-e9f2-4156-ae67-593188d23223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_len = data_new_rb_len.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "\n",
    "for patch, color in zip(bplot_new_len.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_len.yaxis.grid(False)\n",
    "bplot_new_len.xaxis.grid(False)\n",
    "bplot_new_len.set_xlabel(\"Method\")\n",
    "bplot_new_len.set_ylabel(\"Empirical Length\")\n",
    "\n",
    "#plt.title(\"tau=0.9, n_tr = 600, gam=0.8, quantnum=30, p_s0 estimator\")\n",
    "#plt.savefig('fig/new_len_o_gam0.8_nr100_qnum10.png')\n",
    "plt.savefig('Ex1_on_hd_al.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec896a92-ee48-4dc7-9c7b-48842405031b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
