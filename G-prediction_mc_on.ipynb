{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6400d3f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:03.990403Z",
     "start_time": "2025-03-20T03:56:55.070662Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, WhiteKernel\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy.stats import norm\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "from torch.distributions import Categorical\n",
    "from collections import deque\n",
    "from torch.optim.lr_scheduler import SequentialLR, LinearLR, CosineAnnealingLR\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import gymnasium as gym\n",
    "import sklearn.pipeline\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a7e925c-e164-4957-9f8e-743d00e5dce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de05fb78-74f9-4b77-abb9-6a77d661974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d58991-ec9a-4f3f-8930-3b3afc2afa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_env = 'MountainCar-v0'# env = gym.envs.make('CartPole-v1')\n",
    "env = gym.make(openai_env, render_mode=\"rgb_array\")\n",
    "n_actions = env.action_space.n\n",
    "actions = np.arange(n_actions)\n",
    "sample_size = 10000\n",
    "\n",
    "#Note: Alternatively create samples via env.observation_space.sample()\n",
    "\n",
    "obs_samples = []\n",
    "num_samples = 0\n",
    "while num_samples < sample_size:\n",
    "    env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        observation, _, done, _, _, = env.step(env.action_space.sample())\n",
    "        obs_samples.append(observation)\n",
    "        num_samples += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1151ea7-5d3b-4bc2-a207-5c829d50c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Approximator:\n",
    "    def __init__(self, obs, dim, n_a, alpha, discount):\n",
    "        self.__discount = discount\n",
    "        self.__alpha = alpha\n",
    "        self.__n_actions = n_a\n",
    "        self.__obs_samples = obs\n",
    "        self.__feature_dim = dim\n",
    "        self.__w_size = 4 * self.__feature_dim\n",
    "        self.__w = np.zeros((self.__n_actions, self.__w_size))\n",
    "        self.__scaler = None\n",
    "        self.__featuriser = None\n",
    "        self.__initialised = False\n",
    "\n",
    "    def initialise_scaler_featuriser(self):\n",
    "        self.__scaler = sklearn.preprocessing.StandardScaler().fit(self.__obs_samples)\n",
    "        self.__featuriser = sklearn.pipeline.FeatureUnion(\n",
    "                [(\"rbf1\", RBFSampler(gamma=5.0, n_components=self.__feature_dim)),\n",
    "                 (\"rbf2\", RBFSampler(gamma=2.0, n_components=self.__feature_dim)),\n",
    "                 (\"rbf3\", RBFSampler(gamma=1.0, n_components=self.__feature_dim)),\n",
    "                 (\"rbf4\", RBFSampler(gamma=0.5, n_components=self.__feature_dim))])\n",
    "        self.__featuriser.fit(self.__scaler.transform(self.__obs_samples))\n",
    "        self.__initialised = True\n",
    "\n",
    "    @property\n",
    "    def get_w(self):\n",
    "        return self.__w\n",
    "\n",
    "    def feature_transformation(self, state):\n",
    "        if not self.__initialised:\n",
    "            self.initialise_scaler_featuriser()\n",
    "\n",
    "        scaled = self.__scaler.transform([state])\n",
    "        features = self.__featuriser.transform(scaled)\n",
    "        return features\n",
    "\n",
    "    # linear_features\n",
    "    def action_value_estimator(self, features, a):\n",
    "        return np.inner(features, self.__w[a])\n",
    "\n",
    "    # minimising MSE between q(replaced by td target) and q_hat\n",
    "    def update_w(self, r, q, next_q, features, a):\n",
    "        target = r + self.__discount * next_q\n",
    "        td_error = target - q\n",
    "        w_gradient = self.__alpha * td_error * features\n",
    "        self.__w[a] = self.__w[a] + w_gradient\n",
    "        \n",
    "    def set_w(self, a, new_w):\n",
    "        self.__w[a] = new_w\n",
    "\n",
    "    def cost_to_go(self, state):\n",
    "        features = self.feature_transformation(state)\n",
    "        v_s = []\n",
    "        for i in range(self.__n_actions):\n",
    "            v_s.append(self.action_value_estimator(features, i))\n",
    "        return - np.max(v_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e68eac-f810-48aa-b232-85ad3f65820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "gamma = 1.0\n",
    "epsilon = 0.1\n",
    "dim = 100\n",
    "\n",
    "# create an instance of approximator and initialize the normalizer and feature extractor \n",
    "estimator = Approximator(obs_samples, dim, n_actions, alpha, gamma)  \n",
    "estimator.initialise_scaler_featuriser() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a2c6830-8c0b-4884-befd-6ffd70890825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(epsilon, actions, values):\n",
    "    if np.random.binomial(1, epsilon) == 1:\n",
    "        return np.random.choice(actions)\n",
    "    else:\n",
    "        return np.random.choice([action_ for action_, value_ in enumerate(values) if value_ == np.max(values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d1aeca2-4210-426b-9f88-1bf219f20b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 50\n",
    "for i in range(1, episodes + 1):\n",
    "    state = env.reset()[0]\n",
    "    a = env.action_space.sample()\n",
    "    step_count = 0\n",
    "    while True:\n",
    "        step_count +=1 \n",
    "        next_state, r, done, _, _, = env.step(a)  # check the openAI github repo\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        # compute q_sa\n",
    "        features = estimator.feature_transformation(state)\n",
    "        q_sa = estimator.action_value_estimator(features, a)\n",
    "\n",
    "        # compute all actions in the next state for optimal policy\n",
    "        next_feature = estimator.feature_transformation(next_state)\n",
    "        q_values = []\n",
    "        for j in actions:\n",
    "            q_values.append(estimator.action_value_estimator(next_feature, j))\n",
    "\n",
    "        next_a = epsilon_greedy_policy(epsilon, actions, q_values)\n",
    "        next_q_sa = estimator.action_value_estimator(next_feature, next_a)\n",
    "\n",
    "        # update weights for current action\n",
    "        estimator.update_w(r, q_sa, next_q_sa, features, a)\n",
    "\n",
    "        a = next_a\n",
    "        state = next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3971a2d9-3c6b-4340-adf7-f351e633f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "ep=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b81f4e9-f844-4889-88f2-d0b34530ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(last_obs):\n",
    "    env1 = gym.make(\"MountainCar-v0\", render_mode=\"rgb_array\")\n",
    "    features = estimator.feature_transformation(last_obs)\n",
    "    q_values=[estimator.action_value_estimator(features, i)     for i in actions ]\n",
    "    action = epsilon_greedy_policy(ep, actions, q_values)\n",
    "    # last_obs: last observation of state\n",
    "    env1.reset()\n",
    "    env1.unwrapped.state = last_obs\n",
    "    next_state, reward, terminated , truncated, info = env1.step(action)\n",
    "    done = terminated or truncated\n",
    "    return(action, reward, done, next_state)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_probs(state,action):\n",
    "    features = estimator.feature_transformation(state)\n",
    "    values=[estimator.action_value_estimator(features, i)     for i in actions ]\n",
    "    prob = (1 - ep*(len(actions)-1)/len(actions)) if (action == epsilon_greedy_policy(0, actions, values)) else ep / len(actions) \n",
    "    return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec309e15-046b-4d21-b495-067ff7adf076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_traj(gam, seed=None, s_init=None):\n",
    "\n",
    "    if seed is None and s_init is None:\n",
    "        state, info = env.reset()\n",
    "    elif seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        state, info = env.reset()\n",
    "    if s_init is not None:\n",
    "        state = s_init\n",
    "    \n",
    " \n",
    "\n",
    "    s_traj = [state.copy()]  \n",
    "    a_traj = []\n",
    "    r_traj = []\n",
    "    d_traj = []\n",
    "    ret = 0\n",
    "    env.reset()\n",
    "    env.unwrapped.state = state\n",
    "    for i in range(200):\n",
    "        \n",
    "        features = estimator.feature_transformation(state)\n",
    "        values = [estimator.action_value_estimator(features, a) for a in actions]\n",
    "        action = epsilon_greedy_policy(ep, actions, values)\n",
    "        \n",
    "      \n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "       \n",
    "        s_traj.append(next_state.copy())\n",
    "        a_traj.append(action)\n",
    "        r_traj.append(reward)\n",
    "        d_traj.append(done)\n",
    "        ret += reward* gam**i\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "\n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    return [s_traj, a_traj, r_traj,d_traj, ret]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a1fdf6-81a6-47e4-9af0-65cb7aac1054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_ker(gam,seed=None, s_init=None):\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    state = env.reset()[0] if s_init is None else s_init\n",
    "    env.unwrapped.state = state\n",
    "    \n",
    "    s_traj = []\n",
    "    r_traj = []\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "       \n",
    "        features = estimator.feature_transformation(state)\n",
    "        values = [estimator.action_value_estimator(features, a) for a in actions]\n",
    "        action = epsilon_greedy_policy(ep, actions, values)\n",
    "        \n",
    "       \n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        \n",
    "       \n",
    "        s_traj.append(state.copy())\n",
    "        r_traj.append(reward)\n",
    "        state = next_state\n",
    "    cr = 0\n",
    "    cr_traj = []\n",
    "    for r in reversed(r_traj):\n",
    "        cr = cr * gam + r\n",
    "        cr_traj.insert(0, cr) \n",
    "    assert len(s_traj) == len(cr_traj)== len(cr_traj), \"State and reward trajectories must be of equal length\"\n",
    "    return [s_traj, cr_traj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17283cb9-5648-4d26-b3ed-492c899567d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sampling(sample_size,gam,seed=None, s_init=None):\n",
    "    s,cr=data_ker(gam,seed=seed, s_init=None)\n",
    "    seed+=1\n",
    "    num_samples=len(s)\n",
    "    while num_samples<sample_size:\n",
    "        s_new,cr_new=data_ker(gam,seed=None, s_init=None)\n",
    "        s=s+s_new\n",
    "        cr=cr+cr_new\n",
    "        num_samples+=len(s_new)\n",
    "        seed+=1\n",
    "    s=np.array(s)\n",
    "    cr=np.array(cr)\n",
    "    return [s,cr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770403b0-548a-42b9-8084-b9829b2d2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kde_conditional_quantiles_sklearn(x_data, y_data, x_query, quantiles, bandwidth):\n",
    "    # Convert inputs to numpy arrays\n",
    "    x_data = np.array(x_data).reshape(-1,2)\n",
    "    x_data[:,1]=x_data[:,1]*10\n",
    "    y_data = np.array(y_data).reshape(-1, 1)  # Ensure y_data is column vector\n",
    "    x_query = np.array(x_query).reshape(-1,2)\n",
    "    x_query[:,1]=x_query[:,1]*10\n",
    "    \n",
    "    \n",
    "    # Fit KDE for joint distribution\n",
    "    kde_xy = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde_xy.fit(np.column_stack([x_data, y_data]))\n",
    "    \n",
    "    # Fit KDE for marginal distribution of x\n",
    "    kde_x = KernelDensity(bandwidth=bandwidth, kernel='gaussian')\n",
    "    kde_x.fit(x_data)\n",
    "    \n",
    "    # Create evaluation grid for y values\n",
    "    y_grid = np.linspace(np.min(y_data)-3, np.max(y_data)+3, 1000).reshape(-1, 1)\n",
    "    \n",
    "    # Initialize output array (one row per x_query, one column per quantile)\n",
    "    quantile_results = np.zeros((len(x_query), len(quantiles)))\n",
    "    \n",
    "    for i, xq in enumerate(x_query):\n",
    "        # Create evaluation points by repeating current x_query for each y_grid point\n",
    "        x_eval = np.tile(xq, (len(y_grid), 1))\n",
    "        \n",
    "        # Compute log probabilities\n",
    "        log_p_xy = kde_xy.score_samples(np.column_stack([x_eval, y_grid]))\n",
    "        log_p_x = kde_x.score_samples(xq.reshape(1, -1))\n",
    "        \n",
    "        # Convert to probabilities and normalize\n",
    "        p_y_given_x = np.exp(log_p_xy - log_p_x)\n",
    "        p_y_given_x /= np.trapz(p_y_given_x, y_grid.flatten())  # Normalize\n",
    "        \n",
    "        # Compute quantiles\n",
    "        cdf = np.cumsum(p_y_given_x)\n",
    "        cdf /= cdf[-1]  # Ensure proper normalization\n",
    "        \n",
    "        # Store results for this x_query\n",
    "        quantile_results[i, :] = np.interp(quantiles, cdf, y_grid.flatten())\n",
    "    \n",
    "    return quantile_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "149bfe6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:57:10.570183Z",
     "start_time": "2025-03-20T03:57:10.553870Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "#### generate data ####\n",
    "#######################\n",
    "\n",
    "\n",
    "def data_gen(N, T_obs,gam, seed=None):\n",
    "    # N: number of trajectories\n",
    "    # T_obs: observed stage numbers\n",
    "\n",
    "    s_data = np.zeros((N, T_obs, 2))\n",
    "    a_data = np.zeros((N, T_obs), dtype=int)\n",
    "    r_data = np.zeros((N, T_obs))\n",
    "    d_data = np.zeros((N, T_obs))\n",
    "    ret_data = []\n",
    "\n",
    "\n",
    "    for i in range(N):\n",
    "        if seed is not None:\n",
    "            seed += 1\n",
    "        tmp = gen_traj(gam=gam,seed=seed, s_init=None)\n",
    "        s_data[i] = tmp[0][0:T_obs]  # store the i-th state trajectory\n",
    "        a_data[i] = tmp[1][0:T_obs]\n",
    "        r_data[i] = tmp[2][0:T_obs]  # store the i-th reward trajectory\n",
    "        d_data[i] = tmp[3][0:T_obs]\n",
    "        ret_data.append(tmp[-1])\n",
    "  \n",
    "\n",
    "    ## output observed state, reward trajectory and true return\n",
    "    return [s_data, a_data ,r_data, d_data ,ret_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfddf9eb-fc8c-4f07-9a67-6bfec1ea4945",
   "metadata": {},
   "outputs": [],
   "source": [
    "## replay buffer+weight estimation\n",
    "def replay_buffer(s_traj, a_traj, r_traj,step_forward,s_data,g_data,quantiles,bandwidth):\n",
    "    n = np.shape(s_traj)[0]\n",
    "    p = np.shape(s_traj)[1] - step_forward\n",
    "    state_dim=np.shape(s_traj)[2]\n",
    "#logistic regression\n",
    "    s_b = s_traj[:,1:p].reshape(-1,state_dim)\n",
    "    s_0 = s_traj[:,0]\n",
    "    X = np.vstack([s_b,s_0])\n",
    "    y = np.concatenate([np.ones(np.shape(s_b)[0]), np.zeros(np.shape(s_0)[0])])\n",
    "    rt = 1/(p-1)\n",
    "    model = LogisticRegression().fit(X, y)\n",
    "    \n",
    "    Mem_state = np.zeros((n*p,step_forward+1,state_dim))\n",
    "    Mem_action = np.zeros((n*p,step_forward+1),dtype=int)\n",
    "    Mem_reward = np.zeros((n*p,step_forward+1))\n",
    "    Mem_quan = np.zeros((n*p,len(quantiles)))\n",
    "    Mem_mean = np.zeros(n*p)\n",
    "    idx_weight=[]\n",
    "    state_zero=s_traj[:,0]\n",
    "    for i in range(n):\n",
    "        for j in range(p):\n",
    "            Mem_state[(i*p+j),:] = s_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_action[(i*p+j),:] = a_traj[i,j:(j+step_forward+1)]\n",
    "            Mem_reward[(i*p+j),:] = r_traj[i,j:(j+step_forward+1)]\n",
    "            \n",
    "            idx_weight.append(\n",
    "            rt*model.predict_proba(np.expand_dims(Mem_state[(i*p+j), 0], axis=0))[0, 1]/model.predict_proba(np.expand_dims(Mem_state[(i*p+j), 0], axis=0))[0, 0]\n",
    "            )\n",
    "    Mem_quan = kde_conditional_quantiles_sklearn(s_data, g_data, Mem_state[:,-1], quantiles, bandwidth)\n",
    "    Mem_mean = np.mean(kde_conditional_quantiles_sklearn(s_data, g_data, Mem_state[:,0], quantiles, bandwidth),axis=1)\n",
    "    total = np.array(idx_weight).sum()\n",
    "    idx_weight_final=np.array(idx_weight)/total\n",
    "    return([Mem_state,Mem_action,Mem_reward,Mem_quan,Mem_mean,idx_weight_final])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f08e423",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:58:54.244086Z",
     "start_time": "2025-03-20T03:58:54.239265Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def weighted_percentile(data, weights, perc):\n",
    "\n",
    "    data = np.array(data)\n",
    "    weights = np.array(weights)\n",
    "    idx = np.argsort(data)\n",
    "    data = data[idx] # sort data\n",
    "    weights = weights[idx] # sort weights\n",
    "    cdf = np.cumsum(weights) / np.sum(weights)\n",
    "    count = np.sum([ cdf[i] <= perc for i in range(np.shape(cdf)[0]) ])\n",
    "    #if output=infty return the maximum of V\n",
    "    if data[count]==float('inf'):\n",
    "        count-=1\n",
    "    return(data[count])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "758f7b57-0bbe-4fb5-9e95-df19b2d7262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(s_traj, r_traj,step_forward,gam,quan_traj,mean_traj):\n",
    "    # s_traj: state trajectory\n",
    "    # r_traj: reward trajectory\n",
    "    # step_forward: number of steps used in approximating return\n",
    "    # gam: discount\n",
    "    if np.shape(s_traj)[1]!=step_forward+1:\n",
    "        print(\"length dismatch\")\n",
    "    if np.shape(s_traj)[0]!=np.shape(r_traj)[0]:\n",
    "        print(\"height dismatch\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        n = np.shape(s_traj)[0]        \n",
    "        u = np.random.randint(0, np.shape(quan_traj)[1] - 1, size=n)\n",
    "        sc = list(\n",
    "            map(\n",
    "                abs,\n",
    "                np.sum([gam**i *r_traj[:, i] for i in range(step_forward)],\n",
    "                       axis=0) +\n",
    "                [\n",
    "                    gam**step_forward*quan_traj[i,u[i]] -\n",
    "                    mean_traj[i] for i in range(n)\n",
    "                ]))\n",
    "    return (sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785db874",
   "metadata": {},
   "source": [
    "## \n",
    "重复实验500次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40eb6eba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:33.791316Z",
     "start_time": "2025-03-20T03:59:33.787823Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175ce8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T03:59:41.448956Z",
     "start_time": "2025-03-20T03:59:41.435957Z"
    }
   },
   "outputs": [],
   "source": [
    "def new_rb_res(tr_size,data_train, data_test, alp, gam,step_forward, num_quantiles,B,eta,seed,sample_size,action_card,bandwidth):\n",
    "    n_tr, n_te = np.shape(data_train[0])[0], np.shape(data_test[0])[0]\n",
    "    state_dim=np.shape(data_test[0])[2]\n",
    "    s_init_te = data_test[0].reshape(-1,state_dim)\n",
    "    ret_te = data_test[-1]\n",
    "    \n",
    "    s_data,g_data = data_sampling(sample_size=tr_size,gam=gam,seed=seed, s_init=None)\n",
    "    quantiles=np.linspace(1/(2*num_quantiles), 1-1/(2*num_quantiles), num_quantiles)\n",
    "    ## calculate nonconformity scores based on test set\n",
    "    sc_te = abs(ret_te - np.mean(kde_conditional_quantiles_sklearn(s_data, g_data, s_init_te, quantiles, bandwidth))) \n",
    "        \n",
    "        ## replay buffer\n",
    "    l = np.shape(step_forward)[0]\n",
    "    if isinstance(eta, int) == False:\n",
    "        m = np.shape(eta)[0]\n",
    "    elif isinstance(eta, int) == True:\n",
    "        m = 1\n",
    "            \n",
    "    PI_cov_e = np.zeros((m,l))\n",
    "    PI_len_e = np.zeros((m,l))\n",
    "            \n",
    "\n",
    "    for k in range(l):\n",
    "        \n",
    "       \n",
    "        quan_B_e = np.zeros((m,n_te,B))\n",
    "        Mem=replay_buffer(s_traj=data_train[0], a_traj=data_train[1], \n",
    "                         r_traj=data_train[2],step_forward=step_forward[k],s_data=s_data,g_data=g_data,quantiles=quantiles,bandwidth=bandwidth)\n",
    "            \n",
    "        for i in range(B):\n",
    "            \n",
    "        #n_cal = np.random.choice(a=[j for j in range(np.shape(Mem[0])[0])], p=p,size=200)\n",
    "\n",
    "            weight_is=Mem[-1]\n",
    "            n_cal = np.random.choice(range(np.shape(weight_is)[0]),size=sample_size, p=weight_is)\n",
    "            ## calculate nonconformity scores based on calibration set\n",
    "            sc_rb = scoring(s_traj=Mem[0][n_cal,],\n",
    "                            r_traj=Mem[2][n_cal,],\n",
    "                            step_forward=step_forward[k],\n",
    "                            gam=gam,\n",
    "                            quan_traj=Mem[3][n_cal,],\n",
    "                            mean_traj=Mem[4][n_cal,]               \n",
    "                           )\n",
    "            sc_rb.append(float('inf')) \n",
    "            for j in range(n_te): \n",
    "                for z in range(m):\n",
    "                    quan_B_e[z][j,i] = weighted_percentile(data=sc_rb,weights=np.ones(sample_size+1),\n",
    "                                                      perc=1-alp)\n",
    "                    \n",
    "        critical_value_rb_e = np.zeros((m,n_te))\n",
    " \n",
    "        for z in range(m):\n",
    "            critical_value_rb_e[z,:] = [ np.percentile(a=quan_B_e[z][k,:],\n",
    "                                                           q=eta[z]*100) for k in range(n_te) ]\n",
    "\n",
    "            \n",
    "            PI_cov_e[z,k] = np.mean([sc_te[k] <= critical_value_rb_e[z,k] \n",
    "                                         for k in range(n_te)])\n",
    "            PI_len_e[z,k] = 2 * np.mean(critical_value_rb_e[z,:])\n",
    "                \n",
    "            \n",
    "    return([PI_cov_e,PI_len_e])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02f506fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T15:22:31.005418Z",
     "start_time": "2025-03-19T15:22:31.005418Z"
    }
   },
   "outputs": [],
   "source": [
    "def quantile_region_res(sample_size, gam,data_test, alp, num_quantiles,seed,action_card,bandwidth):\n",
    "\n",
    "    n_te = np.shape(data_test[0])[0]\n",
    "    s_init_te = data_test[0]\n",
    "    state_dim = np.shape(data_test[0])[2]\n",
    "    ret_te = data_test[-1]\n",
    "    quantiles=[alp/2,1-alp/2]\n",
    "    ## train QTD using full training data\n",
    "    s_data,g_data = data_sampling(sample_size=sample_size,gam=gam,seed=seed, s_init=None)\n",
    "\n",
    "    quant_interval_lower=np.zeros(n_te)\n",
    "    quant_interval_upper=np.zeros(n_te)\n",
    "    \n",
    "    quant_interval=kde_conditional_quantiles_sklearn(s_data, g_data, s_init_te, quantiles, bandwidth)\n",
    "    quant_interval_lower=quant_interval[:,0] \n",
    "    quant_interval_upper=quant_interval[:,1]\n",
    "    t1 = [\n",
    "    ret_te[i] >= quant_interval_lower[i] for i in range(n_te)\n",
    "    ]\n",
    "    t2 = [\n",
    "    ret_te[i] <= quant_interval_upper[i] for i in range(n_te)\n",
    "    ]\n",
    "    quan_PI_cov = np.mean([all([t1[i], t2[i]]) for i in range(n_te)])\n",
    "    quan_PI_len = np.mean(quant_interval_upper - quant_interval_lower\n",
    "            )\n",
    "\n",
    "\n",
    "    return ([quan_PI_cov, quan_PI_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2b737c9-5a7b-44fc-bada-4f763172ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel Calculation\n",
    "def run_single_experiment(i,tr_size, n_tr, T_obs, seed, n_te,  num_quantiles, B, alp, eta, gam, step_forward,sample_size,action_card,bandwidth):\n",
    "\n",
    "    data_train = data_gen(N=n_tr,\n",
    "                          T_obs=T_obs, \n",
    "                          gam=gam,\n",
    "                          seed=seed + i\n",
    "                         )\n",
    "\n",
    "\n",
    "    data_test = data_gen(N=n_te,\n",
    "                             T_obs=1,\n",
    "                             gam=gam,\n",
    "                             seed=seed + i + 10000\n",
    "                            )\n",
    "\n",
    "    result = new_rb_res(tr_size=tr_size,\n",
    "                        data_train=data_train,\n",
    "                        data_test=data_test,\n",
    "                        alp=alp,\n",
    "                        gam=gam,\n",
    "                        step_forward=step_forward,\n",
    "                        num_quantiles=num_quantiles,\n",
    "                        B=B,\n",
    "                        eta=eta,\n",
    "                        seed=seed + i,\n",
    "                        sample_size=sample_size,\n",
    "                       action_card=action_card,\n",
    "                        bandwidth=bandwidth\n",
    "                       )\n",
    "   \n",
    "    return result  # return [PI_cov_e, PI_len_e]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869f2ea1-53ff-4e9a-a497-184fc6b204cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  10 out of  10 | elapsed: 47.9min finished\n"
     ]
    }
   ],
   "source": [
    "# Parameter setting\n",
    "rep = 50\n",
    "tr_size=2000\n",
    "n_tr = 200\n",
    "T_obs = 10\n",
    "seed = 2025\n",
    "n_te = 350\n",
    "num_quantiles = 20\n",
    "B = 50\n",
    "alp = 0.1\n",
    "eta = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "step_forward = [1, 2, 3,4,5]\n",
    "sample_size=200\n",
    "action_card=3\n",
    "bandwidth=0.045\n",
    "\n",
    "\n",
    "\n",
    "results = Parallel(n_jobs=18, verbose=1)(\n",
    "    delayed(run_single_experiment)(\n",
    "        i, tr_size, n_tr, T_obs, seed, n_te,  num_quantiles, B, alp, eta, gam, step_forward,sample_size,action_card,bandwidth\n",
    "    ) for i in range(rep)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30500b6f-eecd-4a06-81ef-62fd05e6bc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_new_cov_tau01_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau02_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau03_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau04_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau05_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau06_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau07_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau08_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_cov_tau09_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "\n",
    "\n",
    "rb_new_len_tau01_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau02_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau03_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau04_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau05_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau06_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau07_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau08_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "rb_new_len_tau09_e3 = np.zeros((rep, np.shape(step_forward)[0]))\n",
    "#Restore data\n",
    "for i in range(np.shape(results)[0]):\n",
    "    rb_new_cov_tau01_e3[i, :] = results [i][0][0]\n",
    "    rb_new_cov_tau02_e3[i, :] = results [i][0][1]\n",
    "    rb_new_cov_tau03_e3[i, :] = results [i][0][2]\n",
    "    rb_new_cov_tau04_e3[i, :] = results [i][0][3]\n",
    "    rb_new_cov_tau05_e3[i, :] = results [i][0][4]\n",
    "    rb_new_cov_tau06_e3[i, :] = results [i][0][5]\n",
    "    rb_new_cov_tau07_e3[i, :] = results [i][0][6]\n",
    "    rb_new_cov_tau08_e3[i, :] = results [i][0][7]\n",
    "    rb_new_cov_tau09_e3[i, :] = results [i][0][8]\n",
    "\n",
    "    rb_new_len_tau01_e3[i, :] = results [i][1][0]\n",
    "    rb_new_len_tau02_e3[i, :] = results [i][1][1]\n",
    "    rb_new_len_tau03_e3[i, :] = results [i][1][2]\n",
    "    rb_new_len_tau04_e3[i, :] = results [i][1][3]\n",
    "    rb_new_len_tau05_e3[i, :] = results [i][1][4]\n",
    "    rb_new_len_tau06_e3[i, :] = results [i][1][5]\n",
    "    rb_new_len_tau07_e3[i, :] = results [i][1][6]\n",
    "    rb_new_len_tau08_e3[i, :] = results [i][1][7]\n",
    "    rb_new_len_tau09_e3[i, :] = results [i][1][8]\n",
    "    \n",
    "\n",
    "PI_cov_all = [res[0] for res in results]\n",
    "PI_len_all = [res[1] for res in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bef64d-297e-4981-ac25-52ab714a16e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new(tau=0.2): \n",
      "coverage probability: \n",
      "[0.7018181818181819, 0.7799999999999999, 0.8427272727272725, 0.8309090909090908, 0.8554545454545455]\n",
      "average length: \n",
      "[6.520582133702033, 7.408434525995479, 8.12134137054952, 8.130853730339572, 8.468122280015947]\n",
      "new(tau=0.3): \n",
      "coverage probability: \n",
      "[0.7363636363636364, 0.8045454545454545, 0.8554545454545455, 0.8536363636363637, 0.8645454545454545]\n",
      "average length: \n",
      "[6.9371661576714745, 7.7135937100900165, 8.492786256595332, 8.469996803627732, 8.785605660996868]\n",
      "new(tau=0.4): \n",
      "coverage probability: \n",
      "[0.7618181818181817, 0.8327272727272728, 0.8636363636363636, 0.8581818181818182, 0.8681818181818182]\n",
      "average length: \n",
      "[7.197554258902859, 8.095711000753807, 8.848807241986671, 8.77800121647962, 9.134035238069007]\n",
      "new(tau=0.5): \n",
      "coverage probability: \n",
      "[0.7809090909090909, 0.8463636363636363, 0.8699999999999999, 0.8654545454545455, 0.8736363636363637]\n",
      "average length: \n",
      "[7.382564478502969, 8.412902221010985, 9.16102669075666, 9.044757401766953, 9.457614413333225]\n",
      "new(tau=0.6): \n",
      "coverage probability: \n",
      "[0.801818181818182, 0.8581818181818182, 0.8763636363636363, 0.8736363636363637, 0.8827272727272728]\n",
      "average length: \n",
      "[7.592976412625954, 8.623550176999755, 9.482799574700056, 9.318408314959182, 9.764214768226996]\n",
      "new(tau=0.7): \n",
      "coverage probability: \n",
      "[0.8209090909090909, 0.8618181818181817, 0.8863636363636364, 0.8809090909090909, 0.8954545454545453]\n",
      "average length: \n",
      "[7.828460993140571, 8.872984928069743, 9.813050551431099, 9.619913948215585, 10.096358829899081]\n",
      "new(tau=0.8): \n",
      "coverage probability: \n",
      "[0.8381818181818183, 0.8690909090909091, 0.8972727272727272, 0.8945454545454543, 0.9045454545454545]\n",
      "average length: \n",
      "[8.091935649336259, 9.27341944740704, 10.203157740977257, 9.955712043235545, 10.39400177029933]\n"
     ]
    }
   ],
   "source": [
    "print(\"new(tau=0.1): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau01_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau01_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.2): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau02_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau02_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.3): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau03_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "\n",
    "print(\"new(tau=0.4): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau04_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau04_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.5): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau05_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau05_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.6): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau06_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau06_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.7): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau07_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau07_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.8): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau08_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau08_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "\n",
    "print(\"new(tau=0.9): \")\n",
    "print(\"coverage probability: \")\n",
    "print([np.mean(rb_new_cov_tau09_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])\n",
    "print(\"average length: \")\n",
    "print([np.mean(rb_new_len_tau09_e3[:,i]) for i in range(np.shape(rb_new_cov_tau05_e3)[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a268c-c57b-4bb0-86e0-ea39bc4150dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8419fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau01_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau01_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau01_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau01_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau01_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_01.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau01_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau01_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau01_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau01_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau01_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_01.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3007d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau02_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau02_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau02_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau02_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau02_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_02.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau02_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau02_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau02_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau02_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau02_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_02.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db331d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau03_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau03_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau03_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau03_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau03_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_03.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau03_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau03_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau03_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau03_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau03_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_03.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau04_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau04_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau04_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau04_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau04_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_04.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau04_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau04_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau04_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau04_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau04_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_04.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcbf63-11bb-4b4a-b237-cf5f0a31b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau05_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau05_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau05_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau05_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau05_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_05.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau05_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau05_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau05_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau05_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau05_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_05.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0e562-1ca8-4454-a12e-6e685a19f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau06_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau06_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau06_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau06_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau06_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_06.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau06_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau06_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau06_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau06_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau06_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_06.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a06ff0-7838-4134-9873-9d83e221bb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau07_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau07_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau07_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau07_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau07_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_07.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau07_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau07_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau07_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau07_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau07_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_07.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f962e6-89e5-4f0d-bce1-076fdb93742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau08_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau08_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau08_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau08_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau08_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_08.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau08_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau08_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau08_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau08_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau08_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_08.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d74c997-4812-400d-85bd-8196556ef7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### save simulation result\n",
    "data_new_rb_cov = {\n",
    "    'new-rb-1': rb_new_cov_tau09_e3[:,0],\n",
    "    'new-rb-2': rb_new_cov_tau09_e3[:,1],\n",
    "    'new-rb-3': rb_new_cov_tau09_e3[:,2],\n",
    "    'new-rb-4': rb_new_cov_tau09_e3[:,3],\n",
    "    'new-rb-5': rb_new_cov_tau09_e3[:,4],\n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "data_cov = pd.DataFrame(data_new_rb_cov)\n",
    "data_cov.to_excel('cov_mc_on_09.xlsx', index=False)\n",
    "\n",
    "#df_cov.to_excel('simu_res/res_new_rb_e_cov_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_new_rb_len = {\n",
    "     'new-rb-1': rb_new_len_tau09_e3[:,0],\n",
    "     'new-rb-2': rb_new_len_tau09_e3[:,1],\n",
    "     'new-rb-3': rb_new_len_tau09_e3[:,2],\n",
    "     'new-rb-4': rb_new_len_tau09_e3[:,3],\n",
    "     'new-rb-5': rb_new_len_tau09_e3[:,4],\n",
    "\n",
    "}\n",
    "\n",
    "data_len = pd.DataFrame(data_new_rb_len)\n",
    "data_len.to_excel('len_mc_on_09.xlsx', index=False)\n",
    "\n",
    "#df_len.to_excel('simu_res/res_new_rb_e_len_gam0.8_tau0.5_qnum30_100to200.xlsx', index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08941fe-d831-4131-b12b-d2c8c90f7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=18)]: Using backend LokyBackend with 18 concurrent workers.\n",
      "[Parallel(n_jobs=18)]: Done   3 out of   3 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "rep = 50\n",
    "sample_size=4000\n",
    "seed = 2025\n",
    "n_te = 350\n",
    "alp=0.1\n",
    "num_quantiles = 20\n",
    "clip=np.array([0.2,5.0])\n",
    "action_card=3\n",
    "gam=0.99\n",
    "bandwidth=0.04\n",
    "res_quan = np.zeros((rep, 2))\n",
    "\n",
    "# Parallel Calculation\n",
    "def process_iteration(i,sample_size,gam, n_te, num_quantiles, alp, seed,action_card):\n",
    " \n",
    "    \n",
    "    data_test = data_gen(N=n_te,\n",
    "                            T_obs=1,\n",
    "                             gam=gam,\n",
    "                            seed=seed + i + 10000)\n",
    "    \n",
    "\n",
    "    quan_PI_res1 = quantile_region_res(sample_size=sample_size,\n",
    "                                       gam=gam,\n",
    "                                      data_test=data_test,\n",
    "                                      alp=alp,\n",
    "                                      num_quantiles=num_quantiles,\n",
    "                                      seed=seed+i,\n",
    "                                        action_card=action_card,\n",
    "                                       bandwidth=bandwidth\n",
    "                                        )\n",
    "    \n",
    "    print(f\"test num: {i}\")\n",
    "    print(\"quantile region: \")\n",
    "    print(f\"cov: {quan_PI_res1[0]} | length: {quan_PI_res1[1]}\")\n",
    "    \n",
    "    return quan_PI_res1\n",
    "\n",
    "\n",
    "\n",
    "results_qr = Parallel(n_jobs=18, verbose=1)(delayed(process_iteration)(\n",
    "    i, sample_size, gam, n_te, num_quantiles, alp, seed,action_card) for i in range(rep))\n",
    "\n",
    "# restore data\n",
    "for i in range(rep):\n",
    "    res_quan[i, :] = results_qr[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33a1b3fc-aca4-46a7-aa8b-4c6e9d08e9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65142857, 10.08269118],\n",
       "       [ 0.73714286, 10.52855892],\n",
       "       [ 0.88285714, 14.55931226]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_quan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b055a675",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:47:46.618942Z",
     "start_time": "2025-03-19T07:47:46.550210Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quantile region\n",
      "0         0.651429\n",
      "1         0.737143\n",
      "2         0.882857\n",
      "   quantile region\n",
      "0        10.082691\n",
      "1        10.528559\n",
      "2        14.559312\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "##### save simulation result\n",
    "data_quan_cov = {\n",
    "    'quantile region': res_quan[:, 0]\n",
    "}\n",
    "\n",
    "df_cov = pd.DataFrame(data_quan_cov)\n",
    "\n",
    "df_cov.to_excel('QR_cov_mc_on.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "data_quan_len = {\n",
    "    'quantile region': res_quan[:, 1]\n",
    "}\n",
    "\n",
    "df_len = pd.DataFrame(data_quan_len)\n",
    "\n",
    "df_len.to_excel('QR_len_mc_on.xlsx', index=False, engine='openpyxl')\n",
    "\n",
    "print(df_cov.head())\n",
    "print(df_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b906adf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-19T07:46:49.188482Z",
     "start_time": "2025-03-19T07:46:49.179093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile region: \n",
      "coverage probability:  0.7571428571428571 |  average length:  11.723520787269274\n"
     ]
    }
   ],
   "source": [
    "print(\"quantile region: \")\n",
    "print(\"coverage probability: \", np.mean(res_quan[:, 0]),\n",
    "      \"|  average length: \", np.mean(res_quan[:, 1]))\n",
    "\n",
    "#print([ np.mean(rb_new_cov_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])\n",
    "#print([ np.mean(rb_new_len_tau05_e[:,i]) for i in range(np.shape(rb_new_cov_tau05_e)[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d3be7",
   "metadata": {},
   "source": [
    "# 模拟结果图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7c59d47-218e-42d2-81d3-b36efdabaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   new-rb-1  new-rb-2  new-rb-3  new-rb-4  new-rb-5        QR\n",
      "0  0.877419  0.877419  0.877419  0.877419  0.877419  0.887097\n",
      "1  0.880645  0.880645  0.880645  0.883871  0.890323  0.864516\n",
      "2  0.883871  0.887097  0.887097  0.883871  0.883871  0.887097\n",
      "3  0.877419  0.877419  0.877419  0.877419  0.883871  0.887097\n",
      "4  0.877419  0.880645  0.880645  0.880645  0.887097  0.887097\n",
      "   new-rb-1  new-rb-2  new-rb-3  new-rb-4  new-rb-5        QR\n",
      "0  7.184103  7.300162  7.227494  7.234046  7.354492  7.398871\n",
      "1  7.163068  7.181728  7.286160  7.319855  7.422460  7.187608\n",
      "2  7.292234  7.425412  7.465158  7.339162  7.246481  7.400118\n",
      "3  7.208743  7.352818  7.360902  7.363134  7.422255  7.383613\n",
      "4  7.155576  7.290999  7.305147  7.293528  7.457363  7.438672\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_new_rb_cov.columns = ['k=1', 'k=2', 'k=3' , 'k=4' , 'k=5']\n",
    "data_new_rb_len.columns = ['k=1', 'k=2', 'k=3' , 'k=4' , 'k=5']\n",
    "\n",
    "data_QR_cov = pd.read_excel('QR_cov_mc_on.xlsx')\n",
    "data_QR_len = pd.read_excel('QR_len_mc_on.xlsx')\n",
    "\n",
    "\n",
    "#data_new_rb_cov.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "#data_new_rb_len.rename(columns={'quantile region': 'QR'}, inplace=True)\n",
    "data_new_rb_cov['DRL-QR'] = data_QR_cov['quantile region']\n",
    "data_new_rb_len['DRL-QR'] = data_QR_len['quantile region']\n",
    "\n",
    "print(data_new_rb_cov.head())\n",
    "print(data_new_rb_len.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7870e9-8ebb-49d0-969f-cc4108b3b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_cov = data_new_rb_cov.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "colors = [\n",
    "    'goldenrod', 'orange', 'gold', 'khaki', 'wheat', 'lightyellow','skyblue'\n",
    "]\n",
    "\n",
    "colors2 = [\n",
    "    'darkseagreen','limegreen' ,'greenyellow','yellowgreen','lightgreen','honeydew','skyblue'\n",
    "]\n",
    "for patch, color in zip(bplot_new_cov.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_cov.yaxis.grid(False)\n",
    "bplot_new_cov.xaxis.grid(False)\n",
    "bplot_new_cov.set_xlabel(\"Method\")\n",
    "bplot_new_cov.set_ylabel(\"Coverage Probability\")\n",
    "\n",
    "plt.axhline(y=0.90, color='red', linestyle='-', linewidth=1)\n",
    "plt.ylim(0.75,1)\n",
    "#plt.savefig('fig/new_rb_cov_o_gam0.8_nr100_qnum10.png')\n",
    "plt.show()\n",
    "plt.savefig('Ex3_on_policy_cp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce70c4-effd-4877-85d4-d7f990bd1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "bplot_new_len = data_new_rb_len.boxplot(patch_artist=True,\n",
    "                         medianprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black',\n",
    "                             'linewidth': 1.5\n",
    "                         },\n",
    "                         whiskerprops={\n",
    "                             'linestyle': '--',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         capprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         },\n",
    "                         boxprops={\n",
    "                             'linestyle': '-',\n",
    "                             'color': 'black'\n",
    "                         })\n",
    "\n",
    "\n",
    "for patch, color in zip(bplot_new_len.patches, colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_linewidth(1)\n",
    "\n",
    "bplot_new_len.yaxis.grid(False)\n",
    "bplot_new_len.xaxis.grid(False)\n",
    "bplot_new_len.set_xlabel(\"Method\")\n",
    "bplot_new_len.set_ylabel(\"Empirical Length\")\n",
    "#plt.savefig('fig/new_len_o_gam0.8_nr100_qnum10.png')\n",
    "plt.show()\n",
    "plt.savefig('Ex3_on_policy_al.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
